{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c271dcc-5507-455b-ba2b-773de2157b21",
   "metadata": {},
   "source": [
    "# prepare model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27e9c9c-a8b1-4ff8-9fce-28c5a6af4652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.3-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.3-py2.py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.3/251.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2f70199-1976-449f-9d66-b13683113dca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< process attributes\n",
      "100%|██████████████████████████████████| 23536/23536 [00:01<00:00, 16568.35it/s]\n",
      "<<< process keywords\n",
      "100%|███████████████████████████████████| 23536/23536 [00:03<00:00, 6437.70it/s]\n",
      "<<<output json file!\n",
      "Data written to json\n"
     ]
    }
   ],
   "source": [
    "!python prepare_train_data_yf.py --input_file '../data/20240527-eb平台分类属性训练数据.xlsx' --output_folder '../train_llama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8f1d560-3eee-4268-a8dd-7cb34813d7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../train_llama/test.json to s3://sagemaker-us-west-2-726335585155/yafei/keywords/test.json\n",
      "upload: ../train_llama/train.json to s3://sagemaker-us-west-2-726335585155/yafei/keywords/train.json\n",
      "upload: ../train_llama/dataset_info.json to s3://sagemaker-us-west-2-726335585155/yafei/keywords/dataset_info.json\n"
     ]
    }
   ],
   "source": [
    "#cp\n",
    "! aws s3 cp ../train_llama/test.json s3://sagemaker-us-west-2-726335585155/yafei/keywords/ \n",
    "! aws s3 cp ../train_llama/train.json s3://sagemaker-us-west-2-726335585155/yafei/keywords/ \n",
    "! aws s3 cp ../train_llama/dataset_info.json s3://sagemaker-us-west-2-726335585155/yafei/keywords/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1028d-c209-4d5e-9429-3e21d71c423f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dbadc96-b35e-425c-9d43-710cc2e47e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-west-2-726335585155\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762d9cb4-8d87-4ff0-b05d-dd31fdc535bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n",
      "Fetching 17 files:   0%|                                 | 0/17 [00:00<?, ?it/s]Downloading 'model-00002-of-00004.safetensors' to '../Meta-Llama-3-8B-instruct/.huggingface/download/model-00002-of-00004.safetensors.8d4782b4a69ef03845159ce1a15e272aadaaf134dc138d68f616098e8531729c.incomplete'\n",
      "\n",
      "model-00002-of-00004.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   0%|     | 21.0M/5.00G [00:00<00:25, 198MB/s]\u001b[ADownloading 'model-00001-of-00004.safetensors' to '../Meta-Llama-3-8B-instruct/.huggingface/download/model-00001-of-00004.safetensors.d8cf9c4d0dd972e1a2131bfe656235ee98221679711a3beef6d46dadf0f20b5c.incomplete'\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|     | 52.4M/5.00G [00:00<00:19, 249MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|     | 21.0M/4.98G [00:00<00:26, 185MB/s]\u001b[A\u001b[ADownloading 'generation_config.json' to '../Meta-Llama-3-8B-instruct/.huggingface/download/generation_config.json.8675015d20a4b12ee2ee0197a0937beba318122a.incomplete'\n",
      "Downloading 'LICENSE' to '../Meta-Llama-3-8B-instruct/.huggingface/download/LICENSE.4c763399690c7fec642231350756e4ee9184b5ce.incomplete'\n",
      "Downloading 'README.md' to '../Meta-Llama-3-8B-instruct/.huggingface/download/README.md.598429539b31990d69dbcb5e325fce3c32e5c92e.incomplete'\n",
      "\n",
      "model-00002-of-00004.safetensors:   2%|     | 83.9M/5.00G [00:00<00:18, 262MB/s]\u001b[ADownloading 'config.json' to '../Meta-Llama-3-8B-instruct/.huggingface/download/config.json.31553d63b8f18df5d6d440860751533ada3759e4.incomplete'\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|     | 52.4M/4.98G [00:00<00:20, 240MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|▏     | 115M/5.00G [00:00<00:17, 274MB/s]\u001b[ADownloading '.gitattributes' to '../Meta-Llama-3-8B-instruct/.huggingface/download/.gitattributes.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|     | 83.9M/4.98G [00:00<00:18, 260MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   3%|▏     | 147M/5.00G [00:00<00:17, 279MB/s]\u001b[A\n",
      "\n",
      "\n",
      "generation_config.json: 100%|██████████████████| 187/187 [00:00<00:00, 1.79MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/generation_config.json\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏     | 115M/4.98G [00:00<00:17, 277MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▏     | 178M/5.00G [00:00<00:17, 282MB/s]\u001b[ADownloading 'USE_POLICY.md' to '../Meta-Llama-3-8B-instruct/.huggingface/download/USE_POLICY.md.6f8e5f6e3243c92046a133c92eb62b1ed7975a0b.incomplete'\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▏     | 147M/4.98G [00:00<00:17, 278MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▎     | 210M/5.00G [00:00<00:16, 286MB/s]\u001b[A\n",
      "\n",
      "\n",
      "LICENSE: 100%|█████████████████████████████| 7.80k/7.80k [00:00<00:00, 48.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/LICENSE\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▏     | 178M/4.98G [00:00<00:17, 273MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 654/654 [00:00<00:00, 8.02MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/config.json\n",
      "\n",
      "model-00002-of-00004.safetensors:   5%|▎     | 241M/5.00G [00:00<00:16, 280MB/s]\u001b[A\n",
      "\n",
      "\n",
      "USE_POLICY.md: 100%|███████████████████████| 4.70k/4.70k [00:00<00:00, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/USE_POLICY.md\n",
      "\n",
      "\n",
      "\n",
      "README.md:   0%|                                    | 0.00/38.9k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▎     | 210M/4.98G [00:00<00:17, 269MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   5%|▎     | 273M/5.00G [00:00<00:16, 284MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      ".gitattributes: 100%|██████████████████████| 1.52k/1.52k [00:00<00:00, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/.gitattributes\n",
      "Fetching 17 files:   6%|█▍                       | 1/17 [00:01<00:22,  1.38s/it]\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 241M/4.98G [00:00<00:17, 271MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▎     | 304M/5.00G [00:01<00:16, 285MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 273M/4.98G [00:01<00:17, 275MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 336M/5.00G [00:01<00:16, 286MB/s]\u001b[A\n",
      "\n",
      "\n",
      "README.md: 100%|████████████████████████████| 38.9k/38.9k [00:00<00:00, 121kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/README.md\n",
      "Fetching 17 files:  18%|████▍                    | 3/17 [00:01<00:06,  2.21it/s]Downloading 'model-00003-of-00004.safetensors' to '../Meta-Llama-3-8B-instruct/.huggingface/download/model-00003-of-00004.safetensors.3acdd690e65c24f42a24581b8467af98bd3ca357444580f8012aacd2bd607921.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   0%|             | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 367M/5.00G [00:01<00:16, 285MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▎     | 304M/4.98G [00:01<00:17, 271MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   0%|     | 21.0M/4.92G [00:00<00:25, 196MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   8%|▍     | 398M/5.00G [00:01<00:16, 278MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▍     | 336M/4.98G [00:01<00:17, 267MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|     | 52.4M/4.92G [00:00<00:19, 248MB/s]\u001b[A\u001b[A\u001b[ADownloading 'model-00004-of-00004.safetensors' to '../Meta-Llama-3-8B-instruct/.huggingface/download/model-00004-of-00004.safetensors.67e9ad31c8c32abf3a55ee7fc7217b3ecb35fd3c74d98a5bd233e0e4d6964f46.incomplete'\n",
      "\n",
      "model-00002-of-00004.safetensors:   9%|▌     | 430M/5.00G [00:01<00:16, 285MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   0%|             | 0.00/1.17G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▍     | 367M/4.98G [00:01<00:17, 261MB/s]\u001b[A\u001b[ADownloading 'original/consolidated.00.pth' to '../Meta-Llama-3-8B-instruct/.huggingface/download/original/consolidated.00.pth.be52262c9289304f3e8240e0749bf257bc04264405a86cd4de38efb9068724ee.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   0%|                          | 0.00/16.1G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   2%|     | 83.9M/4.92G [00:00<00:19, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▌     | 461M/5.00G [00:01<00:16, 276MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   2%|     | 21.0M/1.17G [00:00<00:06, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   0%|                 | 10.5M/16.1G [00:00<02:47, 95.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▍     | 398M/4.98G [00:01<00:20, 225MB/s]\u001b[A\u001b[ADownloading 'model.safetensors.index.json' to '../Meta-Llama-3-8B-instruct/.huggingface/download/model.safetensors.index.json.0fd8120f1c6acddc268ebc2583058efaf699a771.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   4%|▏    | 41.9M/1.17G [00:00<00:07, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   2%|▏     | 115M/4.92G [00:00<00:23, 203MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|▌     | 493M/5.00G [00:01<00:19, 227MB/s]\u001b[ADownloading 'original/params.json' to '../Meta-Llama-3-8B-instruct/.huggingface/download/original/params.json.65f16bb074ab2ba456331a8ea3d50c3fdbf343bf.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   0%|                  | 31.5M/16.1G [00:00<02:19, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   5%|▎    | 62.9M/1.17G [00:00<00:08, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 430M/4.98G [00:01<00:25, 176MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   0%|                  | 52.4M/16.1G [00:00<01:54, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|▋     | 524M/5.00G [00:02<00:23, 194MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 147M/4.92G [00:00<00:27, 172MB/s]\u001b[A\u001b[A\u001b[ADownloading 'original/tokenizer.model' to '../Meta-Llama-3-8B-instruct/.huggingface/download/original/tokenizer.model.82e9d31979e92ab929cd544440f129d9ecd797b69e327f80f17e1c50d5551b55.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   7%|▎    | 83.9M/1.17G [00:00<00:07, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   0%|                  | 73.4M/16.1G [00:00<01:53, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.model:   0%|                              | 0.00/2.18M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 451M/4.98G [00:02<00:27, 163MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tokenizer.model: 100%|█████████████████████| 2.18M/2.18M [00:00<00:00, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/original/tokenizer.model\n",
      "\n",
      "model-00002-of-00004.safetensors:  11%|▋     | 556M/5.00G [00:02<00:24, 180MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   9%|▌     | 105M/1.17G [00:00<00:07, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   1%|                  | 94.4M/16.1G [00:00<01:46, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original/params.json: 100%|████████████████████| 211/211 [00:00<00:00, 2.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/original/params.json\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 472M/4.98G [00:02<00:28, 156MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   4%|▏     | 189M/4.92G [00:01<00:28, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 577M/5.00G [00:02<00:24, 180MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  11%|▋     | 126M/1.17G [00:00<00:06, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   1%|▏                  | 115M/16.1G [00:00<01:40, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 493M/4.98G [00:02<00:28, 160MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   4%|▎     | 210M/4.92G [00:01<00:28, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 598M/5.00G [00:02<00:24, 177MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  13%|▊     | 147M/1.17G [00:00<00:06, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   1%|▏                  | 136M/16.1G [00:00<01:39, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'tokenizer.json' to '../Meta-Llama-3-8B-instruct/.huggingface/download/tokenizer.json.b197f72effb9d5ed16ee0f5663e11e4cfac2ba62.incomplete'\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 514M/4.98G [00:02<00:27, 160MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   5%|▎     | 231M/4.92G [00:01<00:28, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 619M/5.00G [00:02<00:25, 170MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  14%|▊     | 168M/1.17G [00:01<00:06, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   1%|▏                  | 157M/16.1G [00:01<01:39, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 535M/4.98G [00:02<00:26, 165MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   5%|▎     | 252M/4.92G [00:01<00:28, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model.safetensors.index.json: 100%|████████| 23.9k/23.9k [00:00<00:00, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/model.safetensors.index.json\n",
      "\n",
      "model-00002-of-00004.safetensors:  13%|▊     | 640M/5.00G [00:02<00:26, 165MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  16%|▉     | 189M/1.17G [00:01<00:06, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   1%|▏                  | 178M/16.1G [00:01<01:42, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 556M/4.98G [00:02<00:26, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   6%|▎     | 273M/4.92G [00:01<00:29, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  13%|▊     | 661M/5.00G [00:02<00:26, 163MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  18%|█     | 210M/1.17G [00:01<00:06, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 577M/4.98G [00:02<00:26, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   1%|▏                  | 199M/16.1G [00:01<01:42, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   6%|▎     | 294M/4.92G [00:01<00:29, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▊     | 682M/5.00G [00:03<00:26, 165MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  20%|█▏    | 231M/1.17G [00:01<00:05, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   1%|▎                  | 220M/16.1G [00:01<01:40, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 598M/4.98G [00:02<00:26, 164MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   6%|▍     | 315M/4.92G [00:01<00:29, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▊     | 703M/5.00G [00:03<00:26, 164MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  22%|█▎    | 252M/1.17G [00:01<00:05, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'tokenizer_config.json' to '../Meta-Llama-3-8B-instruct/.huggingface/download/tokenizer_config.json.1bfd1146b7bde6168de7bb673bfe0acaea6e684c.incomplete'\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 619M/4.98G [00:03<00:27, 158MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   2%|▎                  | 241M/16.1G [00:01<01:48, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'special_tokens_map.json' to '../Meta-Llama-3-8B-instruct/.huggingface/download/special_tokens_map.json.d8cd5076496dbe4be2320312abc10adc43097b81.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   7%|▍     | 336M/4.92G [00:01<00:29, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.json:   0%|                               | 0.00/9.09M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▊     | 724M/5.00G [00:03<00:28, 153MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  23%|█▍    | 273M/1.17G [00:01<00:05, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 640M/4.98G [00:03<00:26, 161MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   2%|▎                  | 262M/16.1G [00:01<01:51, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   7%|▍     | 357M/4.92G [00:02<00:29, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  25%|█▌    | 294M/1.17G [00:01<00:05, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|▉     | 744M/5.00G [00:03<00:28, 151MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 661M/4.98G [00:03<00:27, 158MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   2%|▎                  | 283M/16.1G [00:01<01:48, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 377M/4.92G [00:02<00:29, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  27%|█▌    | 315M/1.17G [00:02<00:05, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|▊     | 682M/4.98G [00:03<00:27, 156MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 776M/5.00G [00:03<00:25, 167MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   2%|▎                  | 304M/16.1G [00:02<01:41, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 398M/4.92G [00:02<00:27, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  29%|█▋    | 336M/1.17G [00:02<00:04, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|▊     | 703M/4.98G [00:03<00:26, 160MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 797M/5.00G [00:03<00:24, 169MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   2%|▍                  | 325M/16.1G [00:02<01:38, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   9%|▌     | 419M/4.92G [00:02<00:27, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  31%|█▊    | 357M/1.17G [00:02<00:04, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "special_tokens_map.json: 100%|████████████████| 73.0/73.0 [00:00<00:00, 736kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/special_tokens_map.json\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|▊     | 724M/4.98G [00:03<00:25, 164MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 818M/5.00G [00:03<00:24, 168MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   2%|▍                  | 346M/16.1G [00:02<01:34, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   9%|▌     | 440M/4.92G [00:02<00:26, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  32%|█▉    | 377M/1.17G [00:02<00:04, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer_config.json:   0%|                        | 0.00/51.0k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|████████████████| 51.0k/51.0k [00:00<00:00, 640kB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/tokenizer_config.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   2%|▍                  | 367M/16.1G [00:02<01:30, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  34%|██    | 398M/1.17G [00:02<00:04, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|█     | 849M/5.00G [00:04<00:23, 177MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   9%|▌     | 461M/4.92G [00:02<00:27, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|▉     | 765M/4.98G [00:03<00:24, 174MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   2%|▍                  | 388M/16.1G [00:02<01:27, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  36%|██▏   | 419M/1.17G [00:02<00:04, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|█     | 870M/5.00G [00:04<00:23, 178MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 482M/4.92G [00:02<00:27, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|▉     | 786M/4.98G [00:04<00:23, 179MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   3%|▍                  | 409M/16.1G [00:02<01:29, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  38%|██▎   | 440M/1.17G [00:02<00:04, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  18%|█     | 891M/5.00G [00:04<00:22, 180MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 503M/4.92G [00:03<00:28, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|▉     | 807M/4.98G [00:04<00:24, 172MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   3%|▌                  | 430M/16.1G [00:02<01:26, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  39%|██▎   | 461M/1.17G [00:02<00:03, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  18%|█     | 912M/5.00G [00:04<00:22, 185MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  11%|▋     | 535M/4.92G [00:03<00:24, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   3%|▌                  | 461M/16.1G [00:02<01:16, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  42%|██▌   | 493M/1.17G [00:02<00:03, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  19%|█▏    | 944M/5.00G [00:04<00:20, 200MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  11%|▋     | 556M/4.92G [00:03<00:23, 185MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   3%|▌                  | 493M/16.1G [00:02<01:12, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  45%|██▋   | 524M/1.17G [00:03<00:02, 218MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  19%|█▏    | 965M/5.00G [00:04<00:20, 199MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|▉     | 828M/4.98G [00:04<00:37, 112MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  12%|▋     | 587M/4.92G [00:03<00:22, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   3%|▌                  | 524M/16.1G [00:03<01:09, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  48%|██▊   | 556M/1.17G [00:03<00:02, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  20%|█▏    | 996M/5.00G [00:04<00:18, 211MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 619M/4.92G [00:03<00:20, 210MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   3%|▋                  | 556M/16.1G [00:03<01:10, 221MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  50%|███   | 587M/1.17G [00:03<00:02, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|█    | 1.03G/5.00G [00:04<00:18, 214MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 650M/4.92G [00:03<00:20, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|█    | 1.06G/5.00G [00:05<00:17, 222MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  53%|███▏  | 619M/1.17G [00:03<00:02, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|▊    | 849M/4.98G [00:04<00:50, 81.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   4%|▋                  | 587M/16.1G [00:03<01:23, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  14%|▊     | 682M/4.92G [00:03<00:19, 220MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  22%|█    | 1.09G/5.00G [00:05<00:17, 223MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  56%|███▎  | 650M/1.17G [00:03<00:02, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   4%|▋                  | 619M/16.1G [00:03<01:19, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  15%|▊     | 713M/4.92G [00:03<00:19, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  22%|█    | 1.12G/5.00G [00:05<00:17, 228MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  58%|███▌  | 682M/1.17G [00:03<00:02, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   4%|▊                  | 650M/16.1G [00:03<01:15, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  15%|▉     | 744M/4.92G [00:04<00:18, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  23%|█▏   | 1.15G/5.00G [00:05<00:16, 234MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|▊    | 870M/4.98G [00:05<00:54, 74.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  61%|███▋  | 713M/1.17G [00:03<00:02, 219MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   4%|▊                  | 682M/16.1G [00:03<01:15, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  16%|▉     | 776M/4.92G [00:04<00:18, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  24%|█▏   | 1.18G/5.00G [00:05<00:16, 237MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|▉    | 881M/4.98G [00:05<00:55, 73.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  64%|███▊  | 744M/1.17G [00:04<00:01, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   4%|▊                  | 703M/16.1G [00:04<01:15, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  16%|▉     | 807M/4.92G [00:04<00:18, 225MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  24%|█▏   | 1.22G/5.00G [00:05<00:16, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   5%|▊                  | 724M/16.1G [00:04<01:16, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  66%|███▉  | 776M/1.17G [00:04<00:01, 221MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  17%|█     | 839M/4.92G [00:04<00:18, 225MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  25%|█▏   | 1.25G/5.00G [00:05<00:16, 231MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|▉    | 891M/4.98G [00:05<01:03, 64.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   5%|▉                  | 744M/16.1G [00:04<01:19, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  69%|████▏ | 807M/1.17G [00:04<00:01, 222MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  18%|█     | 870M/4.92G [00:04<00:18, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  26%|█▎   | 1.28G/5.00G [00:05<00:16, 225MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   5%|▉                  | 765M/16.1G [00:04<01:20, 189MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  72%|████▎ | 839M/1.17G [00:04<00:01, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|▉    | 902M/4.98G [00:05<01:11, 57.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  26%|█▎   | 1.31G/5.00G [00:06<00:15, 232MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  18%|█     | 902M/4.92G [00:04<00:17, 225MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   5%|▉                  | 797M/16.1G [00:04<01:14, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  75%|████▍ | 870M/1.17G [00:04<00:01, 230MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|▉    | 912M/4.98G [00:06<01:07, 60.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   5%|▉                  | 818M/16.1G [00:04<01:17, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|█▎   | 1.34G/5.00G [00:06<00:15, 229MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  19%|█▏    | 933M/4.92G [00:04<00:17, 223MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  77%|████▋ | 902M/1.17G [00:04<00:01, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   5%|▉                  | 839M/16.1G [00:04<01:16, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|▉    | 923M/4.98G [00:06<01:03, 63.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|█▎   | 1.37G/5.00G [00:06<00:16, 221MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 965M/4.92G [00:05<00:18, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  80%|████▊ | 933M/1.17G [00:04<00:01, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   5%|█                  | 870M/16.1G [00:04<01:15, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  28%|█▍   | 1.41G/5.00G [00:06<00:15, 233MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 996M/4.92G [00:05<00:17, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  83%|████▉ | 965M/1.17G [00:05<00:00, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|▉    | 933M/4.98G [00:06<01:12, 55.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   6%|█                  | 902M/16.1G [00:05<01:12, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  29%|█▍   | 1.44G/5.00G [00:06<00:15, 237MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  21%|█    | 1.03G/4.92G [00:05<00:16, 235MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  85%|█████ | 996M/1.17G [00:05<00:00, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   6%|█                  | 923M/16.1G [00:05<01:13, 207MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|█    | 1.06G/4.92G [00:05<00:16, 236MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  29%|█▍   | 1.47G/5.00G [00:06<00:15, 231MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  88%|████▍| 1.03G/1.17G [00:05<00:00, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   6%|█▏                 | 954M/16.1G [00:05<01:12, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|█    | 1.09G/4.92G [00:05<00:15, 245MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  30%|█▍   | 1.50G/5.00G [00:06<00:14, 240MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|▉    | 954M/4.98G [00:06<01:06, 60.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  91%|████▌| 1.06G/1.17G [00:05<00:00, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   6%|█▏                 | 975M/16.1G [00:05<01:13, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  23%|█▏   | 1.12G/4.92G [00:05<00:16, 233MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  31%|█▌   | 1.53G/5.00G [00:07<00:14, 231MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  93%|████▋| 1.09G/1.17G [00:05<00:00, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   6%|█▏                | 1.01G/16.1G [00:05<01:08, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  23%|█▏   | 1.15G/4.92G [00:05<00:15, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  31%|█▌   | 1.56G/5.00G [00:07<00:14, 243MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  96%|████▊| 1.12G/1.17G [00:05<00:00, 244MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   6%|█▏                | 1.04G/16.1G [00:05<01:06, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  32%|█▌   | 1.59G/5.00G [00:07<00:13, 245MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|▉    | 975M/4.98G [00:07<01:09, 57.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  24%|█▏   | 1.18G/4.92G [00:06<00:16, 230MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  99%|████▉| 1.15G/1.17G [00:05<00:00, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   7%|█▏                | 1.07G/16.1G [00:05<01:02, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors: 100%|█████| 1.17G/1.17G [00:05<00:00, 199MB/s]\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/model-00004-of-00004.safetensors\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  25%|█▏   | 1.22G/4.92G [00:06<00:15, 234MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   7%|█▏                | 1.10G/16.1G [00:05<01:01, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  33%|█▋   | 1.66G/5.00G [00:07<00:12, 258MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  25%|█▎   | 1.25G/4.92G [00:06<00:14, 247MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   7%|█▎                | 1.13G/16.1G [00:05<00:59, 249MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|▉    | 986M/4.98G [00:07<01:19, 50.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  34%|█▋   | 1.69G/5.00G [00:07<00:12, 263MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  26%|█▎   | 1.28G/4.92G [00:06<00:14, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   7%|█▎                | 1.16G/16.1G [00:06<00:57, 257MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  34%|█▋   | 1.72G/5.00G [00:07<00:12, 268MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█    | 996M/4.98G [00:07<01:13, 54.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  27%|█▎   | 1.31G/4.92G [00:06<00:13, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   7%|█▎                | 1.20G/16.1G [00:06<00:55, 266MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  35%|█▊   | 1.75G/5.00G [00:07<00:12, 270MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  27%|█▎   | 1.34G/4.92G [00:06<00:13, 268MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|▊   | 1.01G/4.98G [00:07<01:08, 57.8MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.78G/5.00G [00:07<00:11, 273MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   8%|█▎                | 1.23G/16.1G [00:06<01:01, 240MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  28%|█▍   | 1.37G/4.92G [00:06<00:13, 264MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|▊   | 1.02G/4.98G [00:07<01:03, 62.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.81G/5.00G [00:08<00:11, 273MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   8%|█▍                | 1.26G/16.1G [00:06<01:03, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.41G/4.92G [00:06<00:13, 265MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  37%|█▊   | 1.85G/5.00G [00:08<00:11, 276MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.44G/4.92G [00:06<00:13, 265MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   8%|█▍                | 1.29G/16.1G [00:06<01:01, 239MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  38%|█▉   | 1.88G/5.00G [00:08<00:11, 283MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|▊   | 1.03G/4.98G [00:08<01:16, 51.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  30%|█▍   | 1.47G/4.92G [00:07<00:13, 255MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  38%|█▉   | 1.91G/5.00G [00:08<00:10, 282MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   8%|█▍                | 1.32G/16.1G [00:06<01:06, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.50G/4.92G [00:07<00:13, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.94G/5.00G [00:08<00:10, 285MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   8%|█▌                | 1.35G/16.1G [00:06<01:06, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.53G/4.92G [00:07<00:12, 264MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.97G/5.00G [00:08<00:10, 282MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   9%|█▌                | 1.38G/16.1G [00:07<01:02, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|▊   | 1.05G/4.98G [00:08<01:15, 52.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  40%|██   | 2.00G/5.00G [00:08<00:10, 284MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  32%|█▌   | 1.56G/4.92G [00:07<00:13, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   9%|█▌                | 1.42G/16.1G [00:07<00:59, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  41%|██   | 2.03G/5.00G [00:08<00:10, 286MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  32%|█▌   | 1.59G/4.92G [00:07<00:13, 248MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   9%|█▌                | 1.45G/16.1G [00:07<00:56, 257MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|▊   | 1.06G/4.98G [00:08<01:14, 52.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  41%|██   | 2.07G/5.00G [00:08<00:10, 287MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   9%|█▋                | 1.48G/16.1G [00:07<00:55, 265MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.63G/4.92G [00:07<00:13, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  42%|██   | 2.10G/5.00G [00:09<00:10, 288MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:   9%|█▋                | 1.51G/16.1G [00:07<00:56, 259MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  34%|█▋   | 1.66G/4.92G [00:07<00:13, 243MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 2.13G/5.00G [00:09<00:09, 288MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|▊   | 1.07G/4.98G [00:09<01:26, 45.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  10%|█▋                | 1.54G/16.1G [00:07<00:57, 252MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  34%|█▋   | 1.69G/4.92G [00:07<00:13, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 2.16G/5.00G [00:09<00:09, 289MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  35%|█▋   | 1.72G/4.92G [00:08<00:12, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  44%|██▏  | 2.19G/5.00G [00:09<00:09, 285MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  10%|█▊                | 1.57G/16.1G [00:07<00:58, 248MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|▊   | 1.08G/4.98G [00:09<01:26, 45.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  36%|█▊   | 1.75G/4.92G [00:08<00:11, 264MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  44%|██▏  | 2.22G/5.00G [00:09<00:09, 287MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  10%|█▊                | 1.60G/16.1G [00:07<01:02, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  36%|█▊   | 1.78G/4.92G [00:08<00:11, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  45%|██▎  | 2.25G/5.00G [00:09<00:09, 286MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  10%|█▊                | 1.64G/16.1G [00:08<01:02, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  37%|█▊   | 1.81G/4.92G [00:08<00:11, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  46%|██▎  | 2.29G/5.00G [00:09<00:09, 287MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  38%|█▉   | 1.85G/4.92G [00:08<00:11, 278MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  46%|██▎  | 2.32G/5.00G [00:09<00:09, 285MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  10%|█▊                | 1.67G/16.1G [00:08<01:04, 224MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|▉   | 1.09G/4.98G [00:09<01:45, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  38%|█▉   | 1.88G/4.92G [00:08<00:11, 274MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 2.35G/5.00G [00:09<00:09, 286MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  11%|█▉                | 1.70G/16.1G [00:08<01:05, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  48%|██▍  | 2.38G/5.00G [00:10<00:09, 289MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  39%|█▉   | 1.91G/4.92G [00:08<00:11, 269MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  11%|█▉                | 1.73G/16.1G [00:08<01:06, 217MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  48%|██▍  | 2.41G/5.00G [00:10<00:08, 291MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  39%|█▉   | 1.94G/4.92G [00:08<00:10, 271MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|▉   | 1.10G/4.98G [00:10<01:49, 35.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  49%|██▍  | 2.44G/5.00G [00:10<00:08, 290MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  11%|█▉                | 1.76G/16.1G [00:08<01:06, 217MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  40%|██   | 1.97G/4.92G [00:09<00:10, 270MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  49%|██▍  | 2.47G/5.00G [00:10<00:08, 290MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  41%|██   | 2.00G/4.92G [00:09<00:10, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  11%|██                | 1.79G/16.1G [00:08<01:04, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|▉   | 1.11G/4.98G [00:10<01:40, 38.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  50%|██▌  | 2.51G/5.00G [00:10<00:08, 284MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  41%|██   | 2.03G/4.92G [00:09<00:10, 271MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  11%|██                | 1.82G/16.1G [00:08<01:02, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.54G/5.00G [00:10<00:08, 283MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  42%|██   | 2.07G/4.92G [00:09<00:10, 278MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  12%|██                | 1.86G/16.1G [00:09<01:00, 233MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|▉   | 1.12G/4.98G [00:10<01:39, 38.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.57G/5.00G [00:10<00:08, 283MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  43%|██▏  | 2.10G/4.92G [00:09<00:10, 274MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  12%|██                | 1.89G/16.1G [00:09<00:59, 239MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|▉   | 1.14G/4.98G [00:10<01:02, 61.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  52%|██▌  | 2.60G/5.00G [00:10<00:08, 276MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  43%|██▏  | 2.13G/4.92G [00:09<00:10, 271MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|▉   | 1.16G/4.98G [00:10<00:45, 84.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  12%|██▏               | 1.92G/16.1G [00:09<00:57, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  53%|██▋  | 2.63G/5.00G [00:10<00:08, 271MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 2.16G/4.92G [00:09<00:10, 260MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|█▏   | 1.18G/4.98G [00:10<00:35, 107MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  12%|██▏               | 1.95G/16.1G [00:09<00:56, 249MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  53%|██▋  | 2.66G/5.00G [00:11<00:09, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  45%|██▏  | 2.19G/4.92G [00:09<00:10, 257MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|█▏   | 1.21G/4.98G [00:10<00:30, 125MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  12%|██▏               | 1.98G/16.1G [00:09<00:59, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  45%|██▎  | 2.22G/4.92G [00:09<00:10, 258MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  54%|██▋  | 2.69G/5.00G [00:11<00:10, 229MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|█▏   | 1.23G/4.98G [00:11<00:28, 131MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 2.25G/4.92G [00:10<00:10, 265MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  13%|██▎               | 2.01G/16.1G [00:09<01:04, 218MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  13%|██▎               | 2.04G/16.1G [00:09<00:59, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  55%|██▋  | 2.73G/5.00G [00:11<00:11, 196MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 2.29G/4.92G [00:10<00:10, 263MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  55%|██▋  | 2.75G/5.00G [00:11<00:11, 198MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  13%|██▎               | 2.08G/16.1G [00:09<00:58, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  47%|██▎  | 2.32G/4.92G [00:10<00:10, 258MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.78G/5.00G [00:11<00:10, 207MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  48%|██▍  | 2.35G/4.92G [00:10<00:09, 263MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|█   | 1.25G/4.98G [00:11<00:47, 78.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  48%|██▍  | 2.38G/4.92G [00:10<00:09, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.81G/5.00G [00:11<00:10, 217MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  49%|██▍  | 2.41G/4.92G [00:10<00:08, 280MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  13%|██▎               | 2.11G/16.1G [00:10<01:26, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.84G/5.00G [00:12<00:09, 218MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  50%|██▍  | 2.44G/4.92G [00:10<00:08, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|█   | 1.27G/4.98G [00:11<00:49, 75.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.87G/5.00G [00:12<00:09, 221MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  50%|██▌  | 2.47G/4.92G [00:10<00:08, 283MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  51%|██▌  | 2.51G/4.92G [00:10<00:08, 287MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  58%|██▉  | 2.90G/5.00G [00:12<00:09, 224MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  13%|██▍               | 2.13G/16.1G [00:10<02:01, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  52%|██▌  | 2.54G/4.92G [00:11<00:08, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  59%|██▉  | 2.94G/5.00G [00:12<00:10, 201MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  52%|██▌  | 2.57G/4.92G [00:11<00:08, 283MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|█   | 1.29G/4.98G [00:12<00:57, 64.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  59%|██▉  | 2.96G/5.00G [00:12<00:10, 202MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  53%|██▋  | 2.60G/4.92G [00:11<00:08, 287MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  13%|██▎              | 2.15G/16.1G [00:11<02:25, 95.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|██▉  | 2.98G/5.00G [00:12<00:10, 197MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|█   | 1.31G/4.98G [00:12<00:48, 75.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  54%|██▋  | 2.63G/4.92G [00:11<00:08, 284MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  54%|██▋  | 2.66G/4.92G [00:11<00:07, 286MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|███  | 3.01G/5.00G [00:12<00:09, 199MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|█   | 1.32G/4.98G [00:12<00:49, 74.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  14%|██▍               | 2.18G/16.1G [00:11<02:12, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  55%|██▋  | 2.69G/4.92G [00:11<00:07, 284MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  61%|███  | 3.03G/5.00G [00:12<00:10, 197MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  55%|██▊  | 2.73G/4.92G [00:11<00:07, 282MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  61%|███  | 3.05G/5.00G [00:13<00:11, 165MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  56%|██▊  | 2.76G/4.92G [00:11<00:07, 283MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|█   | 1.34G/4.98G [00:13<00:56, 64.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  61%|███  | 3.07G/5.00G [00:13<00:11, 161MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.79G/4.92G [00:11<00:07, 277MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  14%|██▎              | 2.20G/16.1G [00:11<02:56, 78.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.82G/4.92G [00:12<00:07, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  58%|██▉  | 2.85G/4.92G [00:12<00:07, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|███  | 3.09G/5.00G [00:13<00:14, 133MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  14%|██▌               | 2.23G/16.1G [00:11<02:14, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|█   | 1.35G/4.98G [00:13<01:03, 56.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  59%|██▉  | 2.88G/4.92G [00:12<00:07, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  14%|██▌               | 2.26G/16.1G [00:11<01:46, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|███  | 3.11G/5.00G [00:13<00:14, 127MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|█   | 1.36G/4.98G [00:13<01:01, 58.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  59%|██▉  | 2.92G/4.92G [00:12<00:07, 282MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  14%|██▌               | 2.30G/16.1G [00:12<01:27, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  63%|███▏ | 3.14G/5.00G [00:13<00:13, 134MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  60%|██▉  | 2.95G/4.92G [00:12<00:06, 284MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  14%|██▌               | 2.33G/16.1G [00:12<01:24, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  61%|███  | 2.98G/4.92G [00:12<00:06, 288MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  63%|███▏ | 3.17G/5.00G [00:13<00:11, 156MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|█   | 1.37G/4.98G [00:13<01:14, 48.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  61%|███  | 3.01G/4.92G [00:12<00:06, 292MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  64%|███▏ | 3.19G/5.00G [00:14<00:10, 166MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  62%|███  | 3.04G/4.92G [00:12<00:06, 293MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  15%|██▋               | 2.35G/16.1G [00:12<01:47, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  64%|███▏ | 3.21G/5.00G [00:14<00:11, 156MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  62%|███  | 3.07G/4.92G [00:12<00:06, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  15%|██▋               | 2.38G/16.1G [00:12<01:27, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  65%|███▏ | 3.23G/5.00G [00:14<00:11, 158MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|█   | 1.38G/4.98G [00:14<01:24, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  63%|███▏ | 3.10G/4.92G [00:13<00:06, 288MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  15%|██▋               | 2.40G/16.1G [00:12<01:25, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  65%|███▎ | 3.25G/5.00G [00:14<00:10, 166MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  64%|███▏ | 3.14G/4.92G [00:13<00:06, 287MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|█   | 1.39G/4.98G [00:14<01:15, 47.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  15%|██▋               | 2.43G/16.1G [00:12<01:12, 187MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  64%|███▏ | 3.17G/4.92G [00:13<00:06, 275MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  66%|███▎ | 3.28G/5.00G [00:14<00:09, 183MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  15%|██▊               | 2.46G/16.1G [00:13<01:05, 207MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|█▏  | 1.41G/4.98G [00:14<01:09, 51.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  65%|███▎ | 3.20G/4.92G [00:13<00:06, 278MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  66%|███▎ | 3.31G/5.00G [00:14<00:08, 196MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  16%|██▊               | 2.50G/16.1G [00:13<00:59, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  66%|███▎ | 3.23G/4.92G [00:13<00:06, 280MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.json: 100%|███████████████████████| 9.09M/9.09M [00:11<00:00, 786kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/tokenizer.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  16%|██▊               | 2.53G/16.1G [00:13<00:56, 240MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  67%|███▎ | 3.34G/5.00G [00:14<00:08, 189MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  66%|███▎ | 3.26G/4.92G [00:13<00:05, 280MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  16%|██▊               | 2.56G/16.1G [00:13<00:53, 254MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  67%|███▎ | 3.29G/4.92G [00:13<00:05, 283MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  16%|██▉               | 2.59G/16.1G [00:13<00:51, 263MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  67%|███▎ | 3.37G/5.00G [00:15<00:10, 157MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|█▏  | 1.42G/4.98G [00:14<01:35, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 3.32G/4.92G [00:13<00:05, 284MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 3.36G/4.92G [00:13<00:05, 287MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|█▏  | 1.44G/4.98G [00:15<01:06, 53.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  68%|███▍ | 3.39G/5.00G [00:15<00:11, 139MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  69%|███▍ | 3.39G/4.92G [00:14<00:05, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|█▏  | 1.45G/4.98G [00:15<00:59, 59.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  16%|██▉               | 2.62G/16.1G [00:13<01:24, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  70%|███▍ | 3.42G/4.92G [00:14<00:05, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  68%|███▍ | 3.41G/5.00G [00:15<00:11, 137MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  70%|███▌ | 3.45G/4.92G [00:14<00:05, 288MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|█▏  | 1.46G/4.98G [00:15<00:56, 62.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  17%|██▉               | 2.65G/16.1G [00:14<01:19, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.43G/5.00G [00:15<00:11, 138MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  71%|███▌ | 3.48G/4.92G [00:14<00:05, 274MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.45G/5.00G [00:15<00:10, 148MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  71%|███▌ | 3.51G/4.92G [00:14<00:05, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  17%|██▉               | 2.67G/16.1G [00:14<01:37, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.47G/5.00G [00:15<00:11, 138MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  72%|███▌ | 3.54G/4.92G [00:14<00:04, 277MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  73%|███▋ | 3.58G/4.92G [00:14<00:04, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  17%|███               | 2.69G/16.1G [00:14<01:42, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|█▏  | 1.48G/4.98G [00:15<01:09, 50.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  73%|███▋ | 3.61G/4.92G [00:14<00:04, 269MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  17%|███               | 2.73G/16.1G [00:14<01:23, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|█▏  | 1.49G/4.98G [00:16<01:00, 57.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  70%|███▍ | 3.49G/5.00G [00:16<00:14, 106MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  17%|███               | 2.76G/16.1G [00:14<01:11, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  74%|███▋ | 3.64G/4.92G [00:15<00:04, 264MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|█▏  | 1.50G/4.98G [00:16<00:58, 59.8MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  70%|███▌ | 3.51G/5.00G [00:16<00:13, 114MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  17%|███▏              | 2.79G/16.1G [00:14<01:04, 207MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  75%|███▋ | 3.67G/4.92G [00:15<00:04, 260MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|█▏  | 1.51G/4.98G [00:16<00:52, 66.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  71%|███▌ | 3.54G/5.00G [00:16<00:10, 142MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  18%|███▏              | 2.82G/16.1G [00:14<01:00, 218MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  75%|███▊ | 3.70G/4.92G [00:15<00:04, 249MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  18%|███▏              | 2.85G/16.1G [00:15<00:56, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  72%|███▌ | 3.58G/5.00G [00:16<00:08, 168MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  76%|███▊ | 3.73G/4.92G [00:15<00:04, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  18%|███▏              | 2.88G/16.1G [00:15<00:53, 248MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  72%|███▌ | 3.61G/5.00G [00:16<00:07, 188MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 3.76G/4.92G [00:15<00:04, 251MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|█▏  | 1.52G/4.98G [00:16<01:17, 44.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 3.80G/4.92G [00:15<00:04, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  73%|███▋ | 3.64G/5.00G [00:16<00:06, 196MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  73%|███▋ | 3.66G/5.00G [00:17<00:07, 189MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  18%|███▎              | 2.92G/16.1G [00:15<01:15, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|█▏  | 1.53G/4.98G [00:16<01:13, 47.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.68G/5.00G [00:17<00:06, 189MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.83G/4.92G [00:15<00:06, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.70G/5.00G [00:17<00:06, 193MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|█▏  | 1.54G/4.98G [00:17<01:10, 49.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.86G/4.92G [00:16<00:05, 199MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  18%|███▎              | 2.95G/16.1G [00:15<01:36, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.72G/5.00G [00:17<00:07, 176MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  79%|███▉ | 3.89G/4.92G [00:16<00:04, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  75%|███▋ | 3.74G/5.00G [00:17<00:06, 184MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  80%|███▉ | 3.92G/4.92G [00:16<00:04, 230MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 3.77G/5.00G [00:17<00:06, 197MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  80%|████ | 3.95G/4.92G [00:16<00:03, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  18%|███▎              | 2.97G/16.1G [00:16<01:57, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  81%|████ | 3.98G/4.92G [00:16<00:03, 259MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 3.81G/5.00G [00:17<00:05, 208MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|█▎  | 1.56G/4.98G [00:17<01:18, 43.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  82%|████ | 4.02G/4.92G [00:16<00:03, 269MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.84G/5.00G [00:17<00:05, 218MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  82%|████ | 4.05G/4.92G [00:16<00:03, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.87G/5.00G [00:18<00:04, 239MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|█▎  | 1.58G/4.98G [00:17<00:59, 56.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  19%|███▏             | 2.99G/16.1G [00:16<02:23, 90.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  83%|████▏| 4.08G/4.92G [00:16<00:03, 275MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  78%|███▉ | 3.90G/5.00G [00:18<00:04, 245MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|█▎  | 1.60G/4.98G [00:17<00:44, 75.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  84%|████▏| 4.11G/4.92G [00:16<00:02, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.93G/5.00G [00:18<00:04, 254MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|█▋   | 1.64G/4.98G [00:18<00:32, 102MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  84%|████▏| 4.14G/4.92G [00:17<00:02, 271MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.96G/5.00G [00:18<00:04, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  19%|███▏             | 3.01G/16.1G [00:16<02:41, 80.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|█▋   | 1.67G/4.98G [00:18<00:25, 132MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  85%|████▏| 4.17G/4.92G [00:17<00:02, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  80%|███▉ | 4.00G/5.00G [00:18<00:03, 254MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|█▋   | 1.70G/4.98G [00:18<00:20, 163MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  19%|███▏             | 3.02G/16.1G [00:16<02:47, 77.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  86%|████▎| 4.20G/4.92G [00:17<00:02, 272MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  81%|████ | 4.03G/5.00G [00:18<00:03, 264MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|█▋   | 1.72G/4.98G [00:18<00:19, 168MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  86%|████▎| 4.24G/4.92G [00:17<00:02, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  81%|████ | 4.06G/5.00G [00:18<00:03, 274MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  19%|███▏             | 3.04G/16.1G [00:17<02:29, 87.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|█▊   | 1.75G/4.98G [00:18<00:16, 191MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  82%|████ | 4.09G/5.00G [00:18<00:03, 277MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  87%|████▎| 4.27G/4.92G [00:17<00:02, 237MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  19%|███▍              | 3.06G/16.1G [00:17<02:08, 101MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.78G/4.98G [00:18<00:15, 212MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  82%|████ | 4.12G/5.00G [00:18<00:03, 278MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  19%|███▍              | 3.08G/16.1G [00:17<01:52, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  83%|████▏| 4.15G/5.00G [00:19<00:03, 281MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.81G/4.98G [00:18<00:15, 203MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  19%|███▍              | 3.10G/16.1G [00:17<01:37, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  87%|████▎| 4.30G/4.92G [00:17<00:03, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 4.18G/5.00G [00:19<00:02, 287MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|█▊   | 1.85G/4.98G [00:19<00:14, 217MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  20%|███▌              | 3.14G/16.1G [00:17<01:18, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 4.22G/5.00G [00:19<00:02, 286MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|█▉   | 1.88G/4.98G [00:19<00:13, 223MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  20%|███▌              | 3.17G/16.1G [00:17<01:07, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  85%|████▏| 4.25G/5.00G [00:19<00:02, 287MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|█▉   | 1.91G/4.98G [00:19<00:13, 224MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  86%|████▎| 4.28G/5.00G [00:19<00:02, 290MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  88%|████▍| 4.32G/4.92G [00:18<00:04, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  20%|███▌              | 3.20G/16.1G [00:17<01:08, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  39%|█▉   | 1.94G/4.98G [00:19<00:12, 235MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  86%|████▎| 4.31G/5.00G [00:19<00:02, 293MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  20%|███▌              | 3.22G/16.1G [00:18<01:14, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 4.34G/5.00G [00:19<00:02, 284MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|█▉   | 1.97G/4.98G [00:19<00:12, 231MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  88%|████▍| 4.34G/4.92G [00:18<00:05, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  20%|███▋              | 3.24G/16.1G [00:18<01:14, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 4.37G/5.00G [00:19<00:02, 222MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|██   | 2.00G/4.98G [00:19<00:14, 202MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  20%|███▋              | 3.26G/16.1G [00:18<01:19, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  89%|███▌| 4.36G/4.92G [00:18<00:05, 98.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  20%|███▋              | 3.28G/16.1G [00:18<01:31, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  88%|████▍| 4.40G/5.00G [00:20<00:03, 170MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|██   | 2.03G/4.98G [00:20<00:18, 160MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  89%|███▌| 4.38G/4.92G [00:19<00:05, 92.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▋              | 3.30G/16.1G [00:18<01:39, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.42G/5.00G [00:20<00:03, 148MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|██   | 2.06G/4.98G [00:20<00:20, 142MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  90%|███▌| 4.40G/4.92G [00:19<00:05, 86.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▋              | 3.32G/16.1G [00:18<01:52, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.45G/5.00G [00:20<00:04, 124MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.08G/4.98G [00:20<00:24, 117MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  90%|███▌| 4.41G/4.92G [00:19<00:05, 86.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  90%|███▌| 4.42G/4.92G [00:19<00:05, 84.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▌             | 3.34G/16.1G [00:19<02:07, 99.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.47G/5.00G [00:20<00:05, 105MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.10G/4.98G [00:20<00:27, 104MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  90%|███▌| 4.44G/4.92G [00:19<00:05, 83.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  90%|███▌| 4.45G/4.92G [00:19<00:05, 84.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|███▋| 4.46G/4.92G [00:19<00:05, 86.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▌             | 3.37G/16.1G [00:19<02:35, 81.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|███▌| 4.49G/5.00G [00:21<00:05, 90.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|█▋  | 2.12G/4.98G [00:21<00:32, 88.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|███▋| 4.47G/4.92G [00:20<00:05, 84.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▌             | 3.38G/16.1G [00:19<02:35, 81.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|█▋  | 2.13G/4.98G [00:21<00:34, 82.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|███▋| 4.48G/4.92G [00:20<00:05, 78.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▌             | 3.39G/16.1G [00:19<02:53, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|███▌| 4.51G/5.00G [00:21<00:06, 78.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|███▋| 4.49G/4.92G [00:20<00:05, 75.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|█▋  | 2.14G/4.98G [00:21<00:37, 75.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▌             | 3.40G/16.1G [00:20<03:06, 67.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|███▌| 4.52G/5.00G [00:21<00:06, 73.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|███▋| 4.50G/4.92G [00:20<00:06, 68.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|█▋  | 2.15G/4.98G [00:21<00:41, 68.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▌             | 3.41G/16.1G [00:20<03:17, 64.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|███▋| 4.51G/4.92G [00:20<00:05, 70.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|███▌| 4.53G/5.00G [00:22<00:07, 66.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|█▋  | 2.16G/4.98G [00:21<00:45, 62.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|███▋| 4.52G/4.92G [00:20<00:05, 72.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▌             | 3.42G/16.1G [00:20<03:28, 60.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|███▋| 4.53G/4.92G [00:20<00:04, 78.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|███▋| 4.54G/5.00G [00:22<00:07, 63.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|█▋  | 2.17G/4.98G [00:22<00:46, 60.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▋             | 3.43G/16.1G [00:20<03:36, 58.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|███▋| 4.54G/4.92G [00:21<00:05, 65.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|███▋| 4.55G/5.00G [00:22<00:07, 59.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|█▊  | 2.18G/4.98G [00:22<00:50, 55.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▋             | 3.44G/16.1G [00:20<03:51, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|███▋| 4.55G/4.92G [00:21<00:05, 68.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|███▋| 4.56G/5.00G [00:22<00:07, 55.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|█▊  | 2.19G/4.98G [00:22<00:52, 53.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|███▋| 4.56G/4.92G [00:21<00:05, 62.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  21%|███▋             | 3.45G/16.1G [00:21<04:06, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|███▋| 4.57G/5.00G [00:22<00:08, 52.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|█▊  | 2.20G/4.98G [00:22<00:53, 51.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|███▋| 4.57G/4.92G [00:21<00:06, 57.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▋             | 3.46G/16.1G [00:21<04:21, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|███▋| 4.58G/5.00G [00:23<00:08, 51.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|█▊  | 2.21G/4.98G [00:23<00:57, 48.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|███▋| 4.58G/4.92G [00:21<00:06, 52.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▋             | 3.47G/16.1G [00:21<04:24, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|███▋| 4.59G/5.00G [00:23<00:08, 48.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|█▊  | 2.22G/4.98G [00:23<00:57, 47.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|███▋| 4.59G/4.92G [00:22<00:06, 51.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▋             | 3.48G/16.1G [00:21<04:22, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|███▋| 4.60G/5.00G [00:23<00:08, 48.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|█▊  | 2.23G/4.98G [00:23<00:57, 47.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  94%|███▋| 4.60G/4.92G [00:22<00:06, 50.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▋             | 3.49G/16.1G [00:22<04:22, 47.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|███▋| 4.61G/5.00G [00:23<00:07, 48.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|█▊  | 2.24G/4.98G [00:23<00:56, 47.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  94%|███▊| 4.61G/4.92G [00:22<00:06, 50.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▋             | 3.50G/16.1G [00:22<04:20, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|███▋| 4.62G/5.00G [00:24<00:07, 48.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|█▊  | 2.25G/4.98G [00:23<00:55, 48.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  94%|███▊| 4.62G/4.92G [00:22<00:06, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▋             | 3.51G/16.1G [00:22<04:26, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  93%|███▋| 4.63G/5.00G [00:24<00:07, 46.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|█▊  | 2.26G/4.98G [00:24<00:55, 49.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  94%|███▊| 4.63G/4.92G [00:23<00:05, 49.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▋             | 3.52G/16.1G [00:22<04:24, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  93%|███▋| 4.65G/5.00G [00:24<00:07, 48.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|█▊  | 2.28G/4.98G [00:24<00:57, 47.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  94%|███▊| 4.65G/4.92G [00:23<00:05, 49.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▋             | 3.53G/16.1G [00:22<04:18, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  93%|███▋| 4.66G/5.00G [00:24<00:07, 48.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|█▊  | 2.29G/4.98G [00:24<00:56, 48.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  95%|███▊| 4.66G/4.92G [00:23<00:05, 49.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▊             | 3.54G/16.1G [00:23<04:16, 48.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  93%|███▋| 4.67G/5.00G [00:24<00:06, 49.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  95%|███▊| 4.67G/4.92G [00:23<00:04, 50.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|█▊  | 2.30G/4.98G [00:24<00:55, 48.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▊             | 3.55G/16.1G [00:23<04:22, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|███▋| 4.68G/5.00G [00:25<00:06, 50.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|█▊  | 2.31G/4.98G [00:24<00:53, 49.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  95%|███▊| 4.68G/4.92G [00:23<00:04, 49.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▊             | 3.57G/16.1G [00:23<04:14, 49.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|███▋| 4.69G/5.00G [00:25<00:06, 49.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|█▊  | 2.32G/4.98G [00:25<00:53, 49.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  95%|███▊| 4.69G/4.92G [00:24<00:04, 49.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▊             | 3.58G/16.1G [00:23<04:06, 50.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|███▊| 4.70G/5.00G [00:25<00:05, 51.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|█▊  | 2.33G/4.98G [00:25<00:52, 50.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  96%|███▊| 4.70G/4.92G [00:24<00:04, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▊             | 3.59G/16.1G [00:24<04:08, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|███▊| 4.71G/5.00G [00:25<00:05, 50.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|█▉  | 2.34G/4.98G [00:25<00:52, 50.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  96%|███▊| 4.71G/4.92G [00:24<00:04, 50.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▊             | 3.60G/16.1G [00:24<04:02, 51.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|███▊| 4.72G/5.00G [00:25<00:05, 51.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  96%|███▊| 4.72G/4.92G [00:24<00:03, 51.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|█▉  | 2.35G/4.98G [00:25<00:52, 50.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  22%|███▊             | 3.61G/16.1G [00:24<04:04, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  95%|███▊| 4.73G/5.00G [00:26<00:05, 50.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|█▉  | 2.36G/4.98G [00:25<00:50, 51.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  96%|███▊| 4.73G/4.92G [00:24<00:03, 50.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▊             | 3.62G/16.1G [00:24<04:07, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  95%|███▊| 4.74G/5.00G [00:26<00:05, 50.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|█▉  | 2.37G/4.98G [00:26<00:51, 50.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  96%|███▊| 4.74G/4.92G [00:25<00:03, 50.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▊             | 3.63G/16.1G [00:24<04:02, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  95%|███▊| 4.75G/5.00G [00:26<00:05, 49.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|███▊| 4.75G/4.92G [00:25<00:03, 49.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|█▉  | 2.38G/4.98G [00:26<00:55, 46.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▊             | 3.64G/16.1G [00:25<04:20, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  95%|███▊| 4.76G/5.00G [00:26<00:04, 50.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|███▊| 4.76G/4.92G [00:25<00:03, 50.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|█▉  | 2.39G/4.98G [00:26<00:51, 50.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▊             | 3.65G/16.1G [00:25<04:05, 50.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  95%|███▊| 4.77G/5.00G [00:26<00:04, 50.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|█▉  | 2.40G/4.98G [00:26<00:49, 51.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|███▉| 4.77G/4.92G [00:25<00:02, 50.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▊             | 3.66G/16.1G [00:25<04:07, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|███▊| 4.78G/5.00G [00:27<00:04, 49.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|█▉  | 2.41G/4.98G [00:27<00:50, 50.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|███▉| 4.78G/4.92G [00:25<00:02, 49.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.67G/16.1G [00:25<04:07, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|███▊| 4.79G/5.00G [00:27<00:04, 51.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|█▉  | 2.42G/4.98G [00:27<00:49, 51.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|███▉| 4.79G/4.92G [00:26<00:02, 51.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.68G/16.1G [00:25<03:57, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|███▊| 4.80G/5.00G [00:27<00:03, 53.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|█▉  | 2.43G/4.98G [00:27<00:47, 53.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  98%|███▉| 4.80G/4.92G [00:26<00:02, 53.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.69G/16.1G [00:26<03:42, 55.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|███▊| 4.81G/5.00G [00:27<00:03, 54.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|█▉  | 2.44G/4.98G [00:27<00:46, 54.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  98%|███▉| 4.81G/4.92G [00:26<00:01, 54.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.70G/16.1G [00:26<03:40, 56.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|███▊| 4.82G/5.00G [00:27<00:03, 56.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|█▉  | 2.45G/4.98G [00:27<00:45, 55.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  98%|███▉| 4.82G/4.92G [00:26<00:01, 55.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.71G/16.1G [00:26<03:38, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|███▊| 4.83G/5.00G [00:28<00:02, 57.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█▉  | 2.46G/4.98G [00:27<00:44, 56.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  98%|███▉| 4.83G/4.92G [00:26<00:01, 56.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.72G/16.1G [00:26<03:36, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|███▉| 4.84G/5.00G [00:28<00:02, 55.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█▉  | 2.47G/4.98G [00:28<00:43, 57.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  99%|███▉| 4.84G/4.92G [00:27<00:01, 56.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.73G/16.1G [00:26<03:41, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|███▉| 4.85G/5.00G [00:28<00:02, 56.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█▉  | 2.49G/4.98G [00:28<00:43, 57.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  99%|███▉| 4.85G/4.92G [00:27<00:01, 57.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.74G/16.1G [00:26<03:38, 56.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|███▉| 4.87G/5.00G [00:28<00:02, 57.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|██  | 2.50G/4.98G [00:28<00:43, 57.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  99%|███▉| 4.87G/4.92G [00:27<00:00, 57.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.75G/16.1G [00:27<03:36, 56.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|███▉| 4.88G/5.00G [00:28<00:02, 56.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|██  | 2.51G/4.98G [00:28<00:43, 56.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  99%|███▉| 4.88G/4.92G [00:27<00:00, 57.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  23%|███▉             | 3.76G/16.1G [00:27<03:34, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|███▉| 4.89G/5.00G [00:29<00:01, 57.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|██  | 2.52G/4.98G [00:28<00:43, 56.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  99%|███▉| 4.89G/4.92G [00:27<00:00, 56.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|███▉             | 3.77G/16.1G [00:27<03:33, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|███▉| 4.90G/5.00G [00:29<00:01, 57.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|██  | 2.53G/4.98G [00:29<00:43, 55.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors: 100%|███▉| 4.90G/4.92G [00:27<00:00, 56.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.79G/16.1G [00:27<03:39, 56.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|███▉| 4.91G/5.00G [00:29<00:01, 57.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|██  | 2.54G/4.98G [00:29<00:43, 56.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors: 100%|███▉| 4.91G/4.92G [00:28<00:00, 55.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.80G/16.1G [00:27<03:36, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|███▉| 4.92G/5.00G [00:29<00:01, 55.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors: 100%|████| 4.92G/4.92G [00:28<00:00, 53.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.81G/16.1G [00:28<03:41, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|██  | 2.55G/4.98G [00:29<00:50, 47.8MB/s]\u001b[A\u001b[A\n",
      "model-00003-of-00004.safetensors: 100%|█████| 4.92G/4.92G [00:28<00:00, 173MB/s]\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/model-00003-of-00004.safetensors\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.82G/16.1G [00:28<03:38, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  99%|███▉| 4.94G/5.00G [00:29<00:01, 55.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|██  | 2.56G/4.98G [00:29<00:56, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.83G/16.1G [00:28<03:42, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  99%|███▉| 4.95G/5.00G [00:30<00:00, 56.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|██  | 2.57G/4.98G [00:30<00:48, 49.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.84G/16.1G [00:28<03:38, 56.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  99%|███▉| 4.96G/5.00G [00:30<00:00, 55.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.85G/16.1G [00:28<03:42, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|██  | 2.58G/4.98G [00:30<00:55, 43.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  99%|███▉| 4.97G/5.00G [00:30<00:00, 55.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.86G/16.1G [00:29<03:38, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|███▉| 4.98G/5.00G [00:30<00:00, 54.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|██  | 2.59G/4.98G [00:30<00:57, 41.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.87G/16.1G [00:29<03:44, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|███▉| 4.99G/5.00G [00:30<00:00, 55.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████             | 3.88G/16.1G [00:29<03:30, 57.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|████| 5.00G/5.00G [00:31<00:00, 55.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors: 100%|█████| 5.00G/5.00G [00:31<00:00, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/model-00002-of-00004.safetensors\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|██  | 2.60G/4.98G [00:31<01:11, 33.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████▏            | 3.90G/16.1G [00:29<03:12, 63.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|██  | 2.61G/4.98G [00:31<00:58, 40.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████▏            | 3.91G/16.1G [00:29<03:09, 64.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|██  | 2.62G/4.98G [00:31<00:54, 43.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████▏            | 3.92G/16.1G [00:29<03:02, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  24%|████▏            | 3.93G/16.1G [00:30<03:03, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▏            | 3.94G/16.1G [00:30<03:04, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|██  | 2.63G/4.98G [00:31<01:08, 34.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▏            | 3.95G/16.1G [00:30<02:58, 67.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▏            | 3.96G/16.1G [00:30<03:00, 67.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|██  | 2.64G/4.98G [00:32<01:08, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▏            | 3.97G/16.1G [00:30<02:55, 68.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▏            | 3.98G/16.1G [00:30<02:57, 67.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▏            | 4.00G/16.1G [00:31<02:54, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▏            | 4.01G/16.1G [00:31<02:56, 68.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|██▏ | 2.65G/4.98G [00:32<01:27, 26.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▎            | 4.02G/16.1G [00:31<02:53, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|██▏ | 2.67G/4.98G [00:32<00:51, 44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|██▏ | 2.69G/4.98G [00:32<00:35, 64.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▎            | 4.03G/16.1G [00:31<02:56, 68.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▎            | 4.04G/16.1G [00:31<02:53, 69.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|██▏ | 2.72G/4.98G [00:33<00:33, 67.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▎            | 4.05G/16.1G [00:31<02:55, 68.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▎            | 4.06G/16.1G [00:31<02:52, 69.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▎            | 4.07G/16.1G [00:32<02:43, 73.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▎            | 4.08G/16.1G [00:32<02:35, 77.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  25%|████▎            | 4.09G/16.1G [00:32<02:29, 80.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|██▏ | 2.74G/4.98G [00:33<00:43, 51.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|██▏ | 2.76G/4.98G [00:33<00:33, 66.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▎            | 4.11G/16.1G [00:32<02:17, 86.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|██▏ | 2.78G/4.98G [00:34<00:26, 84.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▎            | 4.12G/16.1G [00:32<02:20, 84.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|██▎ | 2.80G/4.98G [00:34<00:23, 92.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.14G/16.1G [00:32<02:12, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|██▎ | 2.82G/4.98G [00:34<00:22, 95.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.15G/16.1G [00:33<02:13, 89.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.17G/16.1G [00:33<02:11, 90.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|██▎ | 2.84G/4.98G [00:34<00:25, 82.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|██▎ | 2.86G/4.98G [00:34<00:21, 99.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.19G/16.1G [00:33<02:08, 92.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.20G/16.1G [00:33<02:09, 91.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|██▎ | 2.88G/4.98G [00:35<00:21, 96.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.22G/16.1G [00:33<02:10, 90.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.23G/16.1G [00:33<02:08, 92.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.24G/16.1G [00:33<02:09, 91.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|██▎ | 2.90G/4.98G [00:35<00:23, 87.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  26%|████▍            | 4.25G/16.1G [00:34<02:12, 89.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|██▎ | 2.93G/4.98G [00:35<00:20, 98.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▌            | 4.27G/16.1G [00:34<02:08, 92.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|██▎ | 2.95G/4.98G [00:35<00:21, 95.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▌            | 4.28G/16.1G [00:34<02:08, 91.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▌            | 4.29G/16.1G [00:34<02:30, 78.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██▍ | 2.97G/4.98G [00:36<00:24, 82.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▌            | 4.31G/16.1G [00:34<02:03, 95.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▌            | 4.33G/16.1G [00:34<02:02, 95.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██▍ | 2.98G/4.98G [00:36<00:31, 62.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▌            | 4.34G/16.1G [00:35<02:04, 93.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▌            | 4.35G/16.1G [00:35<02:06, 92.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██▍ | 2.99G/4.98G [00:36<00:34, 57.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▋            | 4.37G/16.1G [00:35<02:04, 94.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██▍ | 3.00G/4.98G [00:36<00:36, 54.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▋            | 4.38G/16.1G [00:35<02:06, 92.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▋            | 4.39G/16.1G [00:35<02:07, 91.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██▍ | 3.01G/4.98G [00:37<00:39, 50.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  27%|████▋            | 4.41G/16.1G [00:35<02:04, 93.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▋            | 4.42G/16.1G [00:35<02:06, 92.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██▍ | 3.02G/4.98G [00:37<00:45, 43.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▋            | 4.45G/16.1G [00:36<02:03, 93.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██▍ | 3.03G/4.98G [00:37<00:38, 51.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▋            | 4.46G/16.1G [00:36<02:05, 92.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██▍ | 3.04G/4.98G [00:37<00:35, 54.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██▍ | 3.05G/4.98G [00:37<00:33, 57.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▋            | 4.48G/16.1G [00:36<02:02, 94.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▊            | 4.49G/16.1G [00:36<02:04, 92.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██▍ | 3.06G/4.98G [00:38<00:31, 60.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██▍ | 3.07G/4.98G [00:38<00:30, 62.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▊            | 4.51G/16.1G [00:36<02:02, 94.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▊            | 4.52G/16.1G [00:36<02:04, 92.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██▍ | 3.08G/4.98G [00:38<00:30, 61.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██▍ | 3.09G/4.98G [00:38<00:29, 63.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▊            | 4.54G/16.1G [00:37<02:02, 94.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  28%|████▊            | 4.56G/16.1G [00:37<02:00, 95.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██▌ | 3.11G/4.98G [00:38<00:26, 70.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██▌ | 3.12G/4.98G [00:39<00:26, 69.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  29%|████▊            | 4.58G/16.1G [00:37<01:59, 95.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██▌ | 3.14G/4.98G [00:39<00:29, 62.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  29%|████▊            | 4.60G/16.1G [00:37<01:54, 99.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██▌ | 3.15G/4.98G [00:39<00:28, 65.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  29%|█████▏            | 4.62G/16.1G [00:37<01:47, 107MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██▌ | 3.16G/4.98G [00:39<00:27, 65.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  29%|█████▏            | 4.65G/16.1G [00:38<01:36, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  29%|█████▏            | 4.67G/16.1G [00:38<01:28, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██▌ | 3.17G/4.98G [00:39<00:30, 59.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  29%|█████▎            | 4.69G/16.1G [00:38<01:24, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██▌ | 3.19G/4.98G [00:39<00:22, 81.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  29%|█████▎            | 4.71G/16.1G [00:38<01:19, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|███▏ | 3.22G/4.98G [00:40<00:14, 118MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  29%|█████▎            | 4.73G/16.1G [00:38<01:18, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|███▎ | 3.25G/4.98G [00:40<00:11, 148MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|███▎ | 3.28G/4.98G [00:40<00:09, 171MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████▎            | 4.75G/16.1G [00:38<01:29, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|███▎ | 3.31G/4.98G [00:40<00:09, 181MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████▎            | 4.77G/16.1G [00:39<01:34, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|███▎ | 3.34G/4.98G [00:40<00:08, 194MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████▎            | 4.79G/16.1G [00:39<01:39, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████▍            | 4.81G/16.1G [00:39<01:42, 110MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 3.38G/4.98G [00:40<00:11, 144MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 3.41G/4.98G [00:41<00:09, 169MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|███▍ | 3.43G/4.98G [00:41<00:09, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████            | 4.83G/16.1G [00:39<02:04, 90.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███▍ | 3.46G/4.98G [00:41<00:08, 185MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████▏           | 4.84G/16.1G [00:39<02:09, 86.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███▌ | 3.49G/4.98G [00:41<00:07, 207MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 3.52G/4.98G [00:41<00:06, 226MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████▏           | 4.85G/16.1G [00:40<02:16, 82.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 3.55G/4.98G [00:41<00:07, 184MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████▏           | 4.87G/16.1G [00:40<02:39, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 3.58G/4.98G [00:41<00:08, 156MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  30%|█████▏           | 4.89G/16.1G [00:40<02:34, 72.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 3.60G/4.98G [00:42<00:09, 151MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  31%|█████▏           | 4.91G/16.1G [00:40<01:59, 93.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███▋ | 3.62G/4.98G [00:42<00:08, 152MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  31%|█████▌            | 4.93G/16.1G [00:40<01:40, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███▋ | 3.64G/4.98G [00:42<00:08, 157MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  31%|█████▌            | 4.95G/16.1G [00:41<01:50, 100MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.66G/4.98G [00:42<00:08, 152MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.68G/4.98G [00:42<00:08, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.70G/4.98G [00:42<00:08, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███▋ | 3.72G/4.98G [00:42<00:07, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  31%|█████▎           | 4.97G/16.1G [00:41<02:23, 77.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███▊ | 3.74G/4.98G [00:43<00:07, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  31%|█████▎           | 4.99G/16.1G [00:41<01:59, 92.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  31%|█████▌            | 5.01G/16.1G [00:41<01:40, 110MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.76G/4.98G [00:43<00:07, 161MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  31%|█████▋            | 5.04G/16.1G [00:41<01:18, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.79G/4.98G [00:43<00:07, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  32%|█████▋            | 5.08G/16.1G [00:42<01:06, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.81G/4.98G [00:43<00:07, 156MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  32%|█████▋            | 5.10G/16.1G [00:42<01:03, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███▊ | 3.83G/4.98G [00:43<00:07, 157MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  32%|█████▋            | 5.12G/16.1G [00:42<01:00, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███▊ | 3.85G/4.98G [00:43<00:06, 162MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  32%|█████▊            | 5.15G/16.1G [00:42<00:54, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███▉ | 3.87G/4.98G [00:43<00:07, 153MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  32%|█████▊            | 5.18G/16.1G [00:42<00:56, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███▉ | 3.89G/4.98G [00:44<00:07, 150MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  32%|█████▊            | 5.21G/16.1G [00:42<00:54, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.91G/4.98G [00:44<00:07, 143MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.93G/4.98G [00:44<00:07, 138MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  33%|█████▊            | 5.23G/16.1G [00:42<01:18, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.95G/4.98G [00:44<00:07, 142MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  33%|█████▉            | 5.26G/16.1G [00:43<01:06, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|███▉ | 3.97G/4.98G [00:44<00:07, 139MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  33%|█████▉            | 5.30G/16.1G [00:43<00:59, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  33%|█████▉            | 5.33G/16.1G [00:43<00:52, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|████ | 4.00G/4.98G [00:44<00:08, 120MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  33%|██████            | 5.36G/16.1G [00:43<00:48, 219MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  34%|██████            | 5.39G/16.1G [00:43<00:45, 232MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████ | 4.02G/4.98G [00:45<00:08, 120MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  34%|██████            | 5.42G/16.1G [00:43<00:48, 221MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████ | 4.04G/4.98G [00:45<00:08, 117MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████ | 4.06G/4.98G [00:45<00:08, 114MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  34%|██████            | 5.45G/16.1G [00:44<01:02, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████ | 4.08G/4.98G [00:45<00:08, 109MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  34%|██████▏           | 5.47G/16.1G [00:44<01:11, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████ | 4.10G/4.98G [00:45<00:08, 109MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  34%|██████▏           | 5.49G/16.1G [00:44<01:17, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  34%|██████▏           | 5.52G/16.1G [00:44<01:17, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 4.12G/4.98G [00:46<00:07, 110MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  34%|██████▏           | 5.54G/16.1G [00:44<01:11, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 4.14G/4.98G [00:46<00:06, 127MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  35%|██████▏           | 5.56G/16.1G [00:44<01:12, 144MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.16G/4.98G [00:46<00:06, 122MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  35%|██████▎           | 5.58G/16.1G [00:45<01:16, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.18G/4.98G [00:46<00:06, 124MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  35%|██████▎           | 5.60G/16.1G [00:45<01:15, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.20G/4.98G [00:46<00:05, 132MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  35%|██████▎           | 5.62G/16.1G [00:45<01:15, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████▏| 4.23G/4.98G [00:46<00:05, 132MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  35%|██████▎           | 5.64G/16.1G [00:45<01:12, 144MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████▎| 4.25G/4.98G [00:46<00:05, 142MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  35%|██████▎           | 5.66G/16.1G [00:45<01:11, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████▎| 4.27G/4.98G [00:47<00:05, 139MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  35%|██████▎           | 5.68G/16.1G [00:45<01:13, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████▎| 4.29G/4.98G [00:47<00:04, 138MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  36%|██████▍           | 5.70G/16.1G [00:45<01:13, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 4.31G/4.98G [00:47<00:04, 136MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  36%|██████▍           | 5.73G/16.1G [00:46<01:14, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 4.33G/4.98G [00:47<00:04, 136MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  36%|██████▍           | 5.75G/16.1G [00:46<01:11, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 4.35G/4.98G [00:47<00:04, 140MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  36%|██████▍           | 5.77G/16.1G [00:46<01:13, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████▍| 4.37G/4.98G [00:47<00:04, 139MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  36%|██████▍           | 5.79G/16.1G [00:46<01:14, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████▍| 4.39G/4.98G [00:47<00:04, 136MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  36%|██████▌           | 5.81G/16.1G [00:46<01:14, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  89%|████▍| 4.41G/4.98G [00:48<00:04, 138MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  36%|██████▌           | 5.83G/16.1G [00:46<01:13, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  89%|████▍| 4.44G/4.98G [00:48<00:04, 134MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  36%|██████▌           | 5.85G/16.1G [00:46<01:16, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|████▍| 4.46G/4.98G [00:48<00:03, 134MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  37%|██████▌           | 5.87G/16.1G [00:47<01:16, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|████▍| 4.48G/4.98G [00:48<00:03, 131MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  37%|██████▌           | 5.89G/16.1G [00:47<01:11, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|████▌| 4.50G/4.98G [00:48<00:03, 142MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  37%|██████▋           | 5.91G/16.1G [00:47<01:09, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 4.52G/4.98G [00:48<00:03, 135MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  37%|██████▋           | 5.93G/16.1G [00:47<01:13, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 4.54G/4.98G [00:49<00:03, 137MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  37%|██████▋           | 5.96G/16.1G [00:47<01:11, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|████▌| 4.56G/4.98G [00:49<00:02, 141MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  37%|██████▋           | 5.98G/16.1G [00:47<01:13, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|████▌| 4.58G/4.98G [00:49<00:02, 140MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  37%|██████▋           | 6.00G/16.1G [00:47<01:11, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|████▌| 4.60G/4.98G [00:49<00:02, 141MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  37%|██████▋           | 6.02G/16.1G [00:48<01:12, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|████▋| 4.62G/4.98G [00:49<00:02, 137MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  38%|██████▊           | 6.04G/16.1G [00:48<01:14, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|████▋| 4.65G/4.98G [00:49<00:02, 134MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  38%|██████▊           | 6.06G/16.1G [00:48<01:13, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|████▋| 4.67G/4.98G [00:49<00:02, 133MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  38%|██████▊           | 6.08G/16.1G [00:48<01:13, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|████▋| 4.69G/4.98G [00:50<00:02, 137MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  38%|██████▊           | 6.10G/16.1G [00:48<01:13, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|████▋| 4.71G/4.98G [00:50<00:01, 138MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  38%|██████▊           | 6.12G/16.1G [00:48<01:13, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|████▊| 4.73G/4.98G [00:50<00:01, 133MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  38%|██████▉           | 6.14G/16.1G [00:49<01:12, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|████▊| 4.75G/4.98G [00:50<00:01, 136MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  38%|██████▉           | 6.17G/16.1G [00:49<01:12, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  96%|████▊| 4.77G/4.98G [00:50<00:01, 136MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  39%|██████▉           | 6.19G/16.1G [00:49<01:14, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  96%|████▊| 4.79G/4.98G [00:50<00:01, 129MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  39%|██████▉           | 6.21G/16.1G [00:49<01:13, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  39%|██████▉           | 6.23G/16.1G [00:49<01:11, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  97%|████▊| 4.81G/4.98G [00:51<00:01, 103MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  39%|███████           | 6.25G/16.1G [00:49<01:07, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  97%|████▊| 4.84G/4.98G [00:51<00:00, 134MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  39%|███████           | 6.27G/16.1G [00:49<01:05, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  98%|████▉| 4.88G/4.98G [00:51<00:00, 163MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  39%|███████           | 6.29G/16.1G [00:50<01:10, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  98%|████▉| 4.90G/4.98G [00:51<00:00, 148MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  39%|███████           | 6.31G/16.1G [00:50<01:13, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  99%|████▉| 4.92G/4.98G [00:51<00:00, 143MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  39%|███████           | 6.33G/16.1G [00:50<01:14, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  99%|████▉| 4.94G/4.98G [00:51<00:00, 141MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  40%|███████           | 6.35G/16.1G [00:50<01:10, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors: 100%|████▉| 4.96G/4.98G [00:52<00:00, 144MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  40%|███████▏          | 6.38G/16.1G [00:50<01:09, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors: 100%|████| 4.98G/4.98G [00:52<00:00, 95.2MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/model-00001-of-00004.safetensors\n",
      "Fetching 17 files:  41%|██████████▎              | 7/17 [00:52<01:28,  8.84s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  40%|███████▏          | 6.40G/16.1G [00:50<01:08, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  40%|███████▏          | 6.42G/16.1G [00:51<01:05, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  40%|███████▏          | 6.44G/16.1G [00:51<01:03, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  40%|███████▏          | 6.46G/16.1G [00:51<01:03, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  40%|███████▎          | 6.48G/16.1G [00:51<01:02, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  40%|███████▎          | 6.50G/16.1G [00:51<01:01, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  41%|███████▎          | 6.52G/16.1G [00:51<01:01, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  41%|███████▎          | 6.54G/16.1G [00:51<00:59, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  41%|███████▎          | 6.56G/16.1G [00:51<00:59, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  41%|███████▍          | 6.59G/16.1G [00:52<01:00, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  41%|███████▍          | 6.61G/16.1G [00:52<01:00, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  41%|███████▍          | 6.63G/16.1G [00:52<00:59, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  41%|███████▍          | 6.65G/16.1G [00:52<00:58, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  42%|███████▍          | 6.67G/16.1G [00:52<00:59, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  42%|███████▍          | 6.69G/16.1G [00:52<00:58, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  42%|███████▌          | 6.71G/16.1G [00:52<00:57, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  42%|███████▌          | 6.73G/16.1G [00:53<01:22, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  42%|███████▌          | 6.76G/16.1G [00:53<01:03, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  42%|███████▌          | 6.79G/16.1G [00:53<00:56, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  42%|███████▋          | 6.82G/16.1G [00:53<00:56, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▋          | 6.84G/16.1G [00:53<01:16, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▋          | 6.86G/16.1G [00:54<01:29, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▎         | 6.88G/16.1G [00:54<01:50, 83.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▎         | 6.89G/16.1G [00:54<01:53, 81.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▎         | 6.91G/16.1G [00:54<01:40, 90.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▎         | 6.92G/16.1G [00:54<01:39, 92.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▎         | 6.93G/16.1G [00:55<01:45, 86.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▎         | 6.94G/16.1G [00:55<02:00, 75.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▎         | 6.95G/16.1G [00:55<02:12, 68.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▎         | 6.96G/16.1G [00:55<02:13, 68.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  43%|███████▍         | 6.98G/16.1G [00:55<01:52, 80.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  44%|███████▍         | 7.00G/16.1G [00:56<01:38, 92.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  44%|███████▊          | 7.03G/16.1G [00:56<01:19, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  44%|███████▍         | 7.05G/16.1G [00:56<01:47, 83.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  44%|███████▍         | 7.06G/16.1G [00:56<01:47, 83.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  44%|███████▍         | 7.07G/16.1G [00:56<02:04, 72.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  44%|███████▍         | 7.08G/16.1G [00:57<02:03, 72.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  44%|███████▌         | 7.10G/16.1G [00:57<01:33, 95.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  44%|███████▉          | 7.13G/16.1G [00:57<01:09, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  45%|████████          | 7.16G/16.1G [00:57<00:55, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  45%|████████          | 7.19G/16.1G [00:57<00:46, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  45%|████████          | 7.22G/16.1G [00:57<00:40, 218MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  45%|████████▏         | 7.26G/16.1G [00:57<00:36, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  45%|████████▏         | 7.29G/16.1G [00:57<00:35, 250MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  46%|████████▏         | 7.32G/16.1G [00:57<00:33, 258MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  46%|████████▏         | 7.35G/16.1G [00:58<00:32, 267MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  46%|████████▎         | 7.38G/16.1G [00:58<00:31, 273MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  46%|████████▎         | 7.41G/16.1G [00:58<00:31, 279MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  46%|████████▎         | 7.44G/16.1G [00:58<00:30, 280MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  47%|████████▍         | 7.48G/16.1G [00:58<00:30, 280MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  47%|████████▍         | 7.51G/16.1G [00:58<00:30, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  47%|████████▍         | 7.54G/16.1G [00:58<00:30, 279MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  47%|████████▍         | 7.57G/16.1G [00:58<00:30, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  47%|████████▌         | 7.60G/16.1G [00:58<00:30, 279MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  48%|████████▌         | 7.63G/16.1G [00:59<00:30, 278MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  48%|████████▌         | 7.67G/16.1G [00:59<00:29, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  48%|████████▋         | 7.70G/16.1G [00:59<00:29, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  48%|████████▋         | 7.73G/16.1G [00:59<00:29, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  48%|████████▋         | 7.76G/16.1G [00:59<00:29, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  49%|████████▋         | 7.79G/16.1G [00:59<00:29, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  49%|████████▊         | 7.82G/16.1G [00:59<00:28, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  49%|████████▊         | 7.85G/16.1G [00:59<00:28, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  49%|████████▊         | 7.89G/16.1G [00:59<00:29, 275MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  49%|████████▊         | 7.92G/16.1G [01:00<00:29, 277MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  49%|████████▉         | 7.95G/16.1G [01:00<00:28, 280MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  50%|████████▉         | 7.98G/16.1G [01:00<00:28, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  50%|████████▉         | 8.01G/16.1G [01:00<00:28, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  50%|█████████         | 8.04G/16.1G [01:00<00:28, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  50%|█████████         | 8.07G/16.1G [01:00<00:28, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  50%|█████████         | 8.11G/16.1G [01:00<00:28, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  51%|█████████         | 8.14G/16.1G [01:00<00:27, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  51%|█████████▏        | 8.17G/16.1G [01:00<00:27, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  51%|█████████▏        | 8.20G/16.1G [01:01<00:27, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  51%|█████████▏        | 8.23G/16.1G [01:01<00:27, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  51%|█████████▎        | 8.26G/16.1G [01:01<00:27, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  52%|█████████▎        | 8.29G/16.1G [01:01<00:27, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  52%|█████████▎        | 8.33G/16.1G [01:01<00:26, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  52%|█████████▎        | 8.36G/16.1G [01:01<00:26, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  52%|█████████▍        | 8.39G/16.1G [01:01<00:26, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  52%|█████████▍        | 8.42G/16.1G [01:01<00:26, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  53%|█████████▍        | 8.45G/16.1G [01:01<00:26, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  53%|█████████▌        | 8.48G/16.1G [01:02<00:26, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  53%|█████████▌        | 8.51G/16.1G [01:02<00:26, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  53%|█████████▌        | 8.55G/16.1G [01:02<00:26, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  53%|█████████▌        | 8.58G/16.1G [01:02<00:26, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  54%|█████████▋        | 8.61G/16.1G [01:02<00:26, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  54%|█████████▋        | 8.64G/16.1G [01:02<00:26, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  54%|█████████▋        | 8.67G/16.1G [01:02<00:25, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  54%|█████████▊        | 8.70G/16.1G [01:02<00:26, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  54%|█████████▊        | 8.73G/16.1G [01:02<00:25, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  55%|█████████▊        | 8.77G/16.1G [01:03<00:25, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  55%|█████████▊        | 8.80G/16.1G [01:03<00:25, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  55%|█████████▉        | 8.83G/16.1G [01:03<00:25, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  55%|█████████▉        | 8.86G/16.1G [01:03<00:25, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  55%|█████████▉        | 8.89G/16.1G [01:03<00:25, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  56%|██████████        | 8.92G/16.1G [01:03<00:24, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  56%|██████████        | 8.95G/16.1G [01:03<00:24, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  56%|██████████        | 8.99G/16.1G [01:03<00:24, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  56%|██████████        | 9.02G/16.1G [01:03<00:24, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  56%|██████████▏       | 9.05G/16.1G [01:04<00:24, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  57%|██████████▏       | 9.08G/16.1G [01:04<00:24, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  57%|██████████▏       | 9.11G/16.1G [01:04<00:24, 280MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  57%|██████████▏       | 9.14G/16.1G [01:04<00:24, 279MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  57%|██████████▎       | 9.18G/16.1G [01:04<00:24, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  57%|██████████▎       | 9.21G/16.1G [01:04<00:24, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  58%|██████████▎       | 9.24G/16.1G [01:04<00:24, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  58%|██████████▍       | 9.27G/16.1G [01:04<00:24, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  58%|██████████▍       | 9.30G/16.1G [01:04<00:23, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  58%|██████████▍       | 9.33G/16.1G [01:05<00:23, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  58%|██████████▍       | 9.36G/16.1G [01:05<00:23, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  58%|██████████▌       | 9.40G/16.1G [01:05<00:23, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  59%|██████████▌       | 9.43G/16.1G [01:05<00:22, 289MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  59%|██████████▌       | 9.46G/16.1G [01:05<00:22, 289MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  59%|██████████▋       | 9.49G/16.1G [01:05<00:22, 289MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  59%|██████████▋       | 9.52G/16.1G [01:05<00:22, 289MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  59%|██████████▋       | 9.55G/16.1G [01:05<00:22, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  60%|██████████▋       | 9.58G/16.1G [01:05<00:22, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  60%|██████████▊       | 9.62G/16.1G [01:06<00:22, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  60%|██████████▊       | 9.65G/16.1G [01:06<00:22, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  60%|██████████▊       | 9.68G/16.1G [01:06<00:22, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  60%|██████████▉       | 9.71G/16.1G [01:06<00:22, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  61%|██████████▉       | 9.74G/16.1G [01:06<00:22, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  61%|██████████▉       | 9.77G/16.1G [01:06<00:22, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  61%|██████████▉       | 9.80G/16.1G [01:06<00:21, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  61%|███████████       | 9.84G/16.1G [01:06<00:21, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  61%|███████████       | 9.87G/16.1G [01:06<00:22, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  62%|███████████       | 9.90G/16.1G [01:07<00:22, 280MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  62%|███████████▏      | 9.93G/16.1G [01:07<00:33, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  62%|███████████▏      | 9.96G/16.1G [01:07<00:31, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  62%|███████████▏      | 9.99G/16.1G [01:07<00:28, 211MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  62%|███████████▏      | 10.0G/16.1G [01:07<00:42, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  63%|███████████▎      | 10.0G/16.1G [01:08<00:47, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  63%|███████████▎      | 10.1G/16.1G [01:08<00:59, 101MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  63%|███████████▎      | 10.1G/16.1G [01:08<00:52, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  63%|███████████▎      | 10.1G/16.1G [01:08<00:47, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  63%|███████████▎      | 10.1G/16.1G [01:09<00:52, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  63%|███████████▍      | 10.2G/16.1G [01:09<00:40, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  63%|███████████▍      | 10.2G/16.1G [01:09<00:33, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  64%|███████████▍      | 10.2G/16.1G [01:09<00:34, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  64%|██████████▊      | 10.2G/16.1G [01:10<01:10, 82.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  64%|██████████▉      | 10.3G/16.1G [01:10<01:03, 91.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  64%|██████████▉      | 10.3G/16.1G [01:10<01:12, 79.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  64%|██████████▉      | 10.3G/16.1G [01:10<01:10, 81.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  64%|██████████▉      | 10.3G/16.1G [01:11<00:58, 97.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  65%|███████████▌      | 10.4G/16.1G [01:11<00:50, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  65%|███████████▋      | 10.4G/16.1G [01:11<00:47, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  65%|███████████▋      | 10.4G/16.1G [01:11<00:37, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  65%|███████████▋      | 10.4G/16.1G [01:11<00:39, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  65%|███████████▋      | 10.5G/16.1G [01:11<00:36, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  65%|███████████▊      | 10.5G/16.1G [01:11<00:36, 152MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  65%|███████████▊      | 10.5G/16.1G [01:12<00:31, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  66%|███████████▊      | 10.5G/16.1G [01:12<00:32, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  66%|███████████▊      | 10.6G/16.1G [01:12<00:28, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  66%|███████████▉      | 10.6G/16.1G [01:12<00:38, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  66%|███████████▉      | 10.6G/16.1G [01:12<00:45, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  66%|███████████▎     | 10.6G/16.1G [01:13<00:59, 90.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  66%|███████████▎     | 10.7G/16.1G [01:13<01:06, 80.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  67%|███████████▉      | 10.7G/16.1G [01:13<00:50, 107MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  67%|███████████▎     | 10.7G/16.1G [01:14<01:05, 81.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  67%|███████████▎     | 10.7G/16.1G [01:14<01:09, 76.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  67%|███████████▍     | 10.7G/16.1G [01:14<01:09, 75.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  67%|████████████      | 10.8G/16.1G [01:14<00:48, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  67%|███████████▍     | 10.8G/16.1G [01:15<00:54, 96.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  67%|████████████▏     | 10.8G/16.1G [01:15<00:41, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  68%|███████████▍     | 10.9G/16.1G [01:15<01:04, 81.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  68%|███████████▌     | 10.9G/16.1G [01:16<01:14, 69.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  68%|███████████▌     | 10.9G/16.1G [01:16<01:01, 84.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  68%|████████████▏     | 10.9G/16.1G [01:16<00:45, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  68%|████████████▎     | 11.0G/16.1G [01:16<00:36, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  68%|████████████▎     | 11.0G/16.1G [01:16<00:29, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  69%|████████████▎     | 11.0G/16.1G [01:16<00:25, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  69%|████████████▍     | 11.1G/16.1G [01:16<00:23, 217MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  69%|████████████▍     | 11.1G/16.1G [01:16<00:21, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  69%|████████████▍     | 11.1G/16.1G [01:17<00:19, 250MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  69%|████████████▍     | 11.1G/16.1G [01:17<00:19, 258MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  70%|████████████▌     | 11.2G/16.1G [01:17<00:18, 266MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  70%|████████████▌     | 11.2G/16.1G [01:17<00:17, 273MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  70%|████████████▌     | 11.2G/16.1G [01:17<00:17, 275MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  70%|████████████▋     | 11.3G/16.1G [01:17<00:17, 279MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  70%|████████████▋     | 11.3G/16.1G [01:17<00:17, 280MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  71%|████████████▋     | 11.3G/16.1G [01:17<00:16, 280MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  71%|████████████▋     | 11.4G/16.1G [01:17<00:16, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  71%|████████████▊     | 11.4G/16.1G [01:18<00:16, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  71%|████████████▊     | 11.4G/16.1G [01:18<00:16, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  71%|████████████▊     | 11.5G/16.1G [01:18<00:16, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  72%|████████████▉     | 11.5G/16.1G [01:18<00:16, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  72%|████████████▉     | 11.5G/16.1G [01:18<00:15, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  72%|████████████▉     | 11.6G/16.1G [01:18<00:15, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  72%|████████████▉     | 11.6G/16.1G [01:18<00:15, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  72%|█████████████     | 11.6G/16.1G [01:18<00:15, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  73%|█████████████     | 11.6G/16.1G [01:18<00:15, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  73%|█████████████     | 11.7G/16.1G [01:19<00:15, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  73%|█████████████▏    | 11.7G/16.1G [01:19<00:15, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  73%|█████████████▏    | 11.7G/16.1G [01:19<00:15, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  73%|█████████████▏    | 11.8G/16.1G [01:19<00:15, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  74%|█████████████▏    | 11.8G/16.1G [01:19<00:14, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  74%|█████████████▎    | 11.8G/16.1G [01:19<00:14, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  74%|█████████████▎    | 11.9G/16.1G [01:19<00:14, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  74%|█████████████▎    | 11.9G/16.1G [01:19<00:14, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  74%|█████████████▎    | 11.9G/16.1G [01:19<00:14, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  74%|█████████████▍    | 12.0G/16.1G [01:20<00:14, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  75%|█████████████▍    | 12.0G/16.1G [01:20<00:14, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  75%|█████████████▍    | 12.0G/16.1G [01:20<00:14, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  75%|█████████████▌    | 12.1G/16.1G [01:20<00:14, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  75%|█████████████▌    | 12.1G/16.1G [01:20<00:14, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  75%|█████████████▌    | 12.1G/16.1G [01:20<00:14, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  76%|█████████████▌    | 12.2G/16.1G [01:20<00:13, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  76%|█████████████▋    | 12.2G/16.1G [01:20<00:13, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  76%|█████████████▋    | 12.2G/16.1G [01:20<00:13, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  76%|█████████████▋    | 12.2G/16.1G [01:21<00:13, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  76%|█████████████▊    | 12.3G/16.1G [01:21<00:13, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  77%|█████████████▊    | 12.3G/16.1G [01:21<00:13, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  77%|█████████████▊    | 12.3G/16.1G [01:21<00:13, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  77%|█████████████▊    | 12.4G/16.1G [01:21<00:12, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  77%|█████████████▉    | 12.4G/16.1G [01:21<00:13, 275MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  77%|█████████████▉    | 12.4G/16.1G [01:21<00:13, 279MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  78%|█████████████▉    | 12.5G/16.1G [01:21<00:12, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  78%|██████████████    | 12.5G/16.1G [01:21<00:12, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  78%|██████████████    | 12.5G/16.1G [01:22<00:12, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  78%|██████████████    | 12.6G/16.1G [01:22<00:12, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  78%|██████████████    | 12.6G/16.1G [01:22<00:13, 263MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  79%|██████████████▏   | 12.6G/16.1G [01:22<00:14, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  79%|██████████████▏   | 12.7G/16.1G [01:22<00:13, 248MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  79%|██████████████▏   | 12.7G/16.1G [01:22<00:13, 257MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  79%|██████████████▎   | 12.7G/16.1G [01:22<00:12, 266MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  79%|██████████████▎   | 12.8G/16.1G [01:22<00:12, 268MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  80%|██████████████▎   | 12.8G/16.1G [01:22<00:12, 271MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  80%|██████████████▎   | 12.8G/16.1G [01:23<00:11, 275MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  80%|██████████████▍   | 12.8G/16.1G [01:23<00:11, 275MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  80%|██████████████▍   | 12.9G/16.1G [01:23<00:11, 272MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  80%|██████████████▍   | 12.9G/16.1G [01:23<00:11, 268MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  81%|██████████████▌   | 12.9G/16.1G [01:23<00:11, 267MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  81%|██████████████▌   | 13.0G/16.1G [01:23<00:11, 260MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  81%|██████████████▌   | 13.0G/16.1G [01:23<00:11, 262MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  81%|██████████████▌   | 13.0G/16.1G [01:23<00:11, 264MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  81%|██████████████▋   | 13.1G/16.1G [01:24<00:11, 265MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  82%|██████████████▋   | 13.1G/16.1G [01:24<00:11, 263MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  82%|██████████████▋   | 13.1G/16.1G [01:24<00:11, 263MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  82%|██████████████▋   | 13.2G/16.1G [01:24<00:10, 265MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  82%|██████████████▊   | 13.2G/16.1G [01:24<00:10, 266MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  82%|██████████████▊   | 13.2G/16.1G [01:24<00:10, 268MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  83%|██████████████▊   | 13.3G/16.1G [01:24<00:10, 270MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  83%|██████████████▉   | 13.3G/16.1G [01:24<00:10, 257MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  83%|██████████████▉   | 13.3G/16.1G [01:25<00:10, 258MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  83%|██████████████▉   | 13.3G/16.1G [01:25<00:10, 259MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  83%|██████████████▉   | 13.4G/16.1G [01:25<00:10, 264MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  84%|███████████████   | 13.4G/16.1G [01:25<00:10, 251MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  84%|███████████████   | 13.4G/16.1G [01:25<00:13, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  84%|███████████████   | 13.5G/16.1G [01:25<00:11, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  84%|███████████████▏  | 13.5G/16.1G [01:25<00:11, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  84%|███████████████▏  | 13.5G/16.1G [01:25<00:10, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  84%|███████████████▏  | 13.6G/16.1G [01:26<00:10, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  85%|███████████████▏  | 13.6G/16.1G [01:26<00:12, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  85%|███████████████▎  | 13.6G/16.1G [01:26<00:20, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  85%|██████████████▍  | 13.7G/16.1G [01:27<00:24, 98.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  85%|███████████████▎  | 13.7G/16.1G [01:27<00:22, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  85%|███████████████▎  | 13.7G/16.1G [01:27<00:20, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  85%|███████████████▍  | 13.7G/16.1G [01:27<00:21, 107MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  86%|███████████████▍  | 13.7G/16.1G [01:28<00:22, 101MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  86%|███████████████▍  | 13.8G/16.1G [01:28<00:22, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  86%|██████████████▌  | 13.8G/16.1G [01:28<00:24, 93.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  86%|██████████████▌  | 13.8G/16.1G [01:28<00:27, 80.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  86%|██████████████▌  | 13.8G/16.1G [01:28<00:28, 78.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  86%|██████████████▋  | 13.8G/16.1G [01:29<00:31, 72.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  86%|██████████████▋  | 13.8G/16.1G [01:29<00:24, 91.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  86%|███████████████▌  | 13.9G/16.1G [01:29<00:17, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  87%|███████████████▌  | 13.9G/16.1G [01:29<00:15, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  87%|███████████████▌  | 13.9G/16.1G [01:29<00:16, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  87%|███████████████▋  | 13.9G/16.1G [01:30<00:20, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  87%|███████████████▋  | 14.0G/16.1G [01:30<00:20, 104MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  87%|███████████████▋  | 14.0G/16.1G [01:30<00:16, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  87%|███████████████▋  | 14.0G/16.1G [01:30<00:13, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  88%|███████████████▊  | 14.1G/16.1G [01:30<00:10, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  88%|███████████████▊  | 14.1G/16.1G [01:30<00:09, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  88%|███████████████▊  | 14.1G/16.1G [01:30<00:08, 222MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  88%|███████████████▊  | 14.2G/16.1G [01:30<00:08, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  88%|███████████████▉  | 14.2G/16.1G [01:31<00:10, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  89%|███████████████▉  | 14.2G/16.1G [01:31<00:10, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  89%|███████████████▉  | 14.3G/16.1G [01:31<00:09, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  89%|████████████████  | 14.3G/16.1G [01:31<00:11, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  89%|████████████████  | 14.3G/16.1G [01:31<00:09, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  89%|████████████████  | 14.3G/16.1G [01:32<00:09, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  89%|████████████████  | 14.4G/16.1G [01:32<00:12, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  90%|████████████████  | 14.4G/16.1G [01:32<00:11, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  90%|████████████████▏ | 14.4G/16.1G [01:32<00:11, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  90%|████████████████▏ | 14.4G/16.1G [01:32<00:09, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  90%|████████████████▏ | 14.5G/16.1G [01:32<00:08, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  90%|████████████████▎ | 14.5G/16.1G [01:33<00:07, 215MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  90%|████████████████▎ | 14.5G/16.1G [01:33<00:06, 233MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  91%|████████████████▎ | 14.6G/16.1G [01:33<00:08, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  91%|████████████████▎ | 14.6G/16.1G [01:33<00:11, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  91%|████████████████▎ | 14.6G/16.1G [01:33<00:11, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  91%|████████████████▍ | 14.6G/16.1G [01:34<00:13, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  91%|████████████████▍ | 14.6G/16.1G [01:34<00:12, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  91%|████████████████▍ | 14.7G/16.1G [01:34<00:11, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  91%|███████████████▌ | 14.7G/16.1G [01:34<00:14, 95.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  92%|███████████████▌ | 14.7G/16.1G [01:35<00:16, 83.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  92%|███████████████▌ | 14.7G/16.1G [01:35<00:16, 80.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  92%|███████████████▌ | 14.7G/16.1G [01:35<00:16, 79.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  92%|████████████████▌ | 14.8G/16.1G [01:35<00:12, 101MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  92%|████████████████▌ | 14.8G/16.1G [01:35<00:10, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  92%|████████████████▌ | 14.8G/16.1G [01:35<00:08, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  92%|████████████████▋ | 14.8G/16.1G [01:35<00:06, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  93%|████████████████▋ | 14.9G/16.1G [01:36<00:05, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  93%|████████████████▋ | 14.9G/16.1G [01:36<00:04, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  93%|████████████████▋ | 14.9G/16.1G [01:36<00:04, 251MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  93%|████████████████▊ | 15.0G/16.1G [01:36<00:04, 263MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  93%|████████████████▊ | 15.0G/16.1G [01:36<00:03, 271MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  94%|████████████████▊ | 15.0G/16.1G [01:36<00:03, 274MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  94%|████████████████▉ | 15.1G/16.1G [01:36<00:03, 274MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  94%|████████████████▉ | 15.1G/16.1G [01:36<00:03, 274MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  94%|████████████████▉ | 15.1G/16.1G [01:36<00:03, 275MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  94%|████████████████▉ | 15.2G/16.1G [01:37<00:03, 275MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  95%|█████████████████ | 15.2G/16.1G [01:37<00:03, 278MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  95%|█████████████████ | 15.2G/16.1G [01:37<00:02, 282MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  95%|█████████████████ | 15.2G/16.1G [01:37<00:02, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  95%|█████████████████ | 15.3G/16.1G [01:37<00:02, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  95%|█████████████████▏| 15.3G/16.1G [01:37<00:02, 289MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  96%|█████████████████▏| 15.3G/16.1G [01:37<00:02, 290MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  96%|█████████████████▏| 15.4G/16.1G [01:37<00:02, 290MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  96%|█████████████████▎| 15.4G/16.1G [01:37<00:02, 290MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  96%|█████████████████▎| 15.4G/16.1G [01:37<00:02, 289MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  96%|█████████████████▎| 15.5G/16.1G [01:38<00:02, 289MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  96%|█████████████████▎| 15.5G/16.1G [01:38<00:01, 289MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  97%|█████████████████▍| 15.5G/16.1G [01:38<00:01, 288MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  97%|█████████████████▍| 15.6G/16.1G [01:38<00:01, 288MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  97%|█████████████████▍| 15.6G/16.1G [01:38<00:01, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  97%|█████████████████▌| 15.6G/16.1G [01:38<00:01, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  97%|█████████████████▌| 15.7G/16.1G [01:38<00:01, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  98%|█████████████████▌| 15.7G/16.1G [01:38<00:01, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  98%|█████████████████▌| 15.7G/16.1G [01:38<00:01, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  98%|█████████████████▋| 15.7G/16.1G [01:39<00:01, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  98%|█████████████████▋| 15.8G/16.1G [01:39<00:00, 286MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  98%|█████████████████▋| 15.8G/16.1G [01:39<00:00, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  99%|█████████████████▊| 15.8G/16.1G [01:39<00:00, 288MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  99%|█████████████████▊| 15.9G/16.1G [01:39<00:00, 287MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  99%|█████████████████▊| 15.9G/16.1G [01:39<00:00, 281MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  99%|█████████████████▊| 15.9G/16.1G [01:39<00:00, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth:  99%|█████████████████▉| 16.0G/16.1G [01:39<00:00, 284MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth: 100%|█████████████████▉| 16.0G/16.1G [01:39<00:00, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "consolidated.00.pth: 100%|██████████████████| 16.1G/16.1G [01:40<00:00, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to ../Meta-Llama-3-8B-instruct/original/consolidated.00.pth\n",
      "Fetching 17 files: 100%|████████████████████████| 17/17 [01:42<00:00,  6.01s/it]\n",
      "/home/ec2-user/SageMaker/yafei/Meta-Llama-3-8B-instruct\n"
     ]
    }
   ],
   "source": [
    "## download llama3-8B from HF\n",
    "!huggingface-cli login --token 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\n",
    "!huggingface-cli download meta-llama/Meta-Llama-3-8B-instruct  --local-dir ../Meta-Llama-3-8B-instruct\n",
    "!rm -rf ../Meta-Llama-3-8B-instruct/original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2118dba-9741-444e-abad-aa1bc92c10e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "prefix = \"hf_home/Meta-Llama-3-8B-Instruct\"\n",
    "model_ckpt = sagemaker_session.upload_data(path = \"../Meta-Llama-3-8B-instruct\", key_prefix=prefix)\n",
    "print(model_ckpt)\n",
    "# model_ckpt=\"s3://sagemaker-us-east-1-005329598202/hf_home/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abacbab8-2ddb-4166-83aa-9dfed821ce25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n",
      "763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.2.0-gpu-py310\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "import sagemaker\n",
    "\n",
    "instance_count = 1\n",
    "instance_type = 'ml.g5.48xlarge'\n",
    "# instance_type = \"ml.p4d.24xlarge\"\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "print(region)\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\", \n",
    "    region=region, \n",
    "    version=\"2.2.0\", \n",
    "    py_version='py310',\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"training\"\n",
    ")\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f1555-ad6e-491f-a733-ee9ed1ca86f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: multi-node-llama3-8b-instruct-sft-2024-06-04-08-57-22-549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-04 08:57:24 Starting - Starting the training job...\n",
      "2024-06-04 08:57:33 Pending - Training job waiting for capacity...\n",
      "2024-06-04 08:58:07 Pending - Preparing the instances for training......\n",
      "2024-06-04 08:59:07 Downloading - Downloading input data.........\n",
      "2024-06-04 09:00:47 Downloading - Downloading the training image............\n",
      "2024-06-04 09:02:43 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-06-04 09:02:45,061 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-06-04 09:02:45,123 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-04 09:02:45,135 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-06-04 09:02:45,137 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-06-04 09:02:46,966 sagemaker-training-toolkit INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.2.0)\u001b[0m\n",
      "\u001b[34mCollecting transformers>=4.37.2 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.8/43.8 kB 2.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.14.3 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate>=0.27.2 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting peft>=0.10.0 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting trl>=0.8.1 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting gradio>=4.0.0 (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading gradio-4.32.2-py3-none-any.whl.metadata (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.8.0)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (3.20.3)\u001b[0m\n",
      "\u001b[34mCollecting uvicorn (from -r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.7.2)\u001b[0m\n",
      "\u001b[34mCollecting fastapi (from -r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting sse-starlette (from -r requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34mDownloading sse_starlette-2.1.0-py3-none-any.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (3.8.4)\u001b[0m\n",
      "\u001b[34mCollecting fire (from -r requirements.txt (line 17))\u001b[0m\n",
      "\u001b[34mDownloading fire-0.6.0.tar.gz (88 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.4/88.4 kB 5.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (23.2)\u001b[0m\n",
      "\u001b[34mCollecting wandb (from -r requirements.txt (line 19))\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (2024.5.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.23.0 (from transformers>=4.37.2->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (6.0.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers>=4.37.2->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 7.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (2.32.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.20,>=0.19 (from transformers>=4.37.2->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.4.1 (from transformers>=4.37.2->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->-r requirements.txt (line 3)) (16.1.0)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow-hotfix (from datasets>=2.14.3->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->-r requirements.txt (line 3)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->-r requirements.txt (line 3)) (2.2.2)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets>=2.14.3->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->-r requirements.txt (line 3)) (0.70.16)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from torch>=1.13.1->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from datasets>=2.14.3->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.27.2->-r requirements.txt (line 4)) (5.9.8)\u001b[0m\n",
      "\u001b[34mCollecting tyro>=0.5.11 (from trl>=0.8.1->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading tyro-0.8.4-py3-none-any.whl.metadata (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiofiles<24.0,>=22.0 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting altair<6.0,>=4.2.0 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting ffmpy (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading ffmpy-0.3.2.tar.gz (5.5 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting gradio-client==0.17.0 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading gradio_client-0.17.0-py3-none-any.whl.metadata (7.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting httpx>=0.24.1 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources<7.0,>=1.3 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 7)) (2.1.5)\u001b[0m\n",
      "\u001b[34mCollecting orjson~=3.0 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.7/49.7 kB 8.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->-r requirements.txt (line 7)) (10.3.0)\u001b[0m\n",
      "\u001b[34mCollecting pydub (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-multipart>=0.0.9 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting ruff>=0.2.2 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\u001b[0m\n",
      "\u001b[34mCollecting semantic-version~=2.0 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting tomlkit==0.12.0 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting typer<1.0,>=0.12 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\u001b[0m\n",
      "\u001b[34mCollecting urllib3~=2.0 (from gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting websockets<12.0,>=10.0 (from gradio-client==0.17.0->gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->-r requirements.txt (line 12)) (8.1.7)\u001b[0m\n",
      "\u001b[34mCollecting h11>=0.8 (from uvicorn->-r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 13)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic-core==2.18.3 in /opt/conda/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 13)) (2.18.3)\u001b[0m\n",
      "\u001b[34mCollecting starlette<0.38.0,>=0.37.2 (from fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting fastapi-cli>=0.0.2 (from fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting email_validator>=2.0.0 (from fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\u001b[0m\n",
      "\u001b[34mCollecting anyio (from sse-starlette->-r requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34mDownloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 16)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 16)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 16)) (4.52.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 16)) (1.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 16)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 16)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->-r requirements.txt (line 17)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting termcolor (from fire->-r requirements.txt (line 17))\u001b[0m\n",
      "\u001b[34mDownloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 19))\u001b[0m\n",
      "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 19))\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 19)) (4.1.0)\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 19))\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting setproctitle (from wandb->-r requirements.txt (line 19))\u001b[0m\n",
      "\u001b[34mDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 19)) (68.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 7)) (4.22.0)\u001b[0m\n",
      "\u001b[34mCollecting toolz (from altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->-r requirements.txt (line 14)) (3.7)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3)) (23.2.0)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets>=2.14.3->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 19))\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 7)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mCollecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting sniffio (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.14.3->-r requirements.txt (line 3)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.14.3->-r requirements.txt (line 3)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.37.2->-r requirements.txt (line 2)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->sse-starlette->-r requirements.txt (line 15)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 7)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 7)) (13.7.1)\u001b[0m\n",
      "\u001b[34mCollecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl>=0.8.1->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.8.1->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.1->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 19))\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 7)) (2023.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 7)) (0.35.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->-r requirements.txt (line 7)) (0.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 7)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 7)) (2.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 7)) (0.1.2)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.1/9.1 MB 79.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.19.2-py3-none-any.whl (542 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.1/542.1 kB 56.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.6/302.6 kB 42.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.11.1-py3-none-any.whl (251 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.6/251.6 kB 37.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading trl-0.8.6-py3-none-any.whl (245 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 245.2/245.2 kB 36.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gradio-4.32.2-py3-none-any.whl (12.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 92.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gradio_client-0.17.0-py3-none-any.whl (316 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 316.3/316.3 kB 43.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 77.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.4/62.4 kB 11.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading fastapi-0.111.0-py3-none-any.whl (91 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 16.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sse_starlette-2.1.0-py3-none-any.whl (9.2 kB)\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.7/6.7 MB 92.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mDownloading altair-5.3.0-py3-none-any.whl (857 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 857.8/857.8 kB 69.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mDownloading email_validator-2.1.1-py3-none-any.whl (30 kB)\u001b[0m\n",
      "\u001b[34mDownloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 27.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 75.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 27.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading h11-0.14.0-py3-none-any.whl (58 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 9.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.6/75.6 kB 12.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 10.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 401.7/401.7 kB 42.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.5/142.5 kB 21.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 775.1/775.1 kB 43.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 86.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 71.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-2.4.0-py2.py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 289.2/289.2 kB 39.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 71.9/71.9 kB 10.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading anyio-4.4.0-py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 14.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 87.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading typer-0.12.3-py3-none-any.whl (47 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.2/47.2 kB 8.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tyro-0.8.4-py3-none-any.whl (102 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.4/102.4 kB 19.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.6/53.6 kB 8.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.1/121.1 kB 21.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\u001b[0m\n",
      "\u001b[34mDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 30.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 kB 38.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 239.5/239.5 kB 37.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 9.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.4/341.4 kB 47.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.3/124.3 kB 24.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34mDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 97.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 80.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.9/129.9 kB 25.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.6/301.6 kB 45.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.1/56.1 kB 10.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: llmtuner, fire, ffmpy\u001b[0m\n",
      "\u001b[34mBuilding wheel for llmtuner (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for llmtuner (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for llmtuner: filename=llmtuner-0.6.4.dev0-py3-none-any.whl size=153803 sha256=777a5d52054cc628e8949cc45c8d89f9ada780f1ddb57c04846e9095b66c4f26\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-ot4v18ry/wheels/ee/79/1e/3fb168dd34359b627e23b53045c3eb498188294150b39e2fb0\u001b[0m\n",
      "\u001b[34mBuilding wheel for fire (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for fire (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=f690eda4decb2a41b79fd703d1317afb443bb23ec033f844ab30aeb3d0c46c94\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpy (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpy (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=616d6df3c1e48bb7e8baacb0e2037cf7b546663439388c4dfd6addbc455cd9b7\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\u001b[0m\n",
      "\u001b[34mSuccessfully built llmtuner fire ffmpy\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sentencepiece, pydub, ffmpy, xxhash, websockets, uvloop, urllib3, ujson, toolz, tomlkit, termcolor, sniffio, smmap, shtab, setproctitle, semantic-version, safetensors, ruff, regex, python-multipart, python-dotenv, pyarrow-hotfix, orjson, multidict, importlib-resources, httptools, h11, fsspec, frozenlist, docstring-parser, docker-pycreds, dnspython, async-timeout, aiofiles, yarl, uvicorn, sentry-sdk, httpcore, gitdb, fire, email_validator, anyio, aiosignal, watchfiles, tyro, typer, starlette, huggingface-hub, httpx, gitpython, aiohttp, wandb, tokenizers, sse-starlette, gradio-client, fastapi-cli, altair, accelerate, transformers, fastapi, datasets, trl, peft, gradio, llmtuner\u001b[0m\n",
      "\u001b[34mAttempting uninstall: urllib3\u001b[0m\n",
      "\u001b[34mFound existing installation: urllib3 1.26.18\u001b[0m\n",
      "\u001b[34mUninstalling urllib3-1.26.18:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled urllib3-1.26.18\u001b[0m\n",
      "\u001b[34mAttempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34mFound existing installation: fsspec 2024.5.0\u001b[0m\n",
      "\u001b[34mUninstalling fsspec-2024.5.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled fsspec-2024.5.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: typer\u001b[0m\n",
      "\u001b[34mFound existing installation: typer 0.9.4\u001b[0m\n",
      "\u001b[34mUninstalling typer-0.9.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled typer-0.9.4\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.22.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.22.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.22.0\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mspacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\n",
      "\u001b[34mweasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.30.1 aiofiles-23.2.1 aiohttp-3.9.5 aiosignal-1.3.1 altair-5.3.0 anyio-4.4.0 async-timeout-4.0.3 datasets-2.19.2 dnspython-2.6.1 docker-pycreds-0.4.0 docstring-parser-0.16 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 frozenlist-1.4.1 fsspec-2024.3.1 gitdb-4.0.11 gitpython-3.1.43 gradio-4.32.2 gradio-client-0.17.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.2 importlib-resources-6.4.0 llmtuner-0.6.4.dev0 multidict-6.0.5 orjson-3.10.3 peft-0.11.1 pyarrow-hotfix-0.6 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 regex-2024.5.15 ruff-0.4.7 safetensors-0.4.3 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.4.0 setproctitle-1.3.3 shtab-1.7.1 smmap-5.0.1 sniffio-1.3.1 sse-starlette-2.1.0 starlette-0.37.2 termcolor-2.4.0 tokenizers-0.19.1 tomlkit-0.12.0 toolz-0.12.1 transformers-4.41.2 trl-0.8.6 typer-0.12.3 tyro-0.8.4 ujson-5.10.0 urllib3-2.2.1 uvicorn-0.30.1 uvloop-0.19.0 wandb-0.17.0 watchfiles-0.22.0 websockets-11.0.3 xxhash-3.4.1 yarl-1.9.4\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-06-04 09:03:18,583 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-06-04 09:03:18,583 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-06-04 09:03:18,669 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-04 09:03:18,746 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-04 09:03:18,824 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-04 09:03:18,837 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.48xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"multi-node-llama3-8b-instruct-sft-2024-06-04-08-57-22-549\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-726335585155/multi-node-llama3-8b-instruct-sft-2024-06-04-08-57-22-549/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"entry\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 192,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.48xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"entry.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=entry.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.48xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=entry\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=192\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-726335585155/multi-node-llama3-8b-instruct-sft-2024-06-04-08-57-22-549/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.48xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"multi-node-llama3-8b-instruct-sft-2024-06-04-08-57-22-549\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-726335585155/multi-node-llama3-8b-instruct-sft-2024-06-04-08-57-22-549/source/sourcedir.tar.gz\",\"module_name\":\"entry\",\"network_interface_name\":\"eth0\",\"num_cpus\":192,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"entry.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m entry\u001b[0m\n",
      "\u001b[34m2024-06-04 09:03:18,839 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-06-04 09:03:18,839 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m-----hosts-----\u001b[0m\n",
      "\u001b[34m10.0.107.205 slots=8\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/config.json.metadata to ../../../tmp/pretrain_model/.huggingface/download/config.json.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/.gitignore to ../../../tmp/pretrain_model/.huggingface/.gitignore\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/LICENSE.lock to ../../../tmp/pretrain_model/.huggingface/download/LICENSE.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/.gitattributes.metadata to ../../../tmp/pretrain_model/.huggingface/download/.gitattributes.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/config.json.lock to ../../../tmp/pretrain_model/.huggingface/download/config.json.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/.gitattributes.lock to ../../../tmp/pretrain_model/.huggingface/download/.gitattributes.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/README.md.lock to ../../../tmp/pretrain_model/.huggingface/download/README.md.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/USE_POLICY.md.metadata to ../../../tmp/pretrain_model/.huggingface/download/USE_POLICY.md.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/LICENSE.metadata to ../../../tmp/pretrain_model/.huggingface/download/LICENSE.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.gitattributes to ../../../tmp/pretrain_model/.gitattributes\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/generation_config.json.lock to ../../../tmp/pretrain_model/.huggingface/download/generation_config.json.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/README.md.metadata to ../../../tmp/pretrain_model/.huggingface/download/README.md.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model-00001-of-00004.safetensors.lock to ../../../tmp/pretrain_model/.huggingface/download/model-00001-of-00004.safetensors.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model-00002-of-00004.safetensors.lock to ../../../tmp/pretrain_model/.huggingface/download/model-00002-of-00004.safetensors.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model-00003-of-00004.safetensors.lock to ../../../tmp/pretrain_model/.huggingface/download/model-00003-of-00004.safetensors.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model-00002-of-00004.safetensors.metadata to ../../../tmp/pretrain_model/.huggingface/download/model-00002-of-00004.safetensors.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/generation_config.json.metadata to ../../../tmp/pretrain_model/.huggingface/download/generation_config.json.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/USE_POLICY.md.lock to ../../../tmp/pretrain_model/.huggingface/download/USE_POLICY.md.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model-00003-of-00004.safetensors.metadata to ../../../tmp/pretrain_model/.huggingface/download/model-00003-of-00004.safetensors.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model-00001-of-00004.safetensors.metadata to ../../../tmp/pretrain_model/.huggingface/download/model-00001-of-00004.safetensors.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model.safetensors.index.json.lock to ../../../tmp/pretrain_model/.huggingface/download/model.safetensors.index.json.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model-00004-of-00004.safetensors.metadata to ../../../tmp/pretrain_model/.huggingface/download/model-00004-of-00004.safetensors.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model-00004-of-00004.safetensors.lock to ../../../tmp/pretrain_model/.huggingface/download/model-00004-of-00004.safetensors.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/original/consolidated.00.pth.metadata to ../../../tmp/pretrain_model/.huggingface/download/original/consolidated.00.pth.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/original/params.json.lock to ../../../tmp/pretrain_model/.huggingface/download/original/params.json.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/original/tokenizer.model.lock to ../../../tmp/pretrain_model/.huggingface/download/original/tokenizer.model.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/original/params.json.metadata to ../../../tmp/pretrain_model/.huggingface/download/original/params.json.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/original/consolidated.00.pth.lock to ../../../tmp/pretrain_model/.huggingface/download/original/consolidated.00.pth.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/special_tokens_map.json.metadata to ../../../tmp/pretrain_model/.huggingface/download/special_tokens_map.json.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/original/tokenizer.model.metadata to ../../../tmp/pretrain_model/.huggingface/download/original/tokenizer.model.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/tokenizer.json.lock to ../../../tmp/pretrain_model/.huggingface/download/tokenizer.json.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/model.safetensors.index.json.metadata to ../../../tmp/pretrain_model/.huggingface/download/model.safetensors.index.json.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/special_tokens_map.json.lock to ../../../tmp/pretrain_model/.huggingface/download/special_tokens_map.json.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/tokenizer.json.metadata to ../../../tmp/pretrain_model/.huggingface/download/tokenizer.json.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/tokenizer_config.json.lock to ../../../tmp/pretrain_model/.huggingface/download/tokenizer_config.json.lock\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/.huggingface/download/tokenizer_config.json.metadata to ../../../tmp/pretrain_model/.huggingface/download/tokenizer_config.json.metadata\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/LICENSE to ../../../tmp/pretrain_model/LICENSE\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/generation_config.json to ../../../tmp/pretrain_model/generation_config.json\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/README.md to ../../../tmp/pretrain_model/README.md\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/config.json to ../../../tmp/pretrain_model/config.json\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/model.safetensors.index.json to ../../../tmp/pretrain_model/model.safetensors.index.json\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/USE_POLICY.md to ../../../tmp/pretrain_model/USE_POLICY.md\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/runs/Jun04_07-57-15_algo-1/events.out.tfevents.1717487946.algo-1.427.0 to ../../../tmp/pretrain_model/runs/Jun04_07-57-15_algo-1/events.out.tfevents.1717487946.algo-1.427.0\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/runs/Jun04_08-38-38_algo-1/events.out.tfevents.1717490434.algo-1.427.0 to ../../../tmp/pretrain_model/runs/Jun04_08-38-38_algo-1/events.out.tfevents.1717490434.algo-1.427.0\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/special_tokens_map.json to ../../../tmp/pretrain_model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/tokenizer.json to ../../../tmp/pretrain_model/tokenizer.json\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/tokenizer_config.json to ../../../tmp/pretrain_model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/trainer_log.jsonl to ../../../tmp/pretrain_model/trainer_log.jsonl\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/model-00004-of-00004.safetensors to ../../../tmp/pretrain_model/model-00004-of-00004.safetensors\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/model-00003-of-00004.safetensors to ../../../tmp/pretrain_model/model-00003-of-00004.safetensors\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/model-00002-of-00004.safetensors to ../../../tmp/pretrain_model/model-00002-of-00004.safetensors\u001b[0m\n",
      "\u001b[34mdownload: s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct/model-00001-of-00004.safetensors to ../../../tmp/pretrain_model/model-00001-of-00004.safetensors\u001b[0m\n",
      "\u001b[34mFinish download pretrained model from s3://sagemaker-us-west-2-726335585155/hf_home/Meta-Llama-3-8B-Instruct.\u001b[0m\n",
      "\u001b[34mLICENSE\u001b[0m\n",
      "\u001b[34mREADME.md\u001b[0m\n",
      "\u001b[34mUSE_POLICY.md\u001b[0m\n",
      "\u001b[34mconfig.json\u001b[0m\n",
      "\u001b[34mgeneration_config.json\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00004.safetensors\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00004.safetensors\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00004.safetensors\u001b[0m\n",
      "\u001b[34mmodel-00004-of-00004.safetensors\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json\u001b[0m\n",
      "\u001b[34mruns\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json\u001b[0m\n",
      "\u001b[34mtokenizer.json\u001b[0m\n",
      "\u001b[34mtokenizer_config.json\u001b[0m\n",
      "\u001b[34mtrainer_log.jsonl\u001b[0m\n",
      "\u001b[34mObtaining file:///opt/ml/code\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mChecking if build backend supports build_editable: started\u001b[0m\n",
      "\u001b[34mChecking if build backend supports build_editable: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build editable: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build editable: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing editable metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing editable metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.1 in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers>=4.37.2 in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (4.41.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=2.14.3 in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (2.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate>=0.27.2 in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.30.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: peft>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: trl>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.8.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gradio>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (4.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.30.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (2.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.111.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sse-starlette in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fire in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from llmtuner==0.6.4.dev0) (0.17.0)\u001b[0m\n",
      "\u001b[34mCollecting deepspeed>=0.10.0 (from llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading deepspeed-0.14.2.tar.gz (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 29.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting nltk (from llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting jieba (from llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading jieba-0.42.1.tar.gz (19.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.2/19.2 MB 82.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting rouge-chinese (from llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting transformers-stream-generator (from llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes>=0.39.0 (from llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.27.2->llmtuner==0.6.4.dev0) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.27.2->llmtuner==0.6.4.dev0) (5.9.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.27.2->llmtuner==0.6.4.dev0) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.27.2->llmtuner==0.6.4.dev0) (0.23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.27.2->llmtuner==0.6.4.dev0) (0.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (16.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (2.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (2.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.14.3->llmtuner==0.6.4.dev0) (2024.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.3->llmtuner==0.6.4.dev0) (3.9.5)\u001b[0m\n",
      "\u001b[34mCollecting hjson (from deepspeed>=0.10.0->llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed>=0.10.0->llmtuner==0.6.4.dev0) (1.11.1.1)\u001b[0m\n",
      "\u001b[34mCollecting py-cpuinfo (from deepspeed>=0.10.0->llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\u001b[0m\n",
      "\u001b[34mCollecting pynvml (from deepspeed>=0.10.0->llmtuner==0.6.4.dev0)\u001b[0m\n",
      "\u001b[34mDownloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (23.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (5.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gradio-client==0.17.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.27.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (6.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (3.10.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (10.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (2.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.12.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llmtuner==0.6.4.dev0) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.17.0->gradio>=4.0.0->llmtuner==0.6.4.dev0) (11.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->llmtuner==0.6.4.dev0) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->llmtuner==0.6.4.dev0) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->llmtuner==0.6.4.dev0) (4.52.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->llmtuner==0.6.4.dev0) (1.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->llmtuner==0.6.4.dev0) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->llmtuner==0.6.4.dev0) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->llmtuner==0.6.4.dev0) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic-core==2.18.3 in /opt/conda/lib/python3.10/site-packages (from pydantic->llmtuner==0.6.4.dev0) (2.18.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.1->llmtuner==0.6.4.dev0) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.1->llmtuner==0.6.4.dev0) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.2->llmtuner==0.6.4.dev0) (2024.5.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.2->llmtuner==0.6.4.dev0) (0.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl>=0.8.1->llmtuner==0.6.4.dev0) (0.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->llmtuner==0.6.4.dev0) (8.1.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->llmtuner==0.6.4.dev0) (0.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->llmtuner==0.6.4.dev0) (0.37.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->llmtuner==0.6.4.dev0) (0.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->llmtuner==0.6.4.dev0) (5.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->llmtuner==0.6.4.dev0) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->llmtuner==0.6.4.dev0) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->llmtuner==0.6.4.dev0) (2.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->llmtuner==0.6.4.dev0) (1.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from sse-starlette->llmtuner==0.6.4.dev0) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->llmtuner==0.6.4.dev0) (0.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->llmtuner==0.6.4.dev0) (3.1.43)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->llmtuner==0.6.4.dev0) (4.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->llmtuner==0.6.4.dev0) (2.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->llmtuner==0.6.4.dev0) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->llmtuner==0.6.4.dev0) (68.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llmtuner==0.6.4.dev0) (4.22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->llmtuner==0.6.4.dev0) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->llmtuner==0.6.4.dev0) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.4.dev0) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.4.dev0) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.4.dev0) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.4.dev0) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.4.dev0) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.3->llmtuner==0.6.4.dev0) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->llmtuner==0.6.4.dev0) (4.0.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llmtuner==0.6.4.dev0) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llmtuner==0.6.4.dev0) (1.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llmtuner==0.6.4.dev0) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.14.3->llmtuner==0.6.4.dev0) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.14.3->llmtuner==0.6.4.dev0) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.14.3->llmtuner==0.6.4.dev0) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->sse-starlette->llmtuner==0.6.4.dev0) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llmtuner==0.6.4.dev0) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llmtuner==0.6.4.dev0) (13.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.8.1->llmtuner==0.6.4.dev0) (0.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.8.1->llmtuner==0.6.4.dev0) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llmtuner==0.6.4.dev0) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llmtuner==0.6.4.dev0) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llmtuner==0.6.4.dev0) (0.19.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llmtuner==0.6.4.dev0) (0.22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.1->llmtuner==0.6.4.dev0) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->llmtuner==0.6.4.dev0) (5.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llmtuner==0.6.4.dev0) (2023.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.35.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llmtuner==0.6.4.dev0) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llmtuner==0.6.4.dev0) (2.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llmtuner==0.6.4.dev0) (0.1.2)\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 22.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 78.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 72.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 10.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mDownloading pynvml-11.5.0-py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 9.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mChecking if build backend supports build_editable: started\u001b[0m\n",
      "\u001b[34mChecking if build backend supports build_editable: finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: llmtuner, deepspeed, jieba, transformers-stream-generator\u001b[0m\n",
      "\u001b[34mBuilding editable for llmtuner (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding editable for llmtuner (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for llmtuner: filename=llmtuner-0.6.4.dev0-0.editable-py3-none-any.whl size=16977 sha256=899a98a81d0b224c35030179ca4bbb39ca85198bf36533a43e1d687a206f483e\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-t0ayirnn/wheels/ee/79/1e/3fb168dd34359b627e23b53045c3eb498188294150b39e2fb0\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for deepspeed: filename=deepspeed-0.14.2-py3-none-any.whl size=1432242 sha256=c7c8152ff613613d9e674838c364159ffd4bd493021aa4a486c852830ce608d1\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/ea/7c/43/bed44d8414c099ff962b754f425f7ff77cc623cc8a98e0da70\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314459 sha256=cecb7abb5fb5c488111f54cae81a057f17275acff50988b90bc826f8f823805a\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers-stream-generator (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers-stream-generator (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12424 sha256=39e2b63c36a2954f562002a1970d8f0a6337571098cd5f13c49011f5791c73b8\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437\u001b[0m\n",
      "\u001b[34mSuccessfully built llmtuner deepspeed jieba transformers-stream-generator\u001b[0m\n",
      "\u001b[34mInstalling collected packages: py-cpuinfo, jieba, hjson, rouge-chinese, pynvml, nltk, tiktoken, deepspeed, bitsandbytes, transformers-stream-generator, llmtuner\u001b[0m\n",
      "\u001b[34mAttempting uninstall: llmtuner\u001b[0m\n",
      "\u001b[34mFound existing installation: llmtuner 0.6.4.dev0\u001b[0m\n",
      "\u001b[34mUninstalling llmtuner-0.6.4.dev0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled llmtuner-0.6.4.dev0\u001b[0m\n",
      "\u001b[34mSuccessfully installed bitsandbytes-0.43.1 deepspeed-0.14.2 hjson-3.1.0 jieba-0.42.1 llmtuner-0.6.4.dev0 nltk-3.8.1 py-cpuinfo-9.0.0 pynvml-11.5.0 rouge-chinese-1.0.3 tiktoken-0.7.0 transformers-stream-generator-0.0.5\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting deepspeed==0.14.0\u001b[0m\n",
      "\u001b[34mDownloading deepspeed-0.14.0.tar.gz (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 27.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (1.11.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (5.9.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (9.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (2.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (11.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.14.0) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepspeed==0.14.0) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic-core==2.18.3 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepspeed==0.14.0) (2.18.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepspeed==0.14.0) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.14.0) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.14.0) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.14.0) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.14.0) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.14.0) (2024.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->deepspeed==0.14.0) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->deepspeed==0.14.0) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: deepspeed\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400402 sha256=5be01e416650d7b118ed69967c52fbf3e2b4eb2b273d8fe870a06c0d91001364\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/23/96/24/bab20c3b4e2af15e195b339afaec373eca7072cf90620432e5\u001b[0m\n",
      "\u001b[34mSuccessfully built deepspeed\u001b[0m\n",
      "\u001b[34mInstalling collected packages: deepspeed\u001b[0m\n",
      "\u001b[34mAttempting uninstall: deepspeed\u001b[0m\n",
      "\u001b[34mFound existing installation: deepspeed 0.14.2\u001b[0m\n",
      "\u001b[34mUninstalling deepspeed-0.14.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled deepspeed-0.14.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed deepspeed-0.14.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m8\u001b[0m\n",
      "\u001b[34m1\u001b[0m\n",
      "\u001b[34m./hostfile.txt\u001b[0m\n",
      "\u001b[34m10.0.107.205\u001b[0m\n",
      "\u001b[34mWARNING:__main__:\u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34mSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:20,903] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:20,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:21,026] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:21,038] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:21,048] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:21,067] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:21,132] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:21,169] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:22,763] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:22,876] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:22,935] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:22,978] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:23,101] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:23,101] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:23,214] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:23,311] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2106] 2024-06-04 09:05:23,329 >> loading file tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2106] 2024-06-04 09:05:23,329 >> loading file tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2106] 2024-06-04 09:05:23,329 >> loading file added_tokens.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2106] 2024-06-04 09:05:23,329 >> loading file special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2106] 2024-06-04 09:05:23,329 >> loading file added_tokens.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2106] 2024-06-04 09:05:23,329 >> loading file special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2106] 2024-06-04 09:05:23,329 >> loading file tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2106] 2024-06-04 09:05:23,329 >> loading file tokenizer_config.json\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:23,362] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.hparams.parser - Process rank: 7, device: cuda:7, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.hparams.parser - Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.hparams.parser - Process rank: 4, device: cuda:4, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.hparams.parser - Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.hparams.parser - Process rank: 6, device: cuda:6, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.hparams.parser - Process rank: 5, device: cuda:5, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[34m[WARNING|logging.py:314] 2024-06-04 09:05:23,669 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m[WARNING|logging.py:314] 2024-06-04 09:05:23,669 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Add pad token: <|eot_id|>\u001b[0m\n",
      "\u001b[34mTemplate(format_user=StringFormatter(slots=['<|start_header_id|>user<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_assistant=StringFormatter(slots=['{{content}}', {'eos_token'}], tool_format=None), format_system=StringFormatter(slots=[{'bos_token'}, '<|start_header_id|>system<|end_header_id|>\\n\\n{{content}}<|eot_id|>'], tool_format=None), format_function=FunctionFormatter(slots=['Action: {{name}}\\nAction Input: {{arguments}}', {'eos_token'}], tool_format=None), format_observation=StringFormatter(slots=['<|start_header_id|>tool<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_tools=ToolFormatter(slots=[], tool_format='default'), format_separator=EmptyFormatter(slots=[], tool_format=None), default_system='You are a helpful assistant.', stop_words=['<|eot_id|>'], efficient_eos=False, replace_eos=True, force_system=False)\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.loader - Loading dataset train.json...\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Add pad token: <|eot_id|>\u001b[0m\n",
      "\u001b[34mTemplate(format_user=StringFormatter(slots=['<|start_header_id|>user<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_assistant=StringFormatter(slots=['{{content}}', {'eos_token'}], tool_format=None), format_system=StringFormatter(slots=[{'bos_token'}, '<|start_header_id|>system<|end_header_id|>\\n\\n{{content}}<|eot_id|>'], tool_format=None), format_function=FunctionFormatter(slots=['Action: {{name}}\\nAction Input: {{arguments}}', {'eos_token'}], tool_format=None), format_observation=StringFormatter(slots=['<|start_header_id|>tool<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_tools=ToolFormatter(slots=[], tool_format='default'), format_separator=EmptyFormatter(slots=[], tool_format=None), default_system='You are a helpful assistant.', stop_words=['<|eot_id|>'], efficient_eos=False, replace_eos=True, force_system=False)\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Add pad token: <|eot_id|>\u001b[0m\n",
      "\u001b[34mTemplate(format_user=StringFormatter(slots=['<|start_header_id|>user<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_assistant=StringFormatter(slots=['{{content}}', {'eos_token'}], tool_format=None), format_system=StringFormatter(slots=[{'bos_token'}, '<|start_header_id|>system<|end_header_id|>\\n\\n{{content}}<|eot_id|>'], tool_format=None), format_function=FunctionFormatter(slots=['Action: {{name}}\\nAction Input: {{arguments}}', {'eos_token'}], tool_format=None), format_observation=StringFormatter(slots=['<|start_header_id|>tool<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_tools=ToolFormatter(slots=[], tool_format='default'), format_separator=EmptyFormatter(slots=[], tool_format=None), default_system='You are a helpful assistant.', stop_words=['<|eot_id|>'], efficient_eos=False, replace_eos=True, force_system=False)\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Add pad token: <|eot_id|>\u001b[0m\n",
      "\u001b[34mTemplate(format_user=StringFormatter(slots=['<|start_header_id|>user<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_assistant=StringFormatter(slots=['{{content}}', {'eos_token'}], tool_format=None), format_system=StringFormatter(slots=[{'bos_token'}, '<|start_header_id|>system<|end_header_id|>\\n\\n{{content}}<|eot_id|>'], tool_format=None), format_function=FunctionFormatter(slots=['Action: {{name}}\\nAction Input: {{arguments}}', {'eos_token'}], tool_format=None), format_observation=StringFormatter(slots=['<|start_header_id|>tool<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_tools=ToolFormatter(slots=[], tool_format='default'), format_separator=EmptyFormatter(slots=[], tool_format=None), default_system='You are a helpful assistant.', stop_words=['<|eot_id|>'], efficient_eos=False, replace_eos=True, force_system=False)\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Add pad token: <|eot_id|>\u001b[0m\n",
      "\u001b[34mTemplate(format_user=StringFormatter(slots=['<|start_header_id|>user<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_assistant=StringFormatter(slots=['{{content}}', {'eos_token'}], tool_format=None), format_system=StringFormatter(slots=[{'bos_token'}, '<|start_header_id|>system<|end_header_id|>\\n\\n{{content}}<|eot_id|>'], tool_format=None), format_function=FunctionFormatter(slots=['Action: {{name}}\\nAction Input: {{arguments}}', {'eos_token'}], tool_format=None), format_observation=StringFormatter(slots=['<|start_header_id|>tool<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_tools=ToolFormatter(slots=[], tool_format='default'), format_separator=EmptyFormatter(slots=[], tool_format=None), default_system='You are a helpful assistant.', stop_words=['<|eot_id|>'], efficient_eos=False, replace_eos=True, force_system=False)\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Add pad token: <|eot_id|>\u001b[0m\n",
      "\u001b[34mTemplate(format_user=StringFormatter(slots=['<|start_header_id|>user<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_assistant=StringFormatter(slots=['{{content}}', {'eos_token'}], tool_format=None), format_system=StringFormatter(slots=[{'bos_token'}, '<|start_header_id|>system<|end_header_id|>\\n\\n{{content}}<|eot_id|>'], tool_format=None), format_function=FunctionFormatter(slots=['Action: {{name}}\\nAction Input: {{arguments}}', {'eos_token'}], tool_format=None), format_observation=StringFormatter(slots=['<|start_header_id|>tool<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_tools=ToolFormatter(slots=[], tool_format='default'), format_separator=EmptyFormatter(slots=[], tool_format=None), default_system='You are a helpful assistant.', stop_words=['<|eot_id|>'], efficient_eos=False, replace_eos=True, force_system=False)\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Add pad token: <|eot_id|>\u001b[0m\n",
      "\u001b[34mTemplate(format_user=StringFormatter(slots=['<|start_header_id|>user<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_assistant=StringFormatter(slots=['{{content}}', {'eos_token'}], tool_format=None), format_system=StringFormatter(slots=[{'bos_token'}, '<|start_header_id|>system<|end_header_id|>\\n\\n{{content}}<|eot_id|>'], tool_format=None), format_function=FunctionFormatter(slots=['Action: {{name}}\\nAction Input: {{arguments}}', {'eos_token'}], tool_format=None), format_observation=StringFormatter(slots=['<|start_header_id|>tool<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_tools=ToolFormatter(slots=[], tool_format='default'), format_separator=EmptyFormatter(slots=[], tool_format=None), default_system='You are a helpful assistant.', stop_words=['<|eot_id|>'], efficient_eos=False, replace_eos=True, force_system=False)\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Replace eos token: <|eot_id|>\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:23 - INFO - llmtuner.data.template - Add pad token: <|eot_id|>\u001b[0m\n",
      "\u001b[34mTemplate(format_user=StringFormatter(slots=['<|start_header_id|>user<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_assistant=StringFormatter(slots=['{{content}}', {'eos_token'}], tool_format=None), format_system=StringFormatter(slots=[{'bos_token'}, '<|start_header_id|>system<|end_header_id|>\\n\\n{{content}}<|eot_id|>'], tool_format=None), format_function=FunctionFormatter(slots=['Action: {{name}}\\nAction Input: {{arguments}}', {'eos_token'}], tool_format=None), format_observation=StringFormatter(slots=['<|start_header_id|>tool<|end_header_id|>\\n\\n{{content}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'], tool_format=None), format_tools=ToolFormatter(slots=[], tool_format='default'), format_separator=EmptyFormatter(slots=[], tool_format=None), default_system='You are a helpful assistant.', stop_words=['<|eot_id|>'], efficient_eos=False, replace_eos=True, force_system=False)\u001b[0m\n",
      "\u001b[34mGenerating train split: 42176 examples [00:02, 18921.73 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 42176 examples [00:02, 18667.24 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   6%|▋         | 2636/42176 [00:00<00:02, 19001.03 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16): 100%|██████████| 42176/42176 [00:00<00:00, 142000.16 examples/s]\u001b[0m\n",
      "\u001b[34malgo-1:431:431 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:431:431 [0] NCCL INFO Bootstrap : Using eth0:10.0.107.205<0>\u001b[0m\n",
      "\u001b[34malgo-1:431:431 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:431:431 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:431:431 [0] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34mNCCL version 2.19.4+cuda12.1\u001b[0m\n",
      "\u001b[34malgo-1:438:438 [7] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:435:435 [4] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:435:435 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:438:438 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:437:437 [6] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:432:432 [1] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:432:432 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:437:437 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:434:434 [3] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:436:436 [5] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:433:433 [2] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:434:434 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:436:436 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:433:433 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:435:435 [4] NCCL INFO Bootstrap : Using eth0:10.0.107.205<0>\u001b[0m\n",
      "\u001b[34malgo-1:438:438 [7] NCCL INFO Bootstrap : Using eth0:10.0.107.205<0>\u001b[0m\n",
      "\u001b[34malgo-1:432:432 [1] NCCL INFO Bootstrap : Using eth0:10.0.107.205<0>\u001b[0m\n",
      "\u001b[34malgo-1:436:436 [5] NCCL INFO Bootstrap : Using eth0:10.0.107.205<0>\u001b[0m\n",
      "\u001b[34malgo-1:433:433 [2] NCCL INFO Bootstrap : Using eth0:10.0.107.205<0>\u001b[0m\n",
      "\u001b[34malgo-1:437:437 [6] NCCL INFO Bootstrap : Using eth0:10.0.107.205<0>\u001b[0m\n",
      "\u001b[34malgo-1:434:434 [3] NCCL INFO Bootstrap : Using eth0:10.0.107.205<0>\u001b[0m\n",
      "\u001b[34malgo-1:432:432 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:436:436 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:437:437 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:433:433 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:435:435 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:438:438 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:434:434 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:433:433 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:437:437 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:436:436 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:434:434 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:438:438 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:432:432 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:435:435 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Using Libfabric version 1.20\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Using Libfabric version 1.20\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Using Libfabric version 1.20\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Using Libfabric version 1.20\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Using Libfabric version 1.20\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Using Libfabric version 1.20\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Using Libfabric version 1.20\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Using Libfabric version 1.20\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO comm 0x560e6c7e3840 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId 1d0 commId 0x1a39dc6c792c8379 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO comm 0x5606881f77f0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId 1c0 commId 0x1a39dc6c792c8379 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO comm 0x561f8b5a5360 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 1b0 commId 0x1a39dc6c792c8379 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO comm 0x557ac8bea000 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 1a0 commId 0x1a39dc6c792c8379 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO comm 0x559d14414be0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 190 commId 0x1a39dc6c792c8379 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO comm 0x56146b168340 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 180 commId 0x1a39dc6c792c8379 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO comm 0x559f41846e90 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 170 commId 0x1a39dc6c792c8379 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO comm 0x55e04e349ef0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 160 commId 0x1a39dc6c792c8379 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NVLS multicast support is not available on dev 6\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NVLS multicast support is not available on dev 0\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NVLS multicast support is not available on dev 5\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Setting affinity for GPU 2 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Setting affinity for GPU 3 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NVLS multicast support is not available on dev 7\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NVLS multicast support is not available on dev 4\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NVLS multicast support is not available on dev 3\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NVLS multicast support is not available on dev 2\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NVLS multicast support is not available on dev 1\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Channel 00 : 7[7] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Channel 00 : 6[6] -> 7[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Channel 01 : 7[7] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Channel 00 : 5[5] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Channel 00 : 4[4] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Channel 00 : 3[3] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Channel 00 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Channel 00 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Channel 01 : 6[6] -> 7[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Channel 01 : 5[5] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Channel 01 : 4[4] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Channel 01 : 3[3] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Channel 01 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Channel 01 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Channel 00 : 7[7] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Channel 01 : 7[7] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Channel 00 : 6[6] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Channel 01 : 6[6] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Channel 00 : 5[5] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Channel 00 : 4[4] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Channel 01 : 5[5] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Channel 01 : 4[4] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Channel 00 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Channel 00 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Channel 01 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Channel 01 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:434:1258 [3] NCCL INFO comm 0x559d14414be0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 190 commId 0x1a39dc6c792c8379 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:431:1251 [0] NCCL INFO comm 0x55e04e349ef0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 160 commId 0x1a39dc6c792c8379 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:432:1255 [1] NCCL INFO comm 0x559f41846e90 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 170 commId 0x1a39dc6c792c8379 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:437:1253 [6] NCCL INFO comm 0x5606881f77f0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId 1c0 commId 0x1a39dc6c792c8379 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:433:1257 [2] NCCL INFO comm 0x56146b168340 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 180 commId 0x1a39dc6c792c8379 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:436:1256 [5] NCCL INFO comm 0x561f8b5a5360 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 1b0 commId 0x1a39dc6c792c8379 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:438:1254 [7] NCCL INFO comm 0x560e6c7e3840 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId 1d0 commId 0x1a39dc6c792c8379 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:435:1252 [4] NCCL INFO comm 0x557ac8bea000 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 1a0 commId 0x1a39dc6c792c8379 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - INFO - llmtuner.data.loader - Loading dataset train.json...\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - INFO - llmtuner.data.loader - Loading dataset train.json...\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - INFO - llmtuner.data.loader - Loading dataset train.json...\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - INFO - llmtuner.data.loader - Loading dataset train.json...\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - INFO - llmtuner.data.loader - Loading dataset train.json...\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - INFO - llmtuner.data.loader - Loading dataset train.json...\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - INFO - llmtuner.data.loader - Loading dataset train.json...\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:05:27 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   5%|▍         | 2000/42176 [00:00<00:02, 14179.00 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   5%|▍         | 2000/42176 [00:00<00:03, 13027.73 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   2%|▏         | 1000/42176 [00:00<00:07, 5265.36 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   5%|▍         | 2000/42176 [00:00<00:03, 10603.75 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   5%|▍         | 2000/42176 [00:00<00:04, 9273.98 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   5%|▍         | 2000/42176 [00:00<00:04, 9373.84 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):   2%|▏         | 1000/42176 [00:00<00:09, 4440.75 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  52%|█████▏    | 22000/42176 [00:00<00:00, 89325.04 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  84%|████████▍ | 35360/42176 [00:00<00:00, 136928.26 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  45%|████▌     | 19000/42176 [00:00<00:00, 73726.97 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  84%|████████▍ | 35632/42176 [00:00<00:00, 134740.74 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16): 100%|██████████| 42176/42176 [00:00<00:00, 98166.44 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16): 100%|██████████| 42176/42176 [00:00<00:00, 95696.48 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16): 100%|██████████| 42176/42176 [00:00<00:00, 82447.39 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  20%|██        | 8636/42176 [00:00<00:02, 13677.18 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  14%|█▍        | 6000/42176 [00:00<00:03, 9873.54 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  86%|████████▌ | 36268/42176 [00:00<00:00, 64805.95 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  71%|███████   | 29816/42176 [00:00<00:00, 39556.86 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  85%|████████▌ | 35996/42176 [00:00<00:00, 67149.51 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16):  81%|████████▏ | 34360/42176 [00:00<00:00, 43573.01 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16): 100%|██████████| 42176/42176 [00:00<00:00, 47273.19 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16): 100%|██████████| 42176/42176 [00:00<00:00, 47111.85 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16): 100%|██████████| 42176/42176 [00:00<00:00, 45138.45 examples/s]\u001b[0m\n",
      "\u001b[34mConverting format of dataset (num_proc=16): 100%|██████████| 42176/42176 [00:01<00:00, 39193.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   2%|▏         | 1000/42176 [00:02<01:30, 453.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   5%|▍         | 2000/42176 [00:02<00:40, 989.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   7%|▋         | 3000/42176 [00:02<00:27, 1422.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  12%|█▏        | 5000/42176 [00:02<00:13, 2837.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  14%|█▍        | 6000/42176 [00:03<00:10, 3345.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  17%|█▋        | 7000/42176 [00:03<00:09, 3836.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  19%|█▉        | 8000/42176 [00:03<00:07, 4323.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  24%|██▎       | 10000/42176 [00:03<00:05, 5648.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  28%|██▊       | 12000/42176 [00:03<00:04, 6854.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  31%|███       | 13000/42176 [00:03<00:04, 6678.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  38%|███▊      | 16000/42176 [00:04<00:02, 9436.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  44%|████▍     | 18636/42176 [00:04<00:02, 11394.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  49%|████▉     | 20636/42176 [00:04<00:01, 11639.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  55%|█████▌    | 23272/42176 [00:04<00:01, 12214.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  59%|█████▉    | 24908/42176 [00:04<00:01, 12064.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  67%|██████▋   | 28180/42176 [00:04<00:00, 14470.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  71%|███████   | 29816/42176 [00:05<00:00, 13201.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  75%|███████▍  | 31452/42176 [00:05<00:00, 11357.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  78%|███████▊  | 33088/42176 [00:05<00:00, 10761.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  82%|████████▏ | 34724/42176 [00:05<00:00, 9732.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  86%|████████▌ | 36360/42176 [00:05<00:00, 9233.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  90%|█████████ | 37996/42176 [00:06<00:00, 8441.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  94%|█████████▍| 39632/42176 [00:06<00:00, 9583.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  97%|█████████▋| 40904/42176 [00:06<00:00, 6664.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:06<00:00, 5430.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:07<00:00, 5954.11 examples/s]\u001b[0m\n",
      "\u001b[34minput_ids:\u001b[0m\n",
      "\u001b[34m[128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 18328, 13, 128009, 128006, 882, 128007, 271, 2675, 527, 264, 10195, 5425, 28117, 384, 42685, 2027, 31760, 11, 701, 3465, 374, 8819, 7180, 2038, 3196, 389, 279, 2316, 11, 4096, 11, 323, 1160, 315, 7180, 5144, 3984, 555, 279, 1217, 11, 4320, 304, 3645, 264, 11240, 315, 58, 9294, 1292, 25, 7180, 3220, 948, 279, 1988, 2316, 374, 220, 1627, 68640, 19921, 63897, 435, 11431, 469, 6751, 27757, 63755, 46945, 22331, 11, 1988, 2027, 4096, 374, 7817, 512, 11144, 3923, 3234, 1472, 2175, 11199, 1627, 73754, 2536, 24924, 12466, 12197, 198, 11144, 32002, 79864, 57920, 73620, 11199, 41581, 315, 1579, 4367, 12466, 1174, 220, 323, 42688, 22658, 13, 578, 6964, 374, 4883, 11, 323, 279, 1404, 374, 4832, 369, 2678, 6206, 11, 433, 690, 387, 279, 1888, 4216, 6975, 16530, 369, 701, 6980, 627, 11144, 16321, 5288, 1753, 81181, 57782, 11199, 791, 12197, 23939, 527, 10107, 34966, 11, 323, 279, 1450, 1404, 374, 8475, 13, 1102, 649, 7417, 701, 1716, 28977, 2137, 40514, 28899, 323, 28697, 11, 4546, 810, 17069, 311, 701, 2911, 994, 814, 1005, 1124, 311, 6725, 3492, 4857, 11, 51923, 1233, 11, 32528, 11, 43529, 323, 7033, 627, 11144, 36, 53566, 5257, 78100, 612, 356, 77964, 11199, 41581, 315, 11623, 481, 3769, 11, 649, 387, 28822, 449, 3090, 13, 4314, 100079, 2586, 304, 264, 2678, 9145, 11, 499, 649, 1935, 433, 311, 12660, 4286, 86121, 512, 2000, 50093, 220, 18, 10, 9787, 1432, 1256, 16923, 25, 922, 220, 16, 70, 9787, 198, 2149, 66888, 8645, 25, 922, 220, 19, 10190, 304, 3160, 11, 922, 220, 19, 10190, 304, 2430, 11, 922, 220, 15, 13, 23, 10190, 304, 2673, 198, 47, 9162, 1160, 25, 549, 604, 3035, 521, 27757, 25800, 220, 1627, 26167, 1933, 340, 9290, 512, 16, 13, 578, 6945, 1193, 5039, 279, 6205, 11, 4245, 311, 279, 3177, 11, 4676, 11, 6382, 11, 5370, 6372, 11, 279, 6945, 374, 10284, 2204, 505, 279, 1972, 3245, 627, 17, 13, 14881, 19179, 690, 617, 459, 1493, 315, 220, 16, 12, 17, 6358, 11, 4587, 3619, 627, 18, 1196, 18394, 17160, 2876, 14791, 369, 2911, 1234, 220, 18, 1667, 2362, 11, 311, 5471, 2911, 33484, 8343, 4286, 11, 1988, 6510, 678, 861, 374, 4482, 28268, 498, 330, 13401, 36962, 498, 330, 5901, 45, 498, 330, 4222, 498, 330, 3175, 8073, 1148, 596, 279, 312, 764, 81, 1503, 2612, 30, 220, 128009, 128006, 78191, 128007, 271, 3081, 1121, 374, 5324, 5901, 45, 794, 4482, 22186, 2876, 21194, 8073, 330, 28268, 794, 4482, 1844, 1347, 6601, 8073, 330, 3175, 794, 4482, 19, 10190, 8073, 330, 4222, 794, 4482, 19, 10190, 8073, 330, 13401, 36962, 794, 4482, 52, 604, 3035, 521, 27757, 25800, 220, 1627, 93546, 128009]\u001b[0m\n",
      "\u001b[34minputs:\u001b[0m\n",
      "\u001b[34m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\u001b[0m\n",
      "\u001b[34mYou are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\u001b[0m\n",
      "\u001b[34mYou are a senior cross-border e-commerce product consultant, your task is extract attribute information based on the title, description, and list of attribute names provided by the user, answer in format a dictionary of[attribute_name: attribute_value]. the input title is 26 Pieces ABC Alphabet Fridge Earily Letter Magnetic Educational Toy, input product description is Description:\u001b[0m\n",
      "\u001b[34m【What Do You Get】26PCS non magnetic plastic letters\u001b[0m\n",
      "\u001b[34m【FOR PRESCHOOL CHILD】Made of high quality plastic,  and eco-friendly. The edge is round, and the size is perfect for small hands, it will be the best early learning kit for your kids.\u001b[0m\n",
      "\u001b[34m【INTERESTING EXPERIENCE】The letters toys are bright colorful, and the hand size is appropriate. It can improve your child&#39;s imagination and creativity, bring more pleasure to your children when they use them to practice word building, phonics, grammar, spelling and math.\u001b[0m\n",
      "\u001b[34m【EASY TO CLEAN & CARRY】Made of washable material, can be cleaned with water. These alphanumeric come in a small bag, you can take it to anywhere.\u001b[0m\n",
      "\u001b[34mSpecifications:\u001b[0m\n",
      "\u001b[34mfor Ages 3+ ·\u001b[0m\n",
      "\u001b[34mItem Weight: about 1g ·\u001b[0m\n",
      "\u001b[34mAlphanumeric Size: about 4CM in length, about 4CM in width, about 0.8CM in height\u001b[0m\n",
      "\u001b[34mPacking list: Uppercase Letter × 26(random color)\u001b[0m\n",
      "\u001b[34mNote:\u001b[0m\n",
      "\u001b[34m1. The picture only shows the sample, due to the light, environment, camera, various effects, the picture is slightly different from the real thing.\u001b[0m\n",
      "\u001b[34m2. Manual measurement will have an error of 1-2cm, please understand.\u001b[0m\n",
      "\u001b[34m3.WARM NOTE Not suitable for children under 3 years old, to prevent children accidentally eat.\u001b[0m\n",
      "\u001b[34m, input attrNameList is [\"Brand\", \"Package Contents\", \"MPN\", \"length\", \"width\"], what's the rephrased output? <|eot_id|><|start_header_id|>assistant<|end_header_id|>\u001b[0m\n",
      "\u001b[34moutput result is {\"MPN\": [\"Does Not Apply\"], \"Brand\": [\"Unbranded\"], \"width\": [\"4CM\"], \"length\": [\"4CM\"], \"Package Contents\": [\"Uppercase Letter × 26\"]}<|eot_id|>\u001b[0m\n",
      "\u001b[34mlabel_ids:\u001b[0m\n",
      "\u001b[34m[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3081, 1121, 374, 5324, 5901, 45, 794, 4482, 22186, 2876, 21194, 8073, 330, 28268, 794, 4482, 1844, 1347, 6601, 8073, 330, 3175, 794, 4482, 19, 10190, 8073, 330, 4222, 794, 4482, 19, 10190, 8073, 330, 13401, 36962, 794, 4482, 52, 604, 3035, 521, 27757, 25800, 220, 1627, 93546, 128009]\u001b[0m\n",
      "\u001b[34mlabels:\u001b[0m\n",
      "\u001b[34moutput result is {\"MPN\": [\"Does Not Apply\"], \"Brand\": [\"Unbranded\"], \"width\": [\"4CM\"], \"length\": [\"4CM\"], \"Package Contents\": [\"Uppercase Letter × 26\"]}<|eot_id|>\u001b[0m\n",
      "\u001b[34mDataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42176\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:731] 2024-06-04 09:05:35,291 >> loading configuration file /tmp/pretrain_model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:731] 2024-06-04 09:05:35,291 >> loading configuration file /tmp/pretrain_model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:796] 2024-06-04 09:05:35,293 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"/tmp/pretrain_model\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:796] 2024-06-04 09:05:35,293 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"/tmp/pretrain_model\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3471] 2024-06-04 09:05:35,320 >> loading weights file /tmp/pretrain_model/model.safetensors.index.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3471] 2024-06-04 09:05:35,320 >> loading weights file /tmp/pretrain_model/model.safetensors.index.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1519] 2024-06-04 09:05:35,320 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1519] 2024-06-04 09:05:35,320 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3614] 2024-06-04 09:05:35,320 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3614] 2024-06-04 09:05:35,320 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:962] 2024-06-04 09:05:35,329 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:962] 2024-06-04 09:05:35,329 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   0%|          | 0/42176 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   2%|▏         | 1000/42176 [00:01<01:15, 548.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   2%|▏         | 1000/42176 [00:01<01:16, 536.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   2%|▏         | 1000/42176 [00:01<01:16, 538.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   2%|▏         | 1000/42176 [00:01<01:17, 534.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   2%|▏         | 1000/42176 [00:01<01:18, 526.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   2%|▏         | 1000/42176 [00:01<01:19, 514.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   5%|▍         | 2000/42176 [00:02<00:35, 1143.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   5%|▍         | 2000/42176 [00:02<00:35, 1135.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   2%|▏         | 1000/42176 [00:02<01:24, 490.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   5%|▍         | 2000/42176 [00:02<00:36, 1111.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   5%|▍         | 2000/42176 [00:02<00:36, 1087.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   5%|▍         | 2000/42176 [00:02<00:37, 1071.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   5%|▍         | 2000/42176 [00:02<00:37, 1063.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   7%|▋         | 3000/42176 [00:02<00:22, 1716.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   7%|▋         | 3000/42176 [00:02<00:23, 1676.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   7%|▋         | 3000/42176 [00:02<00:23, 1632.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   7%|▋         | 3000/42176 [00:02<00:23, 1636.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   5%|▍         | 2000/42176 [00:02<00:41, 971.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   7%|▋         | 3000/42176 [00:02<00:25, 1541.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   7%|▋         | 3000/42176 [00:02<00:25, 1537.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   9%|▉         | 4000/42176 [00:02<00:16, 2292.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   9%|▉         | 4000/42176 [00:02<00:17, 2219.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   9%|▉         | 4000/42176 [00:02<00:17, 2131.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   9%|▉         | 4000/42176 [00:02<00:19, 1967.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  12%|█▏        | 5000/42176 [00:02<00:13, 2803.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   7%|▋         | 3000/42176 [00:02<00:27, 1405.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  12%|█▏        | 5000/42176 [00:02<00:13, 2731.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):   9%|▉         | 4000/42176 [00:02<00:19, 1933.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  12%|█▏        | 5000/42176 [00:02<00:13, 2688.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  14%|█▍        | 6000/42176 [00:02<00:10, 3561.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  14%|█▍        | 6000/42176 [00:02<00:11, 3190.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  17%|█▋        | 7000/42176 [00:03<00:08, 4059.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  14%|█▍        | 6000/42176 [00:03<00:12, 2854.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  14%|█▍        | 6000/42176 [00:03<00:12, 2923.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  12%|█▏        | 5000/42176 [00:03<00:16, 2242.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  12%|█▏        | 5000/42176 [00:03<00:15, 2389.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  17%|█▋        | 7000/42176 [00:03<00:09, 3626.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  19%|█▉        | 8000/42176 [00:03<00:07, 4507.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  19%|█▉        | 8000/42176 [00:03<00:09, 3658.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  17%|█▋        | 7000/42176 [00:03<00:10, 3343.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  24%|██▎       | 10000/42176 [00:03<00:05, 5733.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  14%|█▍        | 6000/42176 [00:03<00:14, 2552.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  19%|█▉        | 8000/42176 [00:03<00:09, 3592.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  19%|█▉        | 8000/42176 [00:03<00:09, 3681.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  17%|█▋        | 7000/42176 [00:03<00:12, 2755.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  28%|██▊       | 12000/42176 [00:03<00:04, 7309.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  28%|██▊       | 12000/42176 [00:03<00:04, 7508.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  24%|██▎       | 10000/42176 [00:03<00:06, 5151.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  21%|██▏       | 9000/42176 [00:03<00:07, 4163.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  17%|█▋        | 7000/42176 [00:03<00:13, 2704.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  33%|███▎      | 14000/42176 [00:03<00:03, 8166.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  33%|███▎      | 14000/42176 [00:03<00:03, 7908.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  24%|██▎       | 10000/42176 [00:03<00:07, 4301.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  24%|██▎       | 10000/42176 [00:03<00:07, 4378.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  31%|███       | 13000/42176 [00:03<00:04, 6935.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  31%|███       | 13000/42176 [00:03<00:04, 6474.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  38%|███▊      | 16000/42176 [00:03<00:03, 8180.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  28%|██▊       | 12000/42176 [00:04<00:05, 5637.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  33%|███▎      | 14000/42176 [00:04<00:04, 6430.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  43%|████▎     | 18000/42176 [00:04<00:02, 9793.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  38%|███▊      | 16000/42176 [00:04<00:03, 7050.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  28%|██▊       | 12000/42176 [00:04<00:06, 4844.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  36%|███▌      | 15000/42176 [00:04<00:03, 6810.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  21%|██▏       | 9000/42176 [00:04<00:10, 3251.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  47%|████▋     | 19636/42176 [00:04<00:02, 9322.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  36%|███▌      | 15000/42176 [00:04<00:04, 6050.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  38%|███▊      | 16000/42176 [00:04<00:03, 7241.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  47%|████▋     | 19636/42176 [00:04<00:02, 9073.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  31%|███       | 13000/42176 [00:04<00:06, 4579.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  44%|████▍     | 18636/42176 [00:04<00:02, 9062.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  36%|███▌      | 15272/42176 [00:04<00:04, 6292.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  52%|█████▏    | 21908/42176 [00:04<00:01, 10731.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  50%|█████     | 21272/42176 [00:04<00:02, 8541.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  28%|██▊       | 12000/42176 [00:04<00:06, 4744.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  42%|████▏     | 17636/42176 [00:04<00:03, 7172.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  43%|████▎     | 18272/42176 [00:04<00:02, 9051.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  53%|█████▎    | 22272/42176 [00:04<00:02, 8666.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  56%|█████▌    | 23544/42176 [00:04<00:01, 10719.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  45%|████▍     | 18908/42176 [00:04<00:02, 8420.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  48%|████▊     | 20272/42176 [00:04<00:02, 8918.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  49%|████▊     | 20544/42176 [00:04<00:02, 9309.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  35%|███▍      | 14636/42176 [00:04<00:04, 5736.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  60%|█████▉    | 25180/42176 [00:04<00:01, 10367.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  50%|█████     | 21272/42176 [00:04<00:02, 8368.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  61%|██████    | 25544/42176 [00:04<00:01, 9661.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  47%|████▋     | 19908/42176 [00:04<00:02, 7974.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  48%|████▊     | 20272/42176 [00:04<00:03, 6810.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  67%|██████▋   | 28180/42176 [00:04<00:00, 14008.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  43%|████▎     | 18272/42176 [00:04<00:02, 8490.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  64%|██████▍   | 27180/42176 [00:05<00:01, 10676.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  51%|█████     | 21544/42176 [00:05<00:02, 8776.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  55%|█████▌    | 23272/42176 [00:05<00:02, 9170.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  53%|█████▎    | 22180/42176 [00:05<00:02, 7875.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  54%|█████▍    | 22908/42176 [00:05<00:02, 7695.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  60%|█████▉    | 25180/42176 [00:05<00:01, 9624.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  56%|█████▋    | 23816/42176 [00:05<00:02, 8883.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  68%|██████▊   | 28816/42176 [00:05<00:01, 9229.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  62%|██████▏   | 26180/42176 [00:05<00:01, 11578.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  73%|███████▎  | 30816/42176 [00:05<00:01, 11111.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  55%|█████▍    | 23180/42176 [00:05<00:02, 7875.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  67%|██████▋   | 28180/42176 [00:05<00:01, 12439.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  46%|████▋     | 19544/42176 [00:05<00:03, 6673.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  72%|███████▏  | 30452/42176 [00:05<00:01, 9623.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  59%|█████▉    | 24816/42176 [00:05<00:01, 8909.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  67%|██████▋   | 28180/42176 [00:05<00:01, 11537.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  64%|██████▎   | 26816/42176 [00:05<00:01, 10443.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  77%|███████▋  | 32452/42176 [00:05<00:00, 10666.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  77%|███████▋  | 32452/42176 [00:05<00:01, 9165.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  61%|██████    | 25816/42176 [00:05<00:02, 7646.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  51%|█████     | 21544/42176 [00:05<00:02, 7365.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  71%|███████   | 29816/42176 [00:05<00:01, 10259.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  73%|███████▎  | 30816/42176 [00:05<00:01, 10022.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  57%|█████▋    | 24180/42176 [00:05<00:01, 9401.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  81%|████████  | 34088/42176 [00:05<00:00, 8934.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  80%|███████▉  | 33724/42176 [00:05<00:00, 8869.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  75%|███████▍  | 31452/42176 [00:05<00:00, 10989.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  65%|██████▌   | 27452/42176 [00:05<00:01, 7737.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  67%|██████▋   | 28452/42176 [00:05<00:01, 8548.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  61%|██████    | 25816/42176 [00:05<00:01, 9287.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  85%|████████▍ | 35724/42176 [00:05<00:00, 9422.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  70%|██████▉   | 29452/42176 [00:05<00:01, 9065.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  71%|███████▏  | 30088/42176 [00:05<00:01, 9485.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  74%|███████▎  | 31088/42176 [00:06<00:01, 9554.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  78%|███████▊  | 32724/42176 [00:06<00:01, 8019.78 examples/s] #015Running tokenizer on dataset (num_proc=16):  89%|████████▊ | 37360/42176 [00:06<00:00, 9555.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  86%|████████▌ | 36360/42176 [00:06<00:00, 8382.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  81%|████████▏ | 34360/42176 [00:06<00:00, 9073.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  78%|███████▊  | 33088/42176 [00:06<00:01, 7409.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  76%|███████▌  | 32088/42176 [00:06<00:01, 8559.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  92%|█████████▏| 38632/42176 [00:06<00:00, 9055.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  80%|███████▉  | 33724/42176 [00:06<00:00, 9494.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  66%|██████▌   | 27816/42176 [00:06<00:02, 7036.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  94%|█████████▍| 39632/42176 [00:06<00:00, 8972.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  82%|████████▏ | 34724/42176 [00:06<00:00, 7798.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  78%|███████▊  | 32724/42176 [00:06<00:01, 7840.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  89%|████████▉ | 37632/42176 [00:06<00:00, 6997.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  72%|███████▏  | 30452/42176 [00:06<00:01, 8775.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  86%|████████▌ | 36360/42176 [00:06<00:00, 8349.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  80%|███████▉  | 33724/42176 [00:06<00:01, 6904.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  92%|█████████▏| 38632/42176 [00:06<00:00, 6466.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  85%|████████▌ | 35996/42176 [00:06<00:00, 6614.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  76%|███████▌  | 32088/42176 [00:06<00:01, 9098.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  95%|█████████▌| 40268/42176 [00:06<00:00, 7973.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  97%|█████████▋| 40904/42176 [00:06<00:00, 5928.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  89%|████████▉ | 37632/42176 [00:06<00:00, 6965.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  84%|████████▍ | 35360/42176 [00:06<00:01, 6245.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  83%|████████▎ | 34996/42176 [00:06<00:01, 5958.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  90%|█████████ | 37996/42176 [00:06<00:00, 6712.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  88%|████████▊ | 36996/42176 [00:06<00:00, 7508.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  80%|███████▉  | 33724/42176 [00:07<00:01, 7152.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  95%|█████████▌| 40268/42176 [00:07<00:00, 7653.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  88%|████████▊ | 36996/42176 [00:07<00:00, 6314.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:07<00:00, 4585.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  92%|█████████▏| 38632/42176 [00:07<00:00, 6945.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  94%|█████████▍| 39632/42176 [00:07<00:00, 6206.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  84%|████████▍ | 35360/42176 [00:07<00:00, 7059.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:07<00:00, 5771.32 examples/s]\u001b[0m\n",
      "\u001b[34mDataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42176\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  98%|█████████▊| 41540/42176 [00:07<00:00, 4148.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  92%|█████████▏| 38632/42176 [00:07<00:00, 6179.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  97%|█████████▋| 40904/42176 [00:07<00:00, 5732.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  88%|████████▊ | 36996/42176 [00:07<00:00, 6404.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:07<00:00, 5521.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  98%|█████████▊| 41540/42176 [00:07<00:00, 5021.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  94%|█████████▍| 39632/42176 [00:07<00:00, 4815.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  94%|█████████▍| 39632/42176 [00:07<00:00, 5451.81 examples/s]\u001b[0m\n",
      "\u001b[34mDataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42176\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:07<00:00, 5406.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  97%|█████████▋| 40904/42176 [00:07<00:00, 5747.31 examples/s]\u001b[0m\n",
      "\u001b[34mDataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42176\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  97%|█████████▋| 40904/42176 [00:08<00:00, 5028.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  92%|█████████▏| 38632/42176 [00:08<00:00, 5454.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:08<00:00, 4180.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  95%|█████████▌| 40268/42176 [00:08<00:00, 6645.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:08<00:00, 5156.21 examples/s]\u001b[0m\n",
      "\u001b[34mDataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42176\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:08<00:00, 3480.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:08<00:00, 3825.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:08<00:00, 4888.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:08<00:00, 4850.22 examples/s]\u001b[0m\n",
      "\u001b[34mDataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42176\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mDataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42176\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16):  98%|█████████▊| 41540/42176 [00:08<00:00, 3962.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=16): 100%|██████████| 42176/42176 [00:09<00:00, 4662.25 examples/s]\u001b[0m\n",
      "\u001b[34mDataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 42176\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:05:54,716] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 291, num_elems = 8.03B\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.79s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.80s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.81s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.93s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.93s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.94s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.95s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.74s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.78s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.77s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.78s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.82s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.83s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.84s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.84s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:13<00:13,  6.75s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.72s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.72s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.72s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.75s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.75s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.75s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.76s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:20<00:06,  6.71s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  4.83s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  5.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  4.83s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  5.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  4.83s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  5.54s/it]\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.adapter - Fine-tuning method: Full\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.adapter - Fine-tuning method: Full\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.adapter - Fine-tuning method: Full\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.loader - trainable params: 8030261248 || all params: 8030261248 || trainable%: 100.0000\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.loader - trainable params: 8030261248 || all params: 8030261248 || trainable%: 100.0000\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:16 - INFO - llmtuner.model.loader - trainable params: 8030261248 || all params: 8030261248 || trainable%: 100.0000\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  4.84s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  5.57s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  4.85s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  5.57s/it]\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.adapter - Fine-tuning method: Full\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.adapter - Fine-tuning method: Full\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  4.85s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  5.57s/it]\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.loader - trainable params: 8030261248 || all params: 8030261248 || trainable%: 100.0000\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.loader - trainable params: 8030261248 || all params: 8030261248 || trainable%: 100.0000\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.adapter - Fine-tuning method: Full\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.loader - trainable params: 8030261248 || all params: 8030261248 || trainable%: 100.0000\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  4.77s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.49s/it]\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4280] 2024-06-04 09:06:17,071 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4280] 2024-06-04 09:06:17,071 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4288] 2024-06-04 09:06:17,071 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /tmp/pretrain_model.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4288] 2024-06-04 09:06:17,071 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /tmp/pretrain_model.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:915] 2024-06-04 09:06:17,074 >> loading configuration file /tmp/pretrain_model/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:915] 2024-06-04 09:06:17,074 >> loading configuration file /tmp/pretrain_model/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:962] 2024-06-04 09:06:17,075 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ],\n",
      "  \"max_length\": 4096,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:962] 2024-06-04 09:06:17,075 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ],\n",
      "  \"max_length\": 4096,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.adapter - Fine-tuning method: Full\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.loader - trainable params: 8030261248 || all params: 8030261248 || trainable%: 100.0000\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  4.86s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:22<00:00,  5.58s/it]\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.adapter - Fine-tuning method: Full\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:641] 2024-06-04 09:06:17,101 >> Using auto half precision backend\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:641] 2024-06-04 09:06:17,101 >> Using auto half precision backend\u001b[0m\n",
      "\u001b[34m06/04/2024 09:06:17 - INFO - llmtuner.model.loader - trainable params: 8030261248 || all params: 8030261248 || trainable%: 100.0000\u001b[0m\n",
      "\u001b[34m[INFO|deepspeed.py:328] 2024-06-04 09:06:17,439 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)\u001b[0m\n",
      "\u001b[34m[INFO|deepspeed.py:328] 2024-06-04 09:06:17,439 >> Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mCreating extension directory /root/.cache/torch_extensions/py310_cu121/cpu_adam...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mDetected CUDA files, patching ldflags\u001b[0m\n",
      "\u001b[34mEmitting ninja build file /root/.cache/torch_extensions/py310_cu121/cpu_adam/build.ninja...\u001b[0m\n",
      "\u001b[34mBuilding extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34m[1/4] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output custom_cuda_kernel.cuda.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ --threads=8 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o\u001b[0m\n",
      "\u001b[34m[2/4] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o\u001b[0m\n",
      "\u001b[34m[3/4] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o\u001b[0m\n",
      "\u001b[34m[4/4] c++ cpu_adam.o cpu_adam_impl.o custom_cuda_kernel.cuda.o -shared -lcurand -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/conda/lib -lcudart -o cpu_adam.so\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 31.769564390182495 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 31.553710460662842 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 31.555405855178833 seconds\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 31.554642915725708 seconds\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 31.540598154067993 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 31.524704694747925 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 31.818127870559692 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 31.820818424224854 seconds\u001b[0m\n",
      "\u001b[34mAdam Optimizer #0 is created with AVX2 arithmetic capability.\u001b[0m\n",
      "\u001b[34mConfig: alpha=0.000050, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,169] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,181] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,182] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,182] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,197] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,197] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,197] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,197] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,539] [INFO] [utils.py:800:see_memory_usage] Stage 3 initialize beginning\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,540] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 1.96 GB         CA 0.0 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,540] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 84.21 GB, percent = 11.3%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,542] [INFO] [stage3.py:130:__init__] Reduce bucket size 16777216\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,542] [INFO] [stage3.py:131:__init__] Prefetch bucket size 15099494\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,878] [INFO] [utils.py:800:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,879] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:51,879] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 84.21 GB, percent = 11.3%\u001b[0m\n",
      "\u001b[34mParameter Offload: Total persistent parameters: 266240 in 65 params\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:52,236] [INFO] [utils.py:800:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:52,237] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:52,237] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 84.21 GB, percent = 11.3%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:52,575] [INFO] [utils.py:800:see_memory_usage] Before creating fp16 partitions\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:52,575] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:52,576] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 84.21 GB, percent = 11.3%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:55,269] [INFO] [utils.py:800:see_memory_usage] After creating fp16 partitions: 2\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:55,272] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:55,272] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.0 GB, percent = 14.0%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:55,601] [INFO] [utils.py:800:see_memory_usage] Before creating fp32 partitions\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:55,602] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:55,602] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 109.61 GB, percent = 14.7%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:58,984] [INFO] [utils.py:800:see_memory_usage] After creating fp32 partitions\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:58,984] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:58,985] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 130.52 GB, percent = 17.5%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:59,311] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:59,311] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:06:59,312] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 135.61 GB, percent = 18.1%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:07,671] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:07,672] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:07,672] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 163.21 GB, percent = 21.8%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:07,672] [INFO] [stage3.py:486:_setup_for_real_optimizer] optimizer state initialized\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,400] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,401] [INFO] [utils.py:801:see_memory_usage] MA 0.03 GB         Max_MA 1.99 GB         CA 1.99 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,401] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 179.73 GB, percent = 24.0%\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,401] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,401] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,401] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,401] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,402] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,403] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,403] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,403] [INFO] [config.py:1000:print]   amp_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,403] [INFO] [config.py:1000:print]   amp_params ................... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,403] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,403] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,403] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f36e9234b80>\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   communication_data_type ...... None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   disable_allgather ............ False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   dump_state ................... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   fp16_enabled ................. False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   global_rank .................. 0\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 2\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   graph_harvesting ............. False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,404] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   memory_breakdown ............. False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   optimizer_name ............... None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   optimizer_params ............. None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   pld_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   pld_params ................... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   prescale_gradients ........... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   scheduler_name ............... None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   scheduler_params ............. None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   sparse_attention ............. None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   steps_per_print .............. inf\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   train_batch_size ............. 16\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   weight_quantization_config ... None\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   world_size ................... 8\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   zero_enabled ................. True\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,405] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 3\u001b[0m\n",
      "\u001b[34m[2024-06-04 09:07:20,406] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"train_batch_size\": 16, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 2, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"zero_allow_untested_optimizer\": true, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 1.677722e+07, \n",
      "        \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
      "        \"stage3_param_persistence_threshold\": 4.096000e+04, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"steps_per_print\": inf\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2078] 2024-06-04 09:07:20,406 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2079] 2024-06-04 09:07:20,406 >>   Num examples = 41,754\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2080] 2024-06-04 09:07:20,406 >>   Num Epochs = 3\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2081] 2024-06-04 09:07:20,406 >>   Instantaneous batch size per device = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2084] 2024-06-04 09:07:20,406 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2085] 2024-06-04 09:07:20,406 >>   Gradient Accumulation steps = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2086] 2024-06-04 09:07:20,406 >>   Total optimization steps = 7,830\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2078] 2024-06-04 09:07:20,406 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2079] 2024-06-04 09:07:20,406 >>   Num examples = 41,754\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2080] 2024-06-04 09:07:20,406 >>   Num Epochs = 3\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2081] 2024-06-04 09:07:20,406 >>   Instantaneous batch size per device = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2084] 2024-06-04 09:07:20,406 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2085] 2024-06-04 09:07:20,406 >>   Gradient Accumulation steps = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2086] 2024-06-04 09:07:20,406 >>   Total optimization steps = 7,830\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2087] 2024-06-04 09:07:20,407 >>   Number of trainable parameters = 8,030,261,248\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2087] 2024-06-04 09:07:20,407 >>   Number of trainable parameters = 8,030,261,248\u001b[0m\n",
      "\u001b[34m[INFO|integration_utils.py:723] 2024-06-04 09:07:20,408 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\u001b[0m\n",
      "\u001b[34m[INFO|integration_utils.py:723] 2024-06-04 09:07:20,408 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\u001b[0m\n",
      "\u001b[34mwandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\u001b[0m\n",
      "\u001b[34mwandb: Currently logged in as: jackieliu_cornell (jackieliu). Use `wandb login --relogin` to force relogin\u001b[0m\n",
      "\u001b[34mwandb: Tracking run with wandb version 0.17.0\u001b[0m\n",
      "\u001b[34mwandb: Run data is saved locally in /opt/ml/code/examples/full_multi_gpu/wandb/run-20240604_090721-multi-node-llama3-8b-instruct-sft-2024-06-04-08-57-22-549-kf36ex-algo-1\u001b[0m\n",
      "\u001b[34mwandb: Run `wandb offline` to turn off syncing.\u001b[0m\n",
      "\u001b[34mwandb: Syncing run /opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mwandb: ⭐️ View project at https://wandb.ai/jackieliu/huggingface\u001b[0m\n",
      "\u001b[34mwandb: 🚀 View run at https://wandb.ai/jackieliu/huggingface/runs/multi-node-llama3-8b-instruct-sft-2024-06-04-08-57-22-549-kf36ex-algo-1\u001b[0m\n",
      "\u001b[34m06/04/2024 09:07:30 - WARNING - llmtuner.extras.callbacks - Previous log file in this folder will be deleted.\u001b[0m\n",
      "\u001b[34m0%|          | 0/7830 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO bootstrapSplit: rank 6 nranks 8 color -934961569 key 6 prev 5 next 7 - DONE\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO bootstrapSplit: rank 0 nranks 8 color -934961569 key 0 prev 7 next 1 - DONE\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO bootstrapSplit: rank 7 nranks 8 color -934961569 key 7 prev 6 next 0 - DONE\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO bootstrapSplit: rank 2 nranks 8 color -934961569 key 2 prev 1 next 3 - DONE\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO comm 0x7fa868bfce90 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId 1c0 commId 0x84ad6f0d6f2d49fb - Init START\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO comm 0x7f34e0bfeb20 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 160 commId 0x84ad6f0d6f2d49fb - Init START\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO bootstrapSplit: rank 5 nranks 8 color -934961569 key 5 prev 4 next 6 - DONE\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO bootstrapSplit: rank 1 nranks 8 color -934961569 key 1 prev 0 next 2 - DONE\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO comm 0x7fd4f8bfced0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId 1d0 commId 0x84ad6f0d6f2d49fb - Init START\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO comm 0x7fd524bfd080 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 180 commId 0x84ad6f0d6f2d49fb - Init START\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO bootstrapSplit: rank 4 nranks 8 color -934961569 key 4 prev 3 next 5 - DONE\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO comm 0x7f1290bfced0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 1b0 commId 0x84ad6f0d6f2d49fb - Init START\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO bootstrapSplit: rank 3 nranks 8 color -934961569 key 3 prev 2 next 4 - DONE\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO comm 0x7fc7ccbfce50 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 170 commId 0x84ad6f0d6f2d49fb - Init START\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO comm 0x7fe0e0bfcf30 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 1a0 commId 0x84ad6f0d6f2d49fb - Init START\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO comm 0x7fa1fcbfcf10 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 190 commId 0x84ad6f0d6f2d49fb - Init START\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Setting affinity for GPU 2 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO NVLS multicast support is not available on dev 2\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO NVLS multicast support is not available on dev 7\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO NVLS multicast support is not available on dev 4\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO NVLS multicast support is not available on dev 6\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO NVLS multicast support is not available on dev 5\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 0 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 4 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 5 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Setting affinity for GPU 3 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO NVLS multicast support is not available on dev 3\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO NVLS multicast support is not available on dev 1\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO NVLS multicast support is not available on dev 0\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Channel 00 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Channel 01 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Channel 00 : 7[7] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Channel 00 : 3[3] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Channel 00 : 4[4] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Channel 01 : 7[7] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Channel 00 : 5[5] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Channel 01 : 4[4] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Channel 01 : 3[3] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Channel 01 : 5[5] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Channel 00 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Channel 00 : 6[6] -> 7[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Channel 01 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Channel 01 : 6[6] -> 7[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Channel 00 : 7[7] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO P2P is disabled between connected GPUs 7 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Channel 01 : 7[7] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO P2P is disabled between connected GPUs 4 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 7. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 6. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 3. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO P2P is disabled between connected GPUs 0 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Channel 00 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO P2P is disabled between connected GPUs 3 and 2. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Channel 01 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Channel 00 : 4[4] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Channel 00 : 6[6] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO P2P is disabled between connected GPUs 6 and 5. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Channel 01 : 4[4] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Channel 00 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO P2P is disabled between connected GPUs 2 and 1. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Channel 00 : 5[5] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO P2P is disabled between connected GPUs 5 and 4. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO P2P is disabled between connected GPUs 1 and 0. You can repress this message with NCCL_IGNORE_DISABLED_P2P=1.\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Channel 01 : 6[6] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Channel 01 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Channel 01 : 5[5] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:436:2809 [5] NCCL INFO comm 0x7f1290bfced0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 1b0 commId 0x84ad6f0d6f2d49fb - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:434:2807 [3] NCCL INFO comm 0x7fa1fcbfcf10 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 190 commId 0x84ad6f0d6f2d49fb - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:438:2811 [7] NCCL INFO comm 0x7fd4f8bfced0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId 1d0 commId 0x84ad6f0d6f2d49fb - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:432:2806 [1] NCCL INFO comm 0x7fc7ccbfce50 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 170 commId 0x84ad6f0d6f2d49fb - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:431:2805 [0] NCCL INFO comm 0x7f34e0bfeb20 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 160 commId 0x84ad6f0d6f2d49fb - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:437:2810 [6] NCCL INFO comm 0x7fa868bfce90 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId 1c0 commId 0x84ad6f0d6f2d49fb - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:435:2808 [4] NCCL INFO comm 0x7fe0e0bfcf30 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 1a0 commId 0x84ad6f0d6f2d49fb - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:433:2812 [2] NCCL INFO comm 0x7fd524bfd080 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 180 commId 0x84ad6f0d6f2d49fb - Init COMPLETE\u001b[0m\n",
      "\u001b[34m0%|          | 1/7830 [01:09<152:01:30, 69.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.666, 'grad_norm': 41.22460155583678, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 1/7830 [01:09<152:01:30, 69.91s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/7830 [02:05<134:08:46, 61.69s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.8215, 'grad_norm': 49.90830948317875, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 2/7830 [02:05<134:08:46, 61.69s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/7830 [03:02<128:38:09, 59.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.5386, 'grad_norm': 29.036510766955647, 'learning_rate': 1.5e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 3/7830 [03:02<128:38:09, 59.17s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/7830 [03:58<126:02:00, 57.98s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6085, 'grad_norm': 31.905853059786008, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 4/7830 [03:58<126:02:00, 57.98s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 5/7830 [04:54<124:43:50, 57.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.5829, 'grad_norm': 28.858312235101238, 'learning_rate': 2.5e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 5/7830 [04:54<124:43:50, 57.38s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 6/7830 [05:50<123:37:23, 56.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1771, 'grad_norm': 18.501830964081297, 'learning_rate': 3e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 6/7830 [05:50<123:37:23, 56.88s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 7/7830 [06:46<122:56:32, 56.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9781, 'grad_norm': 17.432836202872206, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 7/7830 [06:46<122:56:32, 56.58s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 8/7830 [07:42<122:35:47, 56.42s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8122, 'grad_norm': 14.798870270371886, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 8/7830 [07:42<122:35:47, 56.42s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 9/7830 [08:38<122:12:01, 56.25s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8966, 'grad_norm': 12.168672857838432, 'learning_rate': 4.5e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 9/7830 [08:38<122:12:01, 56.25s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 10/7830 [09:34<122:05:14, 56.20s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7459, 'grad_norm': 11.650899277716386, 'learning_rate': 5e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 10/7830 [09:34<122:05:14, 56.20s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 11/7830 [10:30<121:51:51, 56.11s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7643, 'grad_norm': 19.405561990873665, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 11/7830 [10:30<121:51:51, 56.11s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 12/7830 [11:26<121:54:28, 56.14s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7531, 'grad_norm': 7.473233333784089, 'learning_rate': 6e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 12/7830 [11:26<121:54:28, 56.14s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 13/7830 [12:22<121:43:15, 56.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5972, 'grad_norm': 8.20308175211814, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.0}\u001b[0m\n",
      "\u001b[34m0%|          | 13/7830 [12:22<121:43:15, 56.06s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 14/7830 [13:18<121:34:14, 55.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6462, 'grad_norm': 8.392002894747428, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 14/7830 [13:18<121:34:14, 55.99s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 15/7830 [14:14<121:41:28, 56.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7595, 'grad_norm': 7.616732258030825, 'learning_rate': 7.5e-06, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 15/7830 [14:14<121:41:28, 56.06s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 16/7830 [15:10<121:38:47, 56.04s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.612, 'grad_norm': 6.805730693752061, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 16/7830 [15:10<121:38:47, 56.04s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 17/7830 [16:06<121:33:34, 56.01s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4893, 'grad_norm': 7.619428005827362, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 17/7830 [16:06<121:33:34, 56.01s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 18/7830 [17:02<121:27:38, 55.97s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5168, 'grad_norm': 5.684168919565317, 'learning_rate': 9e-06, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 18/7830 [17:02<121:27:38, 55.97s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 19/7830 [17:58<121:24:53, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4529, 'grad_norm': 4.936947175959339, 'learning_rate': 9.5e-06, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 19/7830 [17:58<121:24:53, 55.96s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 20/7830 [18:54<121:24:08, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.603, 'grad_norm': 4.973029063499051, 'learning_rate': 1e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 20/7830 [18:54<121:24:08, 55.96s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 21/7830 [19:50<121:20:29, 55.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6053, 'grad_norm': 5.667559871214316, 'learning_rate': 1.05e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 21/7830 [19:50<121:20:29, 55.94s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 22/7830 [20:46<121:20:53, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4924, 'grad_norm': 4.80040340317894, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 22/7830 [20:46<121:20:53, 55.95s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 23/7830 [21:42<121:21:44, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.817, 'grad_norm': 6.382510081192464, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 23/7830 [21:42<121:21:44, 55.96s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 24/7830 [22:37<121:19:26, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4717, 'grad_norm': 4.469550001121412, 'learning_rate': 1.2e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 24/7830 [22:37<121:19:26, 55.95s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 25/7830 [23:33<121:19:00, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4991, 'grad_norm': 4.135347969515926, 'learning_rate': 1.25e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 25/7830 [23:33<121:19:00, 55.96s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 26/7830 [24:29<121:16:47, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5683, 'grad_norm': 6.032878438475117, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 26/7830 [24:29<121:16:47, 55.95s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 27/7830 [25:25<121:12:03, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5856, 'grad_norm': 5.323946301436656, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 27/7830 [25:25<121:12:03, 55.92s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 28/7830 [26:21<121:08:24, 55.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5801, 'grad_norm': 5.347338090882521, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 28/7830 [26:21<121:08:24, 55.90s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 29/7830 [27:17<121:16:37, 55.97s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4743, 'grad_norm': 4.181595240368496, 'learning_rate': 1.45e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 29/7830 [27:17<121:16:37, 55.97s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 30/7830 [28:13<121:12:48, 55.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6502, 'grad_norm': 5.216893031334898, 'learning_rate': 1.5e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 30/7830 [28:13<121:12:48, 55.94s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 31/7830 [29:09<121:11:42, 55.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6409, 'grad_norm': 5.058513814522874, 'learning_rate': 1.55e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 31/7830 [29:09<121:11:42, 55.94s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 32/7830 [30:05<121:10:34, 55.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4087, 'grad_norm': 3.8854334253899148, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 32/7830 [30:05<121:10:34, 55.94s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 33/7830 [31:01<121:06:47, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5686, 'grad_norm': 4.814008402063877, 'learning_rate': 1.65e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 33/7830 [31:01<121:06:47, 55.92s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 34/7830 [31:57<121:09:15, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6497, 'grad_norm': 4.530614347925556, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 34/7830 [31:57<121:09:15, 55.95s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 35/7830 [32:53<121:05:00, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6133, 'grad_norm': 4.785534503544943, 'learning_rate': 1.75e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 35/7830 [32:53<121:05:00, 55.92s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 36/7830 [33:49<121:02:15, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7794, 'grad_norm': 4.780294684420351, 'learning_rate': 1.8e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 36/7830 [33:49<121:02:15, 55.91s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 37/7830 [34:44<121:02:08, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5039, 'grad_norm': 4.646273376882231, 'learning_rate': 1.85e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 37/7830 [34:44<121:02:08, 55.91s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 38/7830 [35:40<120:58:58, 55.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.676, 'grad_norm': 4.584220291782862, 'learning_rate': 1.9e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 38/7830 [35:40<120:58:58, 55.90s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 39/7830 [36:36<120:57:32, 55.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5993, 'grad_norm': 5.355990661966219, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 39/7830 [36:36<120:57:32, 55.89s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 40/7830 [37:32<121:00:36, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5049, 'grad_norm': 4.527674244098061, 'learning_rate': 2e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 40/7830 [37:32<121:00:36, 55.92s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 41/7830 [38:28<121:03:26, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7126, 'grad_norm': 5.00804825583417, 'learning_rate': 2.05e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 41/7830 [38:28<121:03:26, 55.95s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 42/7830 [39:24<120:59:30, 55.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4767, 'grad_norm': 4.435155544714362, 'learning_rate': 2.1e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 42/7830 [39:24<120:59:30, 55.93s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 43/7830 [40:20<120:57:30, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4759, 'grad_norm': 4.417716615263301, 'learning_rate': 2.15e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 43/7830 [40:20<120:57:30, 55.92s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 44/7830 [41:16<120:54:15, 55.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4141, 'grad_norm': 4.574294430882786, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 44/7830 [41:16<120:54:15, 55.90s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 45/7830 [42:12<120:52:49, 55.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5537, 'grad_norm': 4.3953098268633, 'learning_rate': 2.25e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 45/7830 [42:12<120:52:49, 55.90s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 46/7830 [43:08<120:51:08, 55.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.593, 'grad_norm': 3.9976524378355993, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 46/7830 [43:08<120:51:08, 55.89s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 47/7830 [44:04<120:51:26, 55.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5263, 'grad_norm': 4.4166483368883105, 'learning_rate': 2.35e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 47/7830 [44:04<120:51:26, 55.90s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 48/7830 [45:00<120:53:35, 55.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6081, 'grad_norm': 5.670637684104387, 'learning_rate': 2.4e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 48/7830 [45:00<120:53:35, 55.93s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 49/7830 [45:56<120:57:09, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.679, 'grad_norm': 4.681701736146829, 'learning_rate': 2.45e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 49/7830 [45:56<120:57:09, 55.96s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 50/7830 [46:52<120:56:05, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7258, 'grad_norm': 5.184897079991322, 'learning_rate': 2.5e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 50/7830 [46:52<120:56:05, 55.96s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 51/7830 [47:47<120:52:16, 55.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6611, 'grad_norm': 5.337832202445105, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 51/7830 [47:47<120:52:16, 55.94s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 52/7830 [48:43<120:47:58, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4909, 'grad_norm': 5.177551105123637, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 52/7830 [48:43<120:47:58, 55.91s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 53/7830 [49:39<120:42:30, 55.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6253, 'grad_norm': 5.554522676879513, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 53/7830 [49:39<120:42:30, 55.88s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 54/7830 [50:35<120:47:10, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5418, 'grad_norm': 3.7296064888218976, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 54/7830 [50:35<120:47:10, 55.92s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 55/7830 [51:31<120:46:31, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.558, 'grad_norm': 3.916017938551374, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 55/7830 [51:31<120:46:31, 55.92s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 56/7830 [52:27<120:47:04, 55.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.521, 'grad_norm': 6.206752840475759, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 56/7830 [52:27<120:47:04, 55.93s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 57/7830 [53:23<120:50:14, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7481, 'grad_norm': 5.3713712641375055, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 57/7830 [53:23<120:50:14, 55.96s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 58/7830 [54:19<120:48:10, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5431, 'grad_norm': 4.561936644171483, 'learning_rate': 2.9e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 58/7830 [54:19<120:48:10, 55.96s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 59/7830 [55:15<120:41:30, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5682, 'grad_norm': 5.1457744188321, 'learning_rate': 2.95e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 59/7830 [55:15<120:41:30, 55.91s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 60/7830 [56:11<120:36:47, 55.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6416, 'grad_norm': 5.148811662475579, 'learning_rate': 3e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 60/7830 [56:11<120:36:47, 55.88s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 61/7830 [57:06<120:35:32, 55.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6882, 'grad_norm': 4.401923253473165, 'learning_rate': 3.05e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 61/7830 [57:06<120:35:32, 55.88s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 62/7830 [58:02<120:36:03, 55.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5941, 'grad_norm': 4.611084701789287, 'learning_rate': 3.1e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 62/7830 [58:02<120:36:03, 55.89s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 63/7830 [58:58<120:43:18, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.59, 'grad_norm': 4.029442196997658, 'learning_rate': 3.15e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 63/7830 [58:58<120:43:18, 55.95s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 64/7830 [59:54<120:39:10, 55.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6862, 'grad_norm': 5.14365564308438, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 64/7830 [59:54<120:39:10, 55.93s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 65/7830 [1:00:50<120:33:44, 55.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6658, 'grad_norm': 4.533039029235924, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 65/7830 [1:00:50<120:33:44, 55.89s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 66/7830 [1:01:46<120:37:21, 55.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.546, 'grad_norm': 3.898637479801575, 'learning_rate': 3.3e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 66/7830 [1:01:46<120:37:21, 55.93s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 67/7830 [1:02:42<120:38:32, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5043, 'grad_norm': 5.1914744031808375, 'learning_rate': 3.35e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 67/7830 [1:02:42<120:38:32, 55.95s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 68/7830 [1:03:38<120:34:13, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5247, 'grad_norm': 3.541842213188295, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 68/7830 [1:03:38<120:34:13, 55.92s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 69/7830 [1:04:34<120:34:28, 55.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7267, 'grad_norm': 4.8532299180243905, 'learning_rate': 3.45e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 69/7830 [1:04:34<120:34:28, 55.93s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 70/7830 [1:05:30<120:35:58, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5827, 'grad_norm': 5.85009323437072, 'learning_rate': 3.5e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 70/7830 [1:05:30<120:35:58, 55.95s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 71/7830 [1:06:26<120:35:13, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4498, 'grad_norm': 4.098288080979929, 'learning_rate': 3.55e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 71/7830 [1:06:26<120:35:13, 55.95s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 72/7830 [1:07:22<120:34:01, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5805, 'grad_norm': 3.8245561429467547, 'learning_rate': 3.6e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 72/7830 [1:07:22<120:34:01, 55.95s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 73/7830 [1:08:18<120:32:29, 55.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.654, 'grad_norm': 8.815090799626743, 'learning_rate': 3.65e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 73/7830 [1:08:18<120:32:29, 55.94s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 74/7830 [1:09:14<120:26:21, 55.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6157, 'grad_norm': 4.969218681831313, 'learning_rate': 3.7e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 74/7830 [1:09:14<120:26:21, 55.90s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 75/7830 [1:10:10<120:27:16, 55.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7613, 'grad_norm': 6.386338267527422, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 75/7830 [1:10:10<120:27:16, 55.92s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 76/7830 [1:11:05<120:25:19, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6631, 'grad_norm': 4.44264631984611, 'learning_rate': 3.8e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 76/7830 [1:11:05<120:25:19, 55.91s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 77/7830 [1:12:01<120:20:18, 55.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.952, 'grad_norm': 5.2850247047445995, 'learning_rate': 3.85e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 77/7830 [1:12:01<120:20:18, 55.88s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 78/7830 [1:12:57<120:23:00, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5393, 'grad_norm': 5.058468944527004, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 78/7830 [1:12:57<120:23:00, 55.91s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 79/7830 [1:13:53<120:22:37, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5785, 'grad_norm': 3.5063753646225377, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 79/7830 [1:13:53<120:22:37, 55.91s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 80/7830 [1:14:49<120:20:11, 55.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6585, 'grad_norm': 3.9348572839161013, 'learning_rate': 4e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 80/7830 [1:14:49<120:20:11, 55.90s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 81/7830 [1:15:45<120:30:10, 55.98s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7848, 'grad_norm': 5.20856601449652, 'learning_rate': 4.05e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 81/7830 [1:15:45<120:30:10, 55.98s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 82/7830 [1:16:41<120:28:46, 55.98s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5626, 'grad_norm': 4.15922680711892, 'learning_rate': 4.1e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 82/7830 [1:16:41<120:28:46, 55.98s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 83/7830 [1:17:37<120:36:41, 56.05s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6748, 'grad_norm': 4.002751357830909, 'learning_rate': 4.15e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 83/7830 [1:17:37<120:36:41, 56.05s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 84/7830 [1:18:33<120:34:41, 56.04s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5055, 'grad_norm': 4.229069274883387, 'learning_rate': 4.2e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 84/7830 [1:18:33<120:34:41, 56.04s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 85/7830 [1:19:29<120:34:04, 56.04s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5763, 'grad_norm': 3.758063611306815, 'learning_rate': 4.25e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 85/7830 [1:19:29<120:34:04, 56.04s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 86/7830 [1:20:25<120:25:59, 55.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8977, 'grad_norm': 4.701723010187474, 'learning_rate': 4.3e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 86/7830 [1:20:25<120:25:59, 55.99s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 87/7830 [1:21:21<120:20:13, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5264, 'grad_norm': 3.7636040927423196, 'learning_rate': 4.35e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 87/7830 [1:21:21<120:20:13, 55.95s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 88/7830 [1:22:17<120:13:55, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6306, 'grad_norm': 4.18454535709449, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 88/7830 [1:22:17<120:13:55, 55.91s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 89/7830 [1:23:13<120:11:17, 55.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6481, 'grad_norm': 3.9260006060451635, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 89/7830 [1:23:13<120:11:17, 55.89s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 90/7830 [1:24:09<120:11:58, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6777, 'grad_norm': 3.763983024242685, 'learning_rate': 4.5e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 90/7830 [1:24:09<120:11:58, 55.91s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 91/7830 [1:25:05<120:11:39, 55.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7746, 'grad_norm': 4.114163122167226, 'learning_rate': 4.55e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 91/7830 [1:25:05<120:11:39, 55.91s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 92/7830 [1:26:01<120:19:20, 55.98s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.62, 'grad_norm': 4.190690831884106, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|          | 92/7830 [1:26:01<120:19:20, 55.98s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 93/7830 [1:26:57<120:16:23, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7177, 'grad_norm': 4.571039230081529, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|          | 93/7830 [1:26:57<120:16:23, 55.96s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 94/7830 [1:27:53<120:15:37, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6281, 'grad_norm': 3.5491207592095466, 'learning_rate': 4.7e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|          | 94/7830 [1:27:53<120:15:37, 55.96s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 95/7830 [1:28:49<120:15:39, 55.97s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7136, 'grad_norm': 6.624266385900191, 'learning_rate': 4.75e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|          | 95/7830 [1:28:49<120:15:39, 55.97s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 96/7830 [1:29:45<120:14:31, 55.97s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7409, 'grad_norm': 5.986739764599193, 'learning_rate': 4.8e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|          | 96/7830 [1:29:45<120:14:31, 55.97s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 97/7830 [1:30:41<120:11:31, 55.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6232, 'grad_norm': 7.863147838690652, 'learning_rate': 4.85e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|          | 97/7830 [1:30:41<120:11:31, 55.95s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 98/7830 [1:31:37<120:13:10, 55.97s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7582, 'grad_norm': 4.589716587334209, 'learning_rate': 4.9e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|▏         | 98/7830 [1:31:37<120:13:10, 55.97s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 99/7830 [1:32:33<120:10:56, 55.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7603, 'grad_norm': 6.073521299890584, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|▏         | 99/7830 [1:32:33<120:10:56, 55.96s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 100/7830 [1:33:29<120:16:04, 56.01s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8773, 'grad_norm': 5.381445812247055, 'learning_rate': 5e-05, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|▏         | 100/7830 [1:33:29<120:16:04, 56.01s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3719] 2024-06-04 10:40:59,336 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3719] 2024-06-04 10:40:59,336 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3721] 2024-06-04 10:40:59,336 >>   Num examples = 422\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3721] 2024-06-04 10:40:59,336 >>   Num examples = 422\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3724] 2024-06-04 10:40:59,337 >>   Batch size = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3724] 2024-06-04 10:40:59,337 >>   Batch size = 1\u001b[0m\n",
      "\u001b[34m0%|          | 0/53 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/53 [00:09<03:54,  4.60s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/53 [00:18<05:27,  6.54s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/53 [00:27<06:09,  7.53s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m9%|▉         | 5/53 [00:36<06:29,  8.11s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m11%|█▏        | 6/53 [00:46<06:38,  8.48s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/53 [00:55<06:40,  8.71s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/53 [01:04<06:38,  8.86s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/53 [01:13<06:34,  8.98s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 10/53 [01:22<06:29,  9.06s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m21%|██        | 11/53 [01:32<06:22,  9.11s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m23%|██▎       | 12/53 [01:41<06:14,  9.14s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m25%|██▍       | 13/53 [01:50<06:06,  9.16s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m26%|██▋       | 14/53 [01:59<05:57,  9.18s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 15/53 [02:08<05:48,  9.18s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m30%|███       | 16/53 [02:18<05:40,  9.19s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 17/53 [02:27<05:31,  9.20s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 18/53 [02:36<05:22,  9.20s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 19/53 [02:45<05:13,  9.21s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 20/53 [02:55<05:04,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m40%|███▉      | 21/53 [03:04<04:55,  9.24s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 22/53 [03:13<04:45,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 23/53 [03:22<04:36,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m45%|████▌     | 24/53 [03:32<04:27,  9.24s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m47%|████▋     | 25/53 [03:41<04:18,  9.23s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m49%|████▉     | 26/53 [03:50<04:09,  9.24s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m51%|█████     | 27/53 [03:59<04:00,  9.24s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 28/53 [04:08<03:50,  9.23s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 29/53 [04:18<03:41,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 30/53 [04:27<03:32,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 31/53 [04:36<03:24,  9.27s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m60%|██████    | 32/53 [04:46<03:14,  9.26s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 33/53 [04:55<03:04,  9.24s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 34/53 [05:04<02:55,  9.23s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 35/53 [05:13<02:45,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 36/53 [05:22<02:36,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 37/53 [05:32<02:27,  9.21s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 38/53 [05:41<02:17,  9.20s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 39/53 [05:50<02:08,  9.20s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 40/53 [05:59<01:59,  9.20s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 41/53 [06:08<01:50,  9.21s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 42/53 [06:18<01:41,  9.21s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 43/53 [06:27<01:32,  9.21s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 44/53 [06:36<01:22,  9.21s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 45/53 [06:45<01:13,  9.21s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 46/53 [06:54<01:04,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 47/53 [07:04<00:55,  9.22s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m91%|█████████ | 48/53 [07:13<00:46,  9.24s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 49/53 [07:22<00:36,  9.25s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 50/53 [07:31<00:27,  9.25s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 51/53 [07:41<00:18,  9.23s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 52/53 [07:50<00:09,  9.24s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 53/53 [07:59<00:00,  9.26s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.7171149849891663, 'eval_runtime': 488.9355, 'eval_samples_per_second': 0.863, 'eval_steps_per_second': 0.108, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|▏         | 100/7830 [1:41:38<120:16:04, 56.01s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 53/53 [07:59<00:00,  9.26s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3410] 2024-06-04 10:49:34,590 >> Saving model checkpoint to /opt/ml/checkpoints/checkpoint-100\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3410] 2024-06-04 10:49:34,590 >> Saving model checkpoint to /opt/ml/checkpoints/checkpoint-100\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:472] 2024-06-04 10:49:34,593 >> Configuration saved in /opt/ml/checkpoints/checkpoint-100/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:472] 2024-06-04 10:49:34,593 >> Configuration saved in /opt/ml/checkpoints/checkpoint-100/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:731] 2024-06-04 10:49:34,593 >> Configuration saved in /opt/ml/checkpoints/checkpoint-100/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:731] 2024-06-04 10:49:34,593 >> Configuration saved in /opt/ml/checkpoints/checkpoint-100/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2626] 2024-06-04 10:49:59,086 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/ml/checkpoints/checkpoint-100/model.safetensors.index.json.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2626] 2024-06-04 10:49:59,086 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/ml/checkpoints/checkpoint-100/model.safetensors.index.json.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2513] 2024-06-04 10:49:59,090 >> tokenizer config file saved in /opt/ml/checkpoints/checkpoint-100/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2513] 2024-06-04 10:49:59,090 >> tokenizer config file saved in /opt/ml/checkpoints/checkpoint-100/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2522] 2024-06-04 10:49:59,090 >> Special tokens file saved in /opt/ml/checkpoints/checkpoint-100/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2522] 2024-06-04 10:49:59,090 >> Special tokens file saved in /opt/ml/checkpoints/checkpoint-100/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[2024-06-04 10:49:59,298] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2024-06-04 10:49:59,308] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /opt/ml/checkpoints/checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_model_states.pt\u001b[0m\n",
      "\u001b[34m[2024-06-04 10:49:59,308] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/ml/checkpoints/checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_model_states.pt...\u001b[0m\n",
      "\u001b[34m[2024-06-04 10:49:59,323] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /opt/ml/checkpoints/checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_model_states.pt.\u001b[0m\n",
      "\u001b[34m[2024-06-04 10:49:59,327] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /opt/ml/checkpoints/checkpoint-100/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "environment = {\n",
    "    \"PRETRAINED_MODEL_S3_PATH\": \"s3://{}/{}\".format(bucket, prefix),\n",
    "    \"OUTPUT_DIR\": \"/opt/ml/checkpoints\"\n",
    "}\n",
    "\n",
    "checkpoint_s3_uri = model_ckpt\n",
    "checkpoint_local_path = \"/opt/ml/checkpoints\"\n",
    "\n",
    "train_use_spot_instances = True\n",
    "train_max_run=3600\n",
    "train_max_wait = 3600 if train_use_spot_instances else None\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      entry_point='entry.py',\n",
    "                      source_dir='.',\n",
    "                      base_job_name='multi-node-llama3-8b-instruct-sft',\n",
    "                      instance_count=instance_count,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      max_run=5*24*3600, #任务最大存续时间，默认2day，需要提交ticket提升quota最大28天\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      disable_output_compression=True,\n",
    "                      volume_size=1024,\n",
    "                      checkpoint_s3_uri=checkpoint_s3_uri, \n",
    "                      checkpoint_local_path=checkpoint_local_path,\n",
    "                      # use_spot_instances=train_use_spot_instances,  ## 如果使用spot instance\n",
    "                      # train_max_run=train_max_run, ## 如果使用spot instance\n",
    "                      # train_max_wait=train_max_wait, ## 如果使用spot instance\n",
    "                     )\n",
    "\n",
    "input_channel = {'train': 's3://sagemaker-us-west-2-726335585155/yafei/keywords/'}\n",
    "estimator.fit(input_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fd1c08f-f9a4-47f4-a53b-80cce67836e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-005329598202/hf_home/Meta-Llama-3-8B-Instruct/runs/May21_11-10-55_algo-1/events.out.tfevents.1716318168.algo-1.425.1 to ../llama3_model/runs/May21_11-10-55_algo-1/events.out.tfevents.1716318168.algo-1.425.1\n",
      "download: s3://sagemaker-us-east-1-005329598202/hf_home/Meta-Llama-3-8B-Instruct/runs/May21_11-10-55_algo-1/events.out.tfevents.1716289961.algo-1.425.0 to ../llama3_model/runs/May21_11-10-55_algo-1/events.out.tfevents.1716289961.algo-1.425.0\n"
     ]
    }
   ],
   "source": [
    "## 下载训练模型到本地\n",
    "!aws s3 sync $model_ckpt ../llama3_model --exclude \"checkpoint-100/*\" --exclude \"checkpoint-200/*\" --exclude \"checkpoint-300/*\" --exclude \"checkpoint-400/*\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26bc691-7f83-4da5-97a4-394f5212a7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
